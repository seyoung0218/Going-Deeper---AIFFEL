{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "deacda72c2a34db8a06e15bf9c436aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35deb30f14aa48e295069c2ccc285ec6",
              "IPY_MODEL_9266103230a94a85a175917315bb6ced",
              "IPY_MODEL_1237b88852ba4b08a38fe4cc5265965b"
            ],
            "layout": "IPY_MODEL_52d786601b574f97a593b72fa6927e63"
          }
        },
        "35deb30f14aa48e295069c2ccc285ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6564fe23d24d41ef80efb3e15b9e8996",
            "placeholder": "​",
            "style": "IPY_MODEL_3a6712025526497793b0e3fa6b564ec5",
            "value": "  0%"
          }
        },
        "9266103230a94a85a175917315bb6ced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d8fc687cfc243039c3fb3c1bad5daaa",
            "max": 3957761,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b69c610a1901424baea46879b849983c",
            "value": 105
          }
        },
        "1237b88852ba4b08a38fe4cc5265965b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4b41cf6d00944a79eadeda9031b0b13",
            "placeholder": "​",
            "style": "IPY_MODEL_91e39071ef5f425da5a2b23e2acc306d",
            "value": " 105/3957761 [00:00&lt;1:53:45, 579.86it/s]"
          }
        },
        "52d786601b574f97a593b72fa6927e63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6564fe23d24d41ef80efb3e15b9e8996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a6712025526497793b0e3fa6b564ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d8fc687cfc243039c3fb3c1bad5daaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b69c610a1901424baea46879b849983c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4b41cf6d00944a79eadeda9031b0b13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91e39071ef5f425da5a2b23e2acc306d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cd4ecc26e02414baa6e0c36c83ce875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b58a6f5c8734ec3bcdc01921926a165",
              "IPY_MODEL_8e1f536eb63348f4b98438347c6c552f",
              "IPY_MODEL_a61c73f103d24deb8296e8892be37f9d"
            ],
            "layout": "IPY_MODEL_6d6e0cf259bc40ff8956f508adfb5148"
          }
        },
        "2b58a6f5c8734ec3bcdc01921926a165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_651dbf38769f48668d0c40fee1bc7d6d",
            "placeholder": "​",
            "style": "IPY_MODEL_18066af69a9b4593991a6da38565cae4",
            "value": "100%"
          }
        },
        "8e1f536eb63348f4b98438347c6c552f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_785af7f766da4e569dd45cc0b74b3c6d",
            "max": 3957761,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96aace07c4f44121b3b40f0e0119382c",
            "value": 3957761
          }
        },
        "a61c73f103d24deb8296e8892be37f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d1597060f6e4243863bb9d183a87606",
            "placeholder": "​",
            "style": "IPY_MODEL_9fec43aad3f64b219a1cc4a3c6c1eee9",
            "value": " 3957761/3957761 [05:59&lt;00:00, 15548.60it/s]"
          }
        },
        "6d6e0cf259bc40ff8956f508adfb5148": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "651dbf38769f48668d0c40fee1bc7d6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18066af69a9b4593991a6da38565cae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "785af7f766da4e569dd45cc0b74b3c6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96aace07c4f44121b3b40f0e0119382c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d1597060f6e4243863bb9d183a87606": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fec43aad3f64b219a1cc4a3c6c1eee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "919092081b584a07b1050f63cf716943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28d933d81d384d4aa9575f85783be8a2",
              "IPY_MODEL_36a78dfed5964b08a0b10de0ce0ff094",
              "IPY_MODEL_8b7ebb845a994a508261f3203f58811b"
            ],
            "layout": "IPY_MODEL_4b1496e0793549138773a1bcb86411cf"
          }
        },
        "28d933d81d384d4aa9575f85783be8a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45f80b4a401241c292a8239771b8f4f6",
            "placeholder": "​",
            "style": "IPY_MODEL_33e6ce5de612478a86d27b821a8764df",
            "value": "  0%"
          }
        },
        "36a78dfed5964b08a0b10de0ce0ff094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68389c5f9815477a8595b720e1a7f2c7",
            "max": 918189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f720bf5ac7140c582b915c6e028c1e4",
            "value": 4
          }
        },
        "8b7ebb845a994a508261f3203f58811b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01fe25cf417e47e0907981e2dc4322d3",
            "placeholder": "​",
            "style": "IPY_MODEL_73e496bfaa6b43c2821849f6bc5d545a",
            "value": " 4/918189 [00:00&lt;3:52:05, 65.94it/s]"
          }
        },
        "4b1496e0793549138773a1bcb86411cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45f80b4a401241c292a8239771b8f4f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33e6ce5de612478a86d27b821a8764df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68389c5f9815477a8595b720e1a7f2c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f720bf5ac7140c582b915c6e028c1e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01fe25cf417e47e0907981e2dc4322d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73e496bfaa6b43c2821849f6bc5d545a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a78be1bc7a7047dfaf89becc20ebd051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba24f7ec10524ede8176e9888dacedce",
              "IPY_MODEL_265e9b73a845476c911314491f3c4169",
              "IPY_MODEL_9959c4a8695b497db49385f2a3c7d39a"
            ],
            "layout": "IPY_MODEL_26ddecdfc4ba49aea64a638ff89228cc"
          }
        },
        "ba24f7ec10524ede8176e9888dacedce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aa65246b2f04ac2a14dd3a87d4d52c2",
            "placeholder": "​",
            "style": "IPY_MODEL_0a773e109b0d4289a5214e0467105728",
            "value": "100%"
          }
        },
        "265e9b73a845476c911314491f3c4169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_603fde6f24394a87bfa249333f156491",
            "max": 128000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a289d475f1974902b7fa49110cd08203",
            "value": 128000
          }
        },
        "9959c4a8695b497db49385f2a3c7d39a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0ec543d55574527808bc94d307fa9cf",
            "placeholder": "​",
            "style": "IPY_MODEL_06edb7fd7e1a4bdf8e70857e459a00c6",
            "value": " 128000/128000 [00:34&lt;00:00, 4102.83it/s]"
          }
        },
        "26ddecdfc4ba49aea64a638ff89228cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aa65246b2f04ac2a14dd3a87d4d52c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a773e109b0d4289a5214e0467105728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "603fde6f24394a87bfa249333f156491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a289d475f1974902b7fa49110cd08203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0ec543d55574527808bc94d307fa9cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06edb7fd7e1a4bdf8e70857e459a00c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **프로젝트 : miniBERT 만들기**\n",
        "BERT의 정식 모델은 340M나 되는 파라미터 사이즈를 자랑합니다. 이들을 수십GB나되는 코퍼스를 토대로 학습시키는 것은 최고 성능의 GPU를 가지고도 수일 내지 수 주일의 시간이 걸립니다.\n",
        "\n",
        "그래서 지금은 일반적인 10M 정도의 작은 파라미터 사이즈의 BERT 모델을 만들어, 수백 MB수준의 코퍼스를 기반으로 pretrain을 진행해 보겠습니다. 모델을 만들고 학습시키는 것 이상으로 코퍼스 데이터를 가공해서 학습시켜야 할 task에 적합한 형태의 데이터셋으로 만들어가는 것이 큰 비중을 차지한다는 것을 알게 될 것입니다.\n",
        "\n",
        "학습에 사용할 코퍼스 데이터는 한글 나무위키 코퍼스인 [kowiki.txt.zip](https://d3s0tskafalll9.cloudfront.net/media/documents/kowiki.txt.zip) 입니다."
      ],
      "metadata": {
        "id": "8jFhlzqfFgZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step1. Import necessary Libraries**"
      ],
      "metadata": {
        "id": "uby820d2V5lU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_1kr_llIMmq",
        "outputId": "5eaaaf96-896d-4592-af14-d40400a5c0d5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 27.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sMhyGSx8FXyK"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import collections\n",
        "import json\n",
        "import shutil\n",
        "import zipfile\n",
        "import copy\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import sentencepiece as spm\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "random_seed = 1234\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "tf.random.set_seed(random_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step2. Tokenizer 준비**\n",
        "BERT등의 pretrained model이 나오게 되었을 즈음 자연어처리 분야의 또 다른중요한 흐름 중 하나는 BPE등의 subward기반의 토크나이징 기법이 주요한 방법론으로 굳어졌다는 점입니다. GPT의 BPE, BERT의 WordPiece 모델 등의 성공이 더욱 사람들에게 subword기반의 토크나이저에 대한 확신을 주었습니다. \n",
        "\n",
        "따라서 우리는 SentencePiece기반의 토크나이저를 준비하는 것으로 BERT pretrain과정을 시작할 것입니다.\n",
        "\n",
        "BERT에 사용되는 [MASK], [SEP], [CLS] 등의 주요 특수문자가 vocab에 포함되어야 함에 주의합니다."
      ],
      "metadata": {
        "id": "3OTZRLywWLAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_file = '/content/drive/MyDrive/GoingDeeper_Data/GD7/kowiki.txt'\n",
        "prefix = 'ko_8000'\n",
        "vocab_size = 8000\n",
        "\n",
        "spm.SentencePieceTrainer.train(\n",
        "    f\"--input={corpus_file} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" + \n",
        "    \" --model_type=bpe\" +\n",
        "    \" --max_sentence_length=999999\" + # 문장 최대 길이\n",
        "    \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n",
        "    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n",
        "    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n",
        "    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n",
        "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰"
      ],
      "metadata": {
        "id": "MNyFuBmWIKtx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델과 사전파일이 생성되었는지 확인해봅시다."
      ],
      "metadata": {
        "id": "4Op4QQ72XawD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "생성된 모델을 불러옵니다."
      ],
      "metadata": {
        "id": "AqGGKXUFXqXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.Load('ko_8000.model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV0_EedrXsR4",
        "outputId": "339cbba3-32f5-4b0c-9790-3456f27e26dc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "토크나이저가 잘 만들어졌는지 확인해 봅시다."
      ],
      "metadata": {
        "id": "QHnNTgZebQP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 특수토큰 7개는 제외\n",
        "vocab_list = []\n",
        "for id in range(7, len(vocab)):\n",
        "    if not vocab.is_unknown(id):\n",
        "        vocab_list.append(vocab.id_to_piece(id))\n",
        "\n",
        "print('단어장 크기:', len(vocab_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqQhPTVmbCQF",
        "outputId": "5555ca1c-5e88-45c8-8f87-acb10ffb4a11"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어장 크기: 8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시 문장\n",
        "string_a = \"추적추적 비가 내리는 날이었어 그날은 왠지 손님이 많아 첫 번에 삼십 전 둘째번 오십 전 오랜만에 받아보는 십 전짜리 백통화 서푼에\"\n",
        "string_b = \"손바닥 위엔 기쁨의 눈물이 흘러 컬컬한 목에 모주 한잔을 적셔 몇 달 포 전부터 콜록거리는 아내 생각에 그토록 먹고 싶다던\"\n",
        "tokens_org = [\"[CLS]\"] + vocab.encode_as_pieces(string_a) + [\"[SEP]\"] + vocab.encode_as_pieces(string_b) + [\"[SEP]\"]\n",
        "print(tokens_org)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UWLrzYWlDq0",
        "outputId": "e75f9bb3-9f51-4575-cf85-6e7f8107e37e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step3. MASK 생성**\n",
        "BERT의 Masked Language Model(MLM)은 GPT의 Next Token Prediction 태스크처럼 다음이 이어질 단어는? 을 맞추는 게 아니라 마스킹 된 다음 빈칸에 알맞은 단어는? 문제를 푸는 형식으로 구성됩니다.\n",
        "\n",
        "MLM을 위해 BERT는 학습 데이터의 전체에서 15%를 [MASK] 토큰으로 랜덤하게 바꿉니다. 이 15%의 [MASK] 토큰 중 80%는 [MASK] 토큰, 10%는 무작위로 랜덤한 토큰, 나머지 10%는 원래의 토큰을 그대로 사용합니다.\n",
        "\n",
        "15%를 마스킹 한다고 해도 생각해 볼 것이 더 있습니다. Subword 기반으로 토크나이징을 했을 때 _대, [MASK], 민국이라고 가운데를 마스킹 했을 경우 해당 [MASK]가 '한'일 거라는 건 너무 쉽게 맞출 수 있습니다. '대한민국'이라는 패턴을 아주 자주 보게 될 테니까요. 그래서 Masked LM 태스크를 구성할 땐 띄어쓰기 단위로 한꺼번에 마스킹해 주는 것이 좋습니다. \n",
        "\n",
        "위에서 사용했던 예시문장을 가지고 Mask를 생성하는 과정을 확인해봅시다."
      ],
      "metadata": {
        "id": "YG9wNHMVbi9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 token의 15% mask\n",
        "mask_cnt = int((len(tokens_org) - 3) * 0.15)\n",
        "mask_cnt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHApQf6Mld5S",
        "outputId": "930fdf77-c130-48f6-aa41-9d11d8868fee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 단위로 mask 하기 위해서 index 분할\n",
        "cand_idx = []\n",
        "for (i, token) in enumerate(tokens_org):\n",
        "    # cls, sep 토큰이면 건너뜀\n",
        "    if token == '[CLS]' or token == '[SEP]':\n",
        "        continue\n",
        "    # 단어의 시작에 해당하는 토큰을 제외하고 맨 끝 내부리스트에 인덱스 추가\n",
        "    if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\n",
        "        cand_idx[-1].append(i)\n",
        "    # 단어의 시작에 해당하는 토큰이면 리스트내에 새로운 인덱스리스트추가 \n",
        "    else:\n",
        "        cand_idx.append([i])\n",
        "\n",
        "# 결과 확인\n",
        "for cand in cand_idx:\n",
        "    print(cand, [tokens_org[i] for i in cand])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FAj9Anvly29",
        "outputId": "30a8cea2-ab8c-4ab0-bc80-c656feceb6d2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4] ['▁추', '적', '추', '적']\n",
            "[5, 6] ['▁비', '가']\n",
            "[7, 8] ['▁내', '리는']\n",
            "[9, 10, 11] ['▁날', '이었', '어']\n",
            "[12, 13, 14] ['▁그', '날', '은']\n",
            "[15, 16, 17] ['▁', '왠', '지']\n",
            "[18, 19, 20] ['▁손', '님', '이']\n",
            "[21, 22] ['▁많', '아']\n",
            "[23] ['▁첫']\n",
            "[24, 25] ['▁번', '에']\n",
            "[26, 27] ['▁삼', '십']\n",
            "[28] ['▁전']\n",
            "[29, 30, 31] ['▁둘', '째', '번']\n",
            "[32, 33] ['▁오', '십']\n",
            "[34] ['▁전']\n",
            "[35, 36, 37] ['▁오', '랜', '만에']\n",
            "[38, 39, 40] ['▁받아', '보', '는']\n",
            "[41] ['▁십']\n",
            "[42, 43, 44] ['▁전', '짜', '리']\n",
            "[45, 46, 47] ['▁백', '통', '화']\n",
            "[48, 49, 50] ['▁서', '푼', '에']\n",
            "[52, 53, 54] ['▁손', '바', '닥']\n",
            "[55, 56] ['▁위', '엔']\n",
            "[57, 58, 59] ['▁기', '쁨', '의']\n",
            "[60, 61] ['▁눈', '물이']\n",
            "[62, 63] ['▁흘', '러']\n",
            "[64, 65, 66] ['▁컬', '컬', '한']\n",
            "[67, 68] ['▁목', '에']\n",
            "[69, 70] ['▁모', '주']\n",
            "[71, 72, 73] ['▁한', '잔', '을']\n",
            "[74, 75] ['▁적', '셔']\n",
            "[76] ['▁몇']\n",
            "[77] ['▁달']\n",
            "[78] ['▁포']\n",
            "[79, 80] ['▁전', '부터']\n",
            "[81, 82, 83, 84] ['▁콜', '록', '거', '리는']\n",
            "[85] ['▁아내']\n",
            "[86, 87] ['▁생각', '에']\n",
            "[88, 89, 90] ['▁그', '토', '록']\n",
            "[91, 92] ['▁먹', '고']\n",
            "[93, 94, 95] ['▁싶', '다', '던']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokens가 mask되므로 재 실행을 위해서 넣어줌\n",
        "tokens = copy.deepcopy(tokens_org)\n",
        "\n",
        "# mask 된 값\n",
        "mask_lms = []\n",
        "for index_set in cand_idx:\n",
        "    # 현재 mask된 개수가 15%를 넘으면 중지\n",
        "    if len(mask_lms) >= mask_cnt:\n",
        "        break\n",
        "    # 이번에 mask할 개수를 포함해 15%를 넘으면 skip\n",
        "    if len(mask_lms) + len(index_set) > mask_cnt:\n",
        "        continue\n",
        "    # 0과 1사이의 확률 값\n",
        "    dice = random.random()\n",
        "\n",
        "    for index in index_set:\n",
        "        masked_token = None\n",
        "        # 80%는 [MASK]로 대체\n",
        "        if dice < 0.8:\n",
        "            masked_token = \"[MASK]\"\n",
        "        # 10%는 원래 토큰 유지\n",
        "        elif dice < 0.9:\n",
        "            masked_token = tokens[index]\n",
        "        # 10%는 사전에서 랜덤으로 대체\n",
        "        else:\n",
        "            masked_token = random.choice(vocab_list)\n",
        "        # 마스크된 값을 리스트에 추가\n",
        "        mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
        "        tokens[index] = masked_token\n",
        "\n",
        "print(\"tokens_org\")\n",
        "print(tokens_org, \"\\n\")\n",
        "print(\"tokens\")\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqv4fFDum4BS",
        "outputId": "4304341b-bb7c-4a04-ab68-7325d1ddaeea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens_org\n",
            "['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]'] \n",
            "\n",
            "tokens\n",
            "['[CLS]', '(', '▁제공', '▁소', '▁폐', '溶', 'エ', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 순서 정렬 및 mask_idx, mask_label 생성\n",
        "mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
        "mask_idx = [p[\"index\"] for p in mask_lms]\n",
        "mask_label = [p[\"label\"] for p in mask_lms]\n",
        "\n",
        "print('mask_idx :', mask_idx)\n",
        "print('mask_label :', mask_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHJBo4qmr0SF",
        "outputId": "567756a5-f67f-4f1c-d4e5-dc43fc0d20c0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mask_idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
            "mask_label : ['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번 스텝에서 구현할 최종 메소드는 다음과 같습니다."
      ],
      "metadata": {
        "id": "ypVKrYCls1xP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
        "    \"\"\"\n",
        "    마스크 생성\n",
        "    :param tokens: tokens\n",
        "    :param mask_cnt: mask 개수 (전체 tokens의 15%)\n",
        "    :param vocab_list: vocab list (random token 용)\n",
        "    :return tokens: mask된 tokens\n",
        "    :return mask_idx: mask된 token의 index\n",
        "    :return mask_label: mask된 token의 원래 값\n",
        "    \"\"\"\n",
        "    # 단어 단위로 mask 하기 위해서 index 분할\n",
        "    cand_idx = []  # word 단위의 index array\n",
        "    for (i, token) in enumerate(tokens):\n",
        "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
        "            continue\n",
        "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\n",
        "            cand_idx[-1].append(i)\n",
        "        else:\n",
        "            cand_idx.append([i])\n",
        "    # random mask를 위해서 순서를 섞음\n",
        "    random.shuffle(cand_idx)\n",
        "\n",
        "    mask_lms = []  # mask 된 값\n",
        "    for index_set in cand_idx:\n",
        "        if len(mask_lms) >= mask_cnt:  # 핸재 mask된 개수가 15%를 넘으면 중지\n",
        "            break\n",
        "        if len(mask_lms) + len(index_set) > mask_cnt:  # 이번에 mask할 개수를 포함해 15%를 넘으면 skip\n",
        "            continue\n",
        "        dice = random.random()  # 0..1 사이의 확률 값\n",
        "        for index in index_set:\n",
        "            masked_token = None\n",
        "            if dice < 0.8:  # 80% replace with [MASK]\n",
        "                masked_token = \"[MASK]\"\n",
        "            elif dice < 0.9: # 10% keep original\n",
        "                masked_token = tokens[index]\n",
        "            else:  # 10% random word\n",
        "                masked_token = random.choice(vocab_list)\n",
        "            mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
        "            tokens[index] = masked_token\n",
        "    # mask_lms 정렬 후 mask_idx, mask_label 추출\n",
        "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
        "    mask_idx = [p[\"index\"] for p in mask_lms]  # mask된 token의 index\n",
        "    mask_label = [p[\"label\"] for p in mask_lms]  # mask된 token의 원래 값\n",
        "\n",
        "    return tokens, mask_idx, mask_label"
      ],
      "metadata": {
        "id": "kowBfa3gdZmA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step4. NSP pair 생성**\n",
        "BERT의 pretrain task로 Next Sentence Prediction이 있습니다. 문장 2개를 붙여놓고 두 문장이 이어지는 것인지 아닌지 문장 호응관계를 맞출 수 있게 하는 것입니다.\n",
        "\n",
        "아래의 문장을 예시로 진행해 보겠습니다."
      ],
      "metadata": {
        "id": "13BYPRQYtGgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string = \"\"\"추적추적 비가 내리는 날이었어\n",
        "그날은 왠지 손님이 많아\n",
        "첫 번에 삼십 전 둘째 번 오십 전\n",
        "오랜만에 받아보는 십 전짜리 백통화 서푼에\n",
        "손바닥 위엔 기쁨의 눈물이 흘러\n",
        "컬컬한 목에 모주 한잔을 적셔\n",
        "몇 달 포 전부터 콜록거리는 아내\n",
        "생각에 그토록 먹고 싶다던\n",
        "설렁탕 한 그릇을 이제는 살 수 있어\n",
        "집으로 돌아가는 길 난 문득 떠올라\n",
        "아내의 목소리가 거칠어만 가는 희박한 숨소리가\n",
        "오늘은 왠지 나가지 말라던 내 옆에 있어 달라던\n",
        "그리도 나가고 싶으면 일찍이라도 들어와 달라던\n",
        "아내의 간절한 목소리가 들려와\n",
        "나를 원망하듯 비는 점점 거세져\n",
        "싸늘히 식어가는 아내가 떠올라 걱정은 더해져\n",
        "난 몰라 오늘은 운수 좋은 날\n",
        "난 맨날 이렇게 살 수 있으면 얼마나 좋을까\"\"\""
      ],
      "metadata": {
        "id": "Tx6mXuAvwLTL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 줄 단위로 tokenize\n",
        "doc = [vocab.encode_as_pieces(line) for line in string.split(\"\\n\")]\n",
        "doc[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqlWbQX0wPhw",
        "outputId": "70cf1393-6d98-40e5-d1e7-9210b1e157cd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어'],\n",
              " ['▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아'],\n",
              " ['▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전']]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "우선 원문에서 이어진 두 문장씩 짝지어 보겠습니다.\n",
        "\n",
        "이 단계에서 넣어줄 특수 token은 [CLS]와 [SEP]이고, sequence의 최대 길이는 n_test_seq - 3으로 정합니다."
      ],
      "metadata": {
        "id": "2epLd7o-wZlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 최대 길이\n",
        "n_test_seq = 64\n",
        "# 최소 길이\n",
        "min_seq = 8\n",
        "# [CLS], tokens_a, [SEB], tokens_b, [SEP]\n",
        "max_seq = n_test_seq - 3"
      ],
      "metadata": {
        "id": "1xJSo5wQwZSP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_chunk = []  # line 단위 tokens\n",
        "current_length = 0\n",
        "# 문장별로 반복\n",
        "for i in range(len(doc)):\n",
        "    # line 단위로 추가\n",
        "    current_chunk.append(doc[i])\n",
        "    # current_chunk의 token 수  \n",
        "    current_length += len(doc[i])  \n",
        "    # 마지막 줄 이거나 길이가 max_seq 이상 인 경우, 학습 데이터를 만듭니다. \n",
        "    if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):  \n",
        "        print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
        "\n",
        "        #######################################\n",
        "        # token a\n",
        "        a_end = 1\n",
        "        if 1 < len(current_chunk):\n",
        "            # 해당 범위의 정수하나를 랜덤으로 추출\n",
        "            a_end = random.randrange(1, len(current_chunk))\n",
        "        tokens_a = []\n",
        "        for j in range(a_end):\n",
        "            # extend() : 해당 리스트들을 이어붙여줌\n",
        "            tokens_a.extend(current_chunk[j])\n",
        "        # token b\n",
        "        tokens_b = []\n",
        "        for j in range(a_end, len(current_chunk)):\n",
        "            tokens_b.extend(current_chunk[j])\n",
        "          \n",
        "        print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
        "        print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
        "        #######################################\n",
        "        print()\n",
        "\n",
        "        current_chunk = []\n",
        "        current_length = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giIr0CCuwt6V",
        "outputId": "38737727-e38b-4285-d474-076670319c0e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current_chunk: 5 62 [['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어'], ['▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아'], ['▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전'], ['▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에'], ['▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러']]\n",
            "tokens_a: 34 ['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전']\n",
            "tokens_b: 28 ['▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러']\n",
            "\n",
            "current_chunk: 6 71 [['▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔'], ['▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내'], ['▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던'], ['▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어'], ['▁집', '으로', '▁돌아', '가는', '▁길', '▁난', '▁문', '득', '▁떠', '올', '라'], ['▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가']]\n",
            "tokens_a: 22 ['▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내']\n",
            "tokens_b: 49 ['▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어', '▁집', '으로', '▁돌아', '가는', '▁길', '▁난', '▁문', '득', '▁떠', '올', '라', '▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가']\n",
            "\n",
            "current_chunk: 5 73 [['▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던'], ['▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던'], ['▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와'], ['▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져'], ['▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져']]\n",
            "tokens_a: 17 ['▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던']\n",
            "tokens_b: 56 ['▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던', '▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와', '▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져', '▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져']\n",
            "\n",
            "current_chunk: 2 22 [['▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날'], ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까']]\n",
            "tokens_a: 9 ['▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날']\n",
            "tokens_b: 13 ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "짝지은 두 문장을 그대로 두면 NSP task의 true label 케이스가 되고, 둘의 순서를 뒤바꾸면 false label 케이스가 되겠죠?\n",
        "\n",
        "두 문장의 최대 길이를 유지하도록 trim을 적용한 후 50%의 확률로 true/false 케이스를 생성해 보겠습니다.\n",
        "\n",
        "token A의 길이가 max_seq보다 길면 앞에서부터 토큰을 제거하고, token B의 길이가 길면 뒤에서부터 토큰을 제거합니다.\n"
      ],
      "metadata": {
        "id": "2J3ndG8L0F0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
        "\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        # tokens_a, tokens_b의 길이를 줄임 최대 길이: max_seq\n",
        "        if total_length <= max_seq:\n",
        "            break\n",
        "        # a문장이 더 길면 a문장의 첫번째 토큰을 제거\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            del tokens_a[0]\n",
        "        # b문장이 더 길면 b문장의 맨뒤 토큰 제거\n",
        "        else:\n",
        "            tokens_b.pop()"
      ],
      "metadata": {
        "id": "ZsFl9M9C0Etd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 위의 코드와 동일\n",
        "current_chunk = []  \n",
        "current_length = 0\n",
        "for i in range(len(doc)): \n",
        "    current_chunk.append(doc[i])  \n",
        "    current_length += len(doc[i])  \n",
        "    if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):  # 마지막 줄 이거나 길이가 max_seq 이상 인 경우\n",
        "        print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
        "        a_end = 1\n",
        "        if 1 < len(current_chunk):\n",
        "            a_end = random.randrange(1, len(current_chunk))\n",
        "        tokens_a = []\n",
        "        for j in range(a_end):\n",
        "            tokens_a.extend(current_chunk[j])\n",
        "        tokens_b = []\n",
        "        for j in range(a_end, len(current_chunk)):\n",
        "            tokens_b.extend(current_chunk[j])\n",
        "\n",
        "        #######################################\n",
        "        # 50% 확률로 swap\n",
        "        if random.random() < 0.5:\n",
        "            #False  \n",
        "            is_next = 0     \n",
        "            # 스왑\n",
        "            tokens_t = tokens_a\n",
        "            tokens_a = tokens_b\n",
        "            tokens_b = tokens_t\n",
        "        else:\n",
        "            #True\n",
        "            is_next = 1    \n",
        "        # max_seq 보다 큰 경우 길이 조절\n",
        "        trim_tokens(tokens_a, tokens_b, max_seq)\n",
        "        assert 0 < len(tokens_a)\n",
        "        assert 0 < len(tokens_b)\n",
        "\n",
        "        print(\"is_next:\", is_next)\n",
        "        print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
        "        print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
        "        #######################################\n",
        "        print()\n",
        "\n",
        "        current_chunk = []\n",
        "        current_length = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmciXVUW0WTN",
        "outputId": "3be45828-1ef1-4363-c5bd-a96e01ce630e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current_chunk: 5 62 [['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어'], ['▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아'], ['▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전'], ['▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에'], ['▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러']]\n",
            "is_next: 0\n",
            "tokens_a: 50 ['날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러']\n",
            "tokens_b: 11 ['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어']\n",
            "\n",
            "current_chunk: 6 71 [['▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔'], ['▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내'], ['▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던'], ['▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어'], ['▁집', '으로', '▁돌아', '가는', '▁길', '▁난', '▁문', '득', '▁떠', '올', '라'], ['▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가']]\n",
            "is_next: 0\n",
            "tokens_a: 16 ['▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가']\n",
            "tokens_b: 45 ['▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어', '▁집']\n",
            "\n",
            "current_chunk: 5 73 [['▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던'], ['▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던'], ['▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와'], ['▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져'], ['▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져']]\n",
            "is_next: 0\n",
            "tokens_a: 17 ['▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져']\n",
            "tokens_b: 44 ['▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던', '▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던', '▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와', '▁나']\n",
            "\n",
            "current_chunk: 2 22 [['▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날'], ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까']]\n",
            "is_next: 1\n",
            "tokens_a: 9 ['▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날']\n",
            "tokens_b: 13 ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 두 문장 사이에 segment 처리를 해주어야 합니다. 첫 번째 문장의 segment는 모두 0으로, 두 번째 문장은 1로 채워준 후 둘 사이에 구분자인 [SEP] 등을 넣어주는 것으로 마무리됩니다.\n",
        "\n",
        "이전 스텝의 create_pretrain_mask()까지 함께 호출되어 Mask LM용 데이터셋과 NSP용 데이터셋이 결합된 하나의 데이터셋으로 완성될 것입니다. BERT의 pretrain은 MLM과 NSP, 두 가지 task가 동시에 수행되니까요."
      ],
      "metadata": {
        "id": "855HjpaE4rXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instances = []\n",
        "current_chunk = []  \n",
        "current_length = 0\n",
        "for i in range(len(doc)):  \n",
        "    current_chunk.append(doc[i])  \n",
        "    current_length += len(doc[i]) \n",
        "    if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):  \n",
        "        print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
        "\n",
        "        a_end = 1\n",
        "        if 1 < len(current_chunk):\n",
        "            a_end = random.randrange(1, len(current_chunk))\n",
        "        tokens_a = []\n",
        "        for j in range(a_end):\n",
        "            tokens_a.extend(current_chunk[j])\n",
        "        tokens_b = []\n",
        "        for j in range(a_end, len(current_chunk)):\n",
        "            tokens_b.extend(current_chunk[j])\n",
        "\n",
        "        if random.random() < 0.5:  \n",
        "            is_next = 0   \n",
        "            tokens_t = tokens_a\n",
        "            tokens_a = tokens_b\n",
        "            tokens_b = tokens_t\n",
        "        else:\n",
        "            is_next = 1   \n",
        "        trim_tokens(tokens_a, tokens_b, max_seq)\n",
        "        assert 0 < len(tokens_a)\n",
        "        assert 0 < len(tokens_b)\n",
        "\n",
        "        print(\"is_next:\", is_next)\n",
        "        print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
        "        print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
        "        #######################################\n",
        "\n",
        "        # tokens & segment 생성\n",
        "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
        "        segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
        "        print(\"tokens:\", len(tokens), tokens)\n",
        "        print(\"segment:\", len(segment), segment)\n",
        "        \n",
        "        # mask\n",
        "        tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * 0.15), vocab_list)\n",
        "        print(\"masked tokens:\", len(tokens), tokens)\n",
        "        print(\"masked index:\", len(mask_idx), mask_idx)\n",
        "        print(\"masked label:\", len(mask_label), mask_label)\n",
        "\n",
        "        instance = {\n",
        "            \"tokens\": tokens,\n",
        "            \"segment\": segment,\n",
        "            \"is_next\": is_next,\n",
        "            \"mask_idx\": mask_idx,\n",
        "            \"mask_label\": mask_label\n",
        "        }\n",
        "        instances.append(instance)\n",
        "        #######################################\n",
        "        print()\n",
        "\n",
        "        current_chunk = []\n",
        "        current_length = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXlaZAzD5Rrz",
        "outputId": "14d8763f-ea9a-4b53-aeff-c8b56578f025"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current_chunk: 5 62 [['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어'], ['▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아'], ['▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전'], ['▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에'], ['▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러']]\n",
            "is_next: 1\n",
            "tokens_a: 11 ['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어']\n",
            "tokens_b: 50 ['▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘']\n",
            "tokens: 64 ['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '[SEP]', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '[SEP]']\n",
            "segment: 64 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "masked tokens: 64 ['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '[SEP]', '▁그', '날', '은', '▁', '왠', '지', '[MASK]', '[MASK]', '[MASK]', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '[MASK]', '▁둘', '째', '[MASK]', '▁오', '십', '[MASK]', '▁오', '랜', '만에', '▁받아', '보', '는', '[MASK]', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '▁손', '바', '닥', '[MASK]', '[MASK]', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '[SEP]']\n",
            "masked index: 9 [19, 20, 21, 29, 32, 35, 42, 55, 56]\n",
            "masked label: 9 ['▁손', '님', '이', '▁전', '▁번', '▁전', '▁십', '▁위', '엔']\n",
            "\n",
            "current_chunk: 6 71 [['▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔'], ['▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내'], ['▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던'], ['▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어'], ['▁집', '으로', '▁돌아', '가는', '▁길', '▁난', '▁문', '득', '▁떠', '올', '라'], ['▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가']]\n",
            "is_next: 0\n",
            "tokens_a: 16 ['▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가']\n",
            "tokens_b: 45 ['▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어', '▁집']\n",
            "tokens: 64 ['[CLS]', '▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가', '[SEP]', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어', '▁집', '[SEP]']\n",
            "segment: 64 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "masked tokens: 64 ['[CLS]', '▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가', '[SEP]', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '[MASK]', '[MASK]', '▁몇', '[MASK]', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '▁설', '렁', '탕', '[MASK]', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '[MASK]', '▁집', '[SEP]']\n",
            "masked index: 9 [28, 29, 31, 40, 41, 53, 59, 60, 61]\n",
            "masked label: 9 ['▁적', '셔', '▁달', '▁생각', '에', '▁한', '▁살', '▁수', '▁있어']\n",
            "\n",
            "current_chunk: 5 73 [['▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던'], ['▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던'], ['▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와'], ['▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져'], ['▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져']]\n",
            "is_next: 0\n",
            "tokens_a: 30 ['▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져', '▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져']\n",
            "tokens_b: 31 ['▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던', '▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라']\n",
            "tokens: 64 ['[CLS]', '▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져', '▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져', '[SEP]', '▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던', '▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '[SEP]']\n",
            "segment: 64 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "masked tokens: 64 ['[CLS]', '[MASK]', '[MASK]', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져', '▁싸', '늘', '히', '▁식', '어', '가는', '[MASK]', '[MASK]', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져', '[SEP]', '[MASK]', '[MASK]', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던', '▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '[SEP]']\n",
            "masked index: 9 [1, 2, 20, 21, 32, 33, 45, 53, 54]\n",
            "masked label: 9 ['▁나', '를', '▁아내', '가', '▁오늘', '은', '▁있어', '▁싶', '으면']\n",
            "\n",
            "current_chunk: 2 22 [['▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날'], ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까']]\n",
            "is_next: 1\n",
            "tokens_a: 9 ['▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날']\n",
            "tokens_b: 13 ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까']\n",
            "tokens: 25 ['[CLS]', '▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날', '[SEP]', '▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까', '[SEP]']\n",
            "segment: 25 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "masked tokens: 25 ['[CLS]', '▁난', '▁몰', '라', '[MASK]', '[MASK]', '▁운', '수', '▁좋은', '▁날', '[SEP]', '▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까', '[SEP]']\n",
            "masked index: 3 [4, 5, 11]\n",
            "masked label: 3 ['▁오늘', '은', '▁난']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 데이터셋 결과 확인\n",
        "for instance in instances:\n",
        "    print(instance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4vPyHlk6gEL",
        "outputId": "82317448-9743-49fe-ca94-98327cf84660"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tokens': ['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '[SEP]', '▁그', '날', '은', '▁', '왠', '지', '[MASK]', '[MASK]', '[MASK]', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '[MASK]', '▁둘', '째', '[MASK]', '▁오', '십', '[MASK]', '▁오', '랜', '만에', '▁받아', '보', '는', '[MASK]', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '▁손', '바', '닥', '[MASK]', '[MASK]', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [19, 20, 21, 29, 32, 35, 42, 55, 56], 'mask_label': ['▁손', '님', '이', '▁전', '▁번', '▁전', '▁십', '▁위', '엔']}\n",
            "{'tokens': ['[CLS]', '▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가', '[SEP]', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '[MASK]', '[MASK]', '▁몇', '[MASK]', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '▁설', '렁', '탕', '[MASK]', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '[MASK]', '▁집', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [28, 29, 31, 40, 41, 53, 59, 60, 61], 'mask_label': ['▁적', '셔', '▁달', '▁생각', '에', '▁한', '▁살', '▁수', '▁있어']}\n",
            "{'tokens': ['[CLS]', '[MASK]', '[MASK]', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져', '▁싸', '늘', '히', '▁식', '어', '가는', '[MASK]', '[MASK]', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져', '[SEP]', '[MASK]', '[MASK]', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던', '▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [1, 2, 20, 21, 32, 33, 45, 53, 54], 'mask_label': ['▁나', '를', '▁아내', '가', '▁오늘', '은', '▁있어', '▁싶', '으면']}\n",
            "{'tokens': ['[CLS]', '▁난', '▁몰', '라', '[MASK]', '[MASK]', '▁운', '수', '▁좋은', '▁날', '[SEP]', '▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [4, 5, 11], 'mask_label': ['▁오늘', '은', '▁난']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번 스텝에서 구현할 최종 메소드는 다음과 같습니다."
      ],
      "metadata": {
        "id": "XUAqjQ1a6tWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list):\n",
        "    \"\"\"\n",
        "    doc별 pretrain 데이터 생성\n",
        "    \"\"\"\n",
        "    # for CLS], [SEP], [SEP]\n",
        "    max_seq = n_seq - 3\n",
        "\n",
        "    instances = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "    for i in range(len(doc)):\n",
        "        current_chunk.append(doc[i])  # line\n",
        "        current_length += len(doc[i])\n",
        "        if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):\n",
        "            # token a\n",
        "            a_end = 1\n",
        "            if 1 < len(current_chunk):\n",
        "                a_end = random.randrange(1, len(current_chunk))\n",
        "            tokens_a = []\n",
        "            for j in range(a_end):\n",
        "                tokens_a.extend(current_chunk[j])\n",
        "            # token b\n",
        "            tokens_b = []\n",
        "            for j in range(a_end, len(current_chunk)):\n",
        "                tokens_b.extend(current_chunk[j])\n",
        "\n",
        "            if random.random() < 0.5:  # 50% 확률로 swap\n",
        "                is_next = 0\n",
        "                tokens_t = tokens_a\n",
        "                tokens_a = tokens_b\n",
        "                tokens_b = tokens_t\n",
        "            else:\n",
        "                is_next = 1\n",
        "            # max_seq 보다 큰 경우 길이 조절\n",
        "            trim_tokens(tokens_a, tokens_b, max_seq)\n",
        "            assert 0 < len(tokens_a)\n",
        "            assert 0 < len(tokens_b)\n",
        "            # tokens & aegment 생성\n",
        "            tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
        "            segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
        "            # mask\n",
        "            tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * mask_prob), vocab_list)\n",
        "\n",
        "            instance = {\n",
        "                \"tokens\": tokens,\n",
        "                \"segment\": segment,\n",
        "                \"is_next\": is_next,\n",
        "                \"mask_idx\": mask_idx,\n",
        "                \"mask_label\": mask_label\n",
        "            }\n",
        "            instances.append(instance)\n",
        "\n",
        "            current_chunk = []\n",
        "            current_length = 0\n",
        "    return instances"
      ],
      "metadata": {
        "id": "7Tq0Jwcc6v5g"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step5. 데이터셋 완성**\n",
        "이제 우리가 다루어야 할 kowiki.txt에 대해 본격적으로 들여다보겠습니다."
      ],
      "metadata": {
        "id": "4Yrmu2dO7JfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# line count 확인\n",
        "total = 0\n",
        "with open(corpus_file, 'r') as in_f:\n",
        "    for line in in_f:\n",
        "        total += 1\n",
        "\n",
        "total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDdn-Qy37PIL",
        "outputId": "312fa927-aaf4-4e86-ad8a-c8b1de24dfa4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3957761"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "거의 400만개에 육박하는 수치입니다.\n",
        "\n",
        "위키 문서는 하나의 도큐먼트가 주제 키워드에 대해 상세 내용이 설명으로 따라붙어 있는 형태로 구성되어 있습니다. 도큐먼트 주제별로 잘 나눠지는지도 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "K75L9Nml7TLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 5\n",
        "\n",
        "with open(corpus_file, 'r') as in_f:\n",
        "    doc = []  # 단락 단위로 문서 저장\n",
        "    for line in tqdm(in_f, total=total):\n",
        "        line = line.strip()\n",
        "        if line == \"\":  # line이 빈줄 일 경우 (새로운 단락)  \n",
        "            if 0 < len(doc):\n",
        "                if 0 < count:\n",
        "                    count -= 1\n",
        "                    print(len(doc), \"lines :\", doc[0])\n",
        "                    print(doc[1])\n",
        "                    print(doc[-1])\n",
        "                    print()\n",
        "                else:\n",
        "                    break\n",
        "                doc = []\n",
        "        else:  # 빈 줄이 아니면 doc에 저장\n",
        "            pieces = vocab.encode_as_pieces(line)    \n",
        "            if 0 < len(pieces):\n",
        "                doc.append(pieces)\n",
        "    if 0 < len(doc):  # 마지막에 처리되지 않은 doc가 있는 경우\n",
        "        print(doc[0])\n",
        "        print(doc[1])\n",
        "        print(doc[-1])\n",
        "        doc = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448,
          "referenced_widgets": [
            "deacda72c2a34db8a06e15bf9c436aca",
            "35deb30f14aa48e295069c2ccc285ec6",
            "9266103230a94a85a175917315bb6ced",
            "1237b88852ba4b08a38fe4cc5265965b",
            "52d786601b574f97a593b72fa6927e63",
            "6564fe23d24d41ef80efb3e15b9e8996",
            "3a6712025526497793b0e3fa6b564ec5",
            "5d8fc687cfc243039c3fb3c1bad5daaa",
            "b69c610a1901424baea46879b849983c",
            "d4b41cf6d00944a79eadeda9031b0b13",
            "91e39071ef5f425da5a2b23e2acc306d"
          ]
        },
        "id": "10CE9Ght8wIP",
        "outputId": "4db6cb3f-8ed7-421a-9085-cd85e02c4f22"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3957761 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "deacda72c2a34db8a06e15bf9c436aca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21 lines : ['▁지', '미', '▁카', '터']\n",
            "['▁제임스', '▁얼', '▁\"', '지', '미', '\"', '▁카', '터', '▁주', '니어', '(,', '▁192', '4', '년', '▁10', '월', '▁1', '일', '▁~', '▁)', '는', '▁민주', '당', '▁출신', '▁미국', '▁3', '9', '번째', '▁대통령', '▁(19', '7', '7', '년', '▁~', '▁1981', '년', ')', '이다', '.']\n",
            "['▁그는', '▁2002', '년', '▁말', '▁인', '권', '과', '▁중', '재', '▁역할', '에', '▁대한', '▁공', '로를', '▁인정', '받아', '▁노', '벨', '▁평화', '상을', '▁받', '게', '▁되었다', '.']\n",
            "\n",
            "14 lines : ['▁수학']\n",
            "['▁수학', '(', '數', '學', ',', '▁)', '은', '▁양', ',', '▁구조', ',', '▁공간', ',', '▁변화', ',', '▁미', '적', '분', '▁등의', '▁개념', '을', '▁다루', '는', '▁학', '문', '이다', '.', '▁현대', '▁수학', '은', '▁형식', '▁논', '리를', '▁이용', '해서', '▁공', '리로', '▁구성된', '▁추', '상', '적', '▁구조를', '▁연구', '하는', '▁학', '문', '으로', '▁여겨', '지', '기도', '▁한다', '.', '▁수학', '은', '▁그', '▁구조', '와', '▁발전', '▁과정', '에서는', '▁자연', '과학', '에', '▁속하는', '▁물리', '학을', '▁비롯한', '▁다른', '▁학', '문', '들과', '▁깊', '은', '▁연', '관을', '▁맺', '고', '▁있다', '.', '▁하지만', ',', '▁어느', '▁과학', '의', '▁분야', '들과', '는', '▁달리', ',', '▁자연', '계에서', '▁관측', '되지', '▁않는', '▁개념', '들에', '▁대해서', '까지', '▁이론', '을', '▁일반', '화', '▁및', '▁추', '상', '화', '시', '킬', '▁수', '▁있다는', '▁차', '이가', '▁있다고', '▁한다', '.', '▁수', '학자', '들은', '▁그러', '한', '▁개념', '들에', '▁대해서', '▁추', '측', '을', '▁하고', ',', '▁적', '절', '하게', '▁선택', '된', '▁정의', '와', '▁공', '리', '로부터', '의', '▁엄', '밀', '한', '▁연', '역을', '▁통해', '서', '▁추', '측', '들의', '▁진', '위를', '▁파', '악', '한다', '.']\n",
            "['▁수', '학의', '▁기초', '를', '▁확', '실', '히', '▁세', '우', '기', '▁위해', ',', '▁수', '리', '논', '리', '학과', '▁집합', '론', '이', '▁발전', '하였고', ',', '▁이와', '▁더불어', '▁범', '주', '론', '이', '▁최근', '에도', '▁발전', '되고', '▁있다', '.', '▁“', '근', '본', '▁위', '기', '”', '라는', '▁말', '은', '▁대', '략', '▁19', '00', '년', '에서', '▁1930', '년', '▁사이에', '▁일어난', ',', '▁수', '학의', '▁엄', '밀', '한', '▁기초', '에', '▁대한', '▁탐', '구를', '▁상징', '적으로', '▁보여', '주는', '▁말이다', '.', '▁수', '학의', '▁엄', '밀', '한', '▁기초', '에', '▁대한', '▁몇', '▁가지', '▁의견', '▁불', '일', '치는', '▁오늘날', '에도', '▁계속', '되고', '▁있다', '.', '▁수', '학의', '▁기초', '에', '▁대한', '▁위', '기는', '▁그', '▁당시', '▁수많은', '▁논', '쟁', '에', '▁의해', '▁촉', '발', '되었으며', ',', '▁그', '▁논', '쟁', '에는', '▁칸', '토', '어의', '▁집합', '론', '과', '▁브라', '우', '어', '-', '힐', '베', '르트', '▁논', '쟁', '이', '▁포함', '되었다', '.']\n",
            "\n",
            "4 lines : ['▁수학', '▁상', '수']\n",
            "['▁수학', '에서', '▁상', '수', '란', '▁그', '▁값', '이', '▁변', '하지', '▁않는', '▁불', '변', '량', '으로', ',', '▁변', '수의', '▁반대', '말', '이다', '.', '▁물리', '▁상', '수', '와는', '▁달리', ',', '▁수학', '▁상', '수는', '▁물리', '적', '▁측정', '과는', '▁상', '관', '없이', '▁정의', '된다', '.']\n",
            "['▁특정', '▁수학', '▁상', '수', ',', '▁예를', '▁들', '면', '▁골', '롬', '-', '딕', '맨', '▁상', '수', ',', '▁프랑', '세', '즈', '-', '로', '빈', '슨', '▁상', '수', ',', '▁formula', '_1', ',', '▁레', '비', '▁상', '수', '같은', '▁상', '수는', '▁다른', '▁수학', '상', '수', '▁또는', '▁함수', '와', '▁약', '한', '▁상', '관', '관', '계', '▁또는', '▁강한', '▁상', '관', '관', '계를', '▁갖', '는다', '.']\n",
            "\n",
            "10 lines : ['▁문학']\n",
            "['▁문학', '(', '文', '學', ')', '은', '▁언', '어를', '▁예술', '적', '▁표현', '의', '▁제', '재', '로', '▁삼', '아', '▁새로운', '▁의미', '를', '▁창', '출', '하여', ',', '▁인간', '과', '▁사회', '를', '▁진', '실', '되', '게', '▁묘사', '하는', '▁예술', '의', '▁하', '위', '분', '야', '이다', '.', '▁간', '단', '하게', '▁설명', '하면', ',', '▁언', '어를', '▁통해', '▁인간의', '▁삶', '을', '▁미', '적', '(', '美', '的', ')', '으로', '▁형', '상', '화', '한', '▁것이라고', '▁볼', '▁수', '▁있다', '.', '▁문학', '은', '▁원래', '▁문', '예', '(', '文', '藝', ')', '라고', '▁부', '르는', '▁것이', '▁', '옳', '으며', ',', '▁문', '학을', '▁학', '문', '의', '▁대상', '으로서', '▁탐', '구', '하는', '▁학', '문', '의', '▁명칭', '▁역시', '▁문', '예', '학', '이다', '.', '▁문', '예', '학', '은', '▁음악', '사', '학', ',', '▁미술', '사', '학', '▁등과', '▁함께', '▁예술', '학의', '▁핵', '심', '분', '야', '로서', '▁인', '문', '학의', '▁하', '위', '범', '주에', '▁포함', '된다', '.']\n",
            "['▁반', '영', '론', '적', '▁관', '점에', '▁의한', '▁감', '상은', '▁작품', '을', '▁창', '작', '된', '▁당시', '▁시대', '▁정', '황', '과', '▁연결', '시켜', '▁감', '상', '하는', '▁입', '장', '이고', ',', '▁내', '재', '적', '▁관', '점', '의', '▁감', '상은', '▁작품', '의', '▁형식', ',', '▁내용', '에', '▁국', '한', '하여', '▁감', '상', '하는', '▁것이다', '.', '▁표현', '론', '적', '▁관', '점', '의', '▁감', '상은', '▁작가', '의', '▁전기', '적', '▁사실', '과', '▁작품', '을', '▁연결', '시켜', '▁감', '상', '하는', '▁것이', '고', ',', '▁수용', '론', '적', '▁관', '점', '의', '▁감', '상은', '▁독', '자와', '▁작품', '을', '▁연결', '시켜', '▁감', '상', '하는', '▁것을', '▁말한다', '.']\n",
            "\n",
            "10 lines : ['▁나라', '▁목록']\n",
            "['▁이', '▁문', '서는', '▁나라', '▁목록', '이며', ',', '▁전', '▁세계', '▁20', '6', '개', '▁나라', '의', '▁각', '▁현', '황', '과', '▁주', '권', '▁승', '인', '▁정보를', '▁개', '요', '▁형태로', '▁나', '열', '하고', '▁있다', '.']\n",
            "['▁위', '▁목록', '에', '▁포함', '되지', '▁않은', '▁다음', '▁국가', '는', '▁몬', '테', '비', '데', '오', '▁협', '약', '의', '▁모든', '▁조건', '을', '▁만족', '하지', '▁못', '하거나', ',', '▁자주', '적이고', '▁독립', '적', '임을', '▁주장', '하지', '▁않는', '▁국가', '이다', '.']\n",
            "\n",
            "['▁화학']\n",
            "['▁화학', '(', '化', '學', ',', '▁)', '은', '▁물질', '의', '▁성', '질', ',', '▁조성', ',', '▁구조', ',', '▁변화', '▁및', '▁그', '에', '▁수', '반', '하는', '▁에너', '지의', '▁변', '화를', '▁연구', '하는', '▁자연', '과', '학의', '▁한', '▁분야', '이다', '.', '▁물리', '학', '도', '▁역시', '▁물질', '을', '▁다루', '는', '▁학', '문', '이지만', ',', '▁물리', '학', '이', '▁원', '소', '와', '▁화', '합', '물을', '▁모두', '▁포함한', '▁물', '체의', '▁운동', '과', '▁에너', '지', ',', '▁열', '적', '·', '전', '기', '적', '·', '광', '학적', '·', '기', '계', '적', '▁속', '성을', '▁다루', '고', '▁이러한', '▁현', '상', '으로부터', '▁통일', '된', '▁이론', '을', '▁구축', '하려는', '▁것', '과는', '▁달리', '▁화학', '에서는', '▁물질', '▁자', '체를', '▁연구', '▁대상으로', '▁한다', '.', '▁화학', '은', '▁이미', '▁존재', '하는', '▁물질', '을', '▁이용하여', '▁특', '정한', '▁목', '적', '에', '▁맞', '는', '▁새로운', '▁물질', '을', '▁합', '성', '하는', '▁길', '을', '▁제공', '하며', ',', '▁이는', '▁농', '작', '물의', '▁증', '산', ',', '▁질', '병', '의', '▁치료', '▁및', '▁예', '방', ',', '▁에너', '지', '▁효', '율', '▁증', '대', ',', '▁환경', '오', '염', '▁감소', '▁등', '▁여러', '▁가지', '▁이', '점을', '▁제공', '한다', '.']\n",
            "['▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '해', '낸', '▁화', '합', '물을', '▁뜻', '하였으나', '▁지금', '은', '▁유', '기', '▁화', '합', '물의', '▁범', '위가', '▁크게', '▁넓', '어져', '▁탄', '소', '▁사', '슬', '▁또는', '▁탄', '소', '▁고', '리를', '▁가진', '▁모든', '▁화', '합', '물을', '▁뜻', '한다', '.', '▁유', '기', '화', '학의', '▁오', '랜', '▁관', '심', '사는', '▁유', '기', '▁화', '합', '물의', '▁합', '성', '▁메', '커', '니', '즘', '이다', '.', '▁현', '대에', '▁들어', '서', '▁핵', '자', '기', '▁공', '명', '법', '과', '▁X', '선', '▁결정', '학', '▁등이', '▁개발', '되어', '▁유', '기', '▁화', '합', '물', '▁분석', '에', '▁있어서', '▁매우', '▁중요한', '▁방법', '으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전체 전처리 과정을 거쳐 최종적으로 만들어지는 BERT pretrain 데이터셋 생성 메소드는 다음과 같습니다."
      ],
      "metadata": {
        "id": "JnXUSlkQ-La7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_pretrain_data(vocab, in_file, out_file, n_seq, mask_prob=0.15):\n",
        "    \"\"\" pretrain 데이터 생성 \"\"\"\n",
        "    def save_pretrain_instances(out_f, doc):\n",
        "        instances = create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list)\n",
        "        for instance in instances:\n",
        "            # dumps() : 파이썬 객체를 json문자열로 변환\n",
        "            out_f.write(json.dumps(instance, ensure_ascii=False))\n",
        "            out_f.write(\"\\n\")\n",
        "\n",
        "    # 특수문자 7개를 제외한 vocab_list 생성\n",
        "    vocab_list = []\n",
        "    for id in range(7, len(vocab)):\n",
        "        # 생성되는 단어 목록이 unknown인 경우는 제거합니다.\n",
        "        if not vocab.is_unknown(id):         \n",
        "            vocab_list.append(vocab.id_to_piece(id))\n",
        "\n",
        "    # line count 확인\n",
        "    line_cnt = 0\n",
        "    with open(in_file, \"r\") as in_f:\n",
        "        for line in in_f:\n",
        "            line_cnt += 1\n",
        "\n",
        "    with open(in_file, \"r\") as in_f:\n",
        "        with open(out_file, \"w\") as out_f:\n",
        "            doc = []\n",
        "            for line in tqdm(in_f, total=line_cnt):\n",
        "                line = line.strip()\n",
        "                if line == \"\":  # line이 빈줄 일 경우 (새로운 단락)\n",
        "                    if 0 < len(doc):\n",
        "                        save_pretrain_instances(out_f, doc)\n",
        "                        doc = []\n",
        "                else:  # line이 빈줄이 아닐 경우 tokenize 해서 doc에 저장\n",
        "                    pieces = vocab.encode_as_pieces(line)\n",
        "                    if 0 < len(pieces):\n",
        "                        doc.append(pieces)\n",
        "            if 0 < len(doc):  # 마지막에 처리되지 않은 doc가 있는 경우\n",
        "                save_pretrain_instances(out_f, doc)\n",
        "                doc = []"
      ],
      "metadata": {
        "id": "dLEAJSRP-Ofm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 약 400만 라인에 해당하는 전체 코퍼스에 대해 make_pretrain_data()를 구동해 봅시다.\n",
        "\n",
        "최종적으로 생성된 데이터셋은 json 포맷으로 저장될 것입니다."
      ],
      "metadata": {
        "id": "GL8kVexTAr5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrain_json_path = '/content/drive/MyDrive/GoingDeeper_Data/GD7/bert_pre_train.json'\n",
        "\n",
        "make_pretrain_data(vocab, corpus_file, pretrain_json_path, 128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3cd4ecc26e02414baa6e0c36c83ce875",
            "2b58a6f5c8734ec3bcdc01921926a165",
            "8e1f536eb63348f4b98438347c6c552f",
            "a61c73f103d24deb8296e8892be37f9d",
            "6d6e0cf259bc40ff8956f508adfb5148",
            "651dbf38769f48668d0c40fee1bc7d6d",
            "18066af69a9b4593991a6da38565cae4",
            "785af7f766da4e569dd45cc0b74b3c6d",
            "96aace07c4f44121b3b40f0e0119382c",
            "9d1597060f6e4243863bb9d183a87606",
            "9fec43aad3f64b219a1cc4a3c6c1eee9"
          ]
        },
        "id": "seIf2pDrAtcS",
        "outputId": "c487c869-1845-4196-bb22-cc762838e213"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3957761 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3cd4ecc26e02414baa6e0c36c83ce875"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라인수\n",
        "total = 0\n",
        "with open(pretrain_json_path, \"r\") as f:\n",
        "    for line in f:\n",
        "        total += 1\n",
        "total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThKIRICTBuXi",
        "outputId": "ca91d989-38fa-4d76-b117-7a4ece9ab37a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "918189"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 파일을 만드는 것까지 수행되었습니다.\n",
        "\n",
        "하지만 여기서 고려해야 할 점이 있습니다. 우리가 다루어야 할 데이터셋은 사이즈가 큽니다. 만들어질 json 데이터파일의 크기가 1.4GB 정도 됩니다.\n",
        " 실제 BERT 학습용의 백 분의 일 사이즈 정도밖에 안 되겠지만 그럼에도 불구하고 이렇게 큰 파일을 로딩하는 함수를 만들 때는 메모리 사용량과 관련해 고려해야 할 점이 있습니다.\n",
        "\n",
        "그래서 우리는 np.memmap을 사용해서 메모리 사용량을 최소화하는 방법을 시도해 볼 것입니다."
      ],
      "metadata": {
        "id": "UfIbpTv8G9np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_seq = 128\n",
        "# [CLS], tokens_a, [SEP], tokens_b, [SEP]\n",
        "max_seq = n_seq - 3\n",
        "\n",
        "# 만약 일반적인 Numpy Array에다 데이터를 로딩한다면 이렇게 되겠지만\n",
        "# enc_tokens = np.zeros((total, n_seq), np.int32)\n",
        "# dec_tokens = np.zeros((total, n_seq), np.int32)\n",
        "# labels_nsp = np.zeros((total,), np.int32)\n",
        "# labels_mlm = np.zeros((total, n_seq), np.int32)\n",
        "\n",
        "# np.memmap을 사용하면 메모리를 적은 메모리에서도 대용량 데이터 처리가 가능 함\n",
        "enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
        "segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
        "labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
        "labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
        "\n",
        "\n",
        "enc_tokens[0], enc_tokens[-1], segments[0], segments[-1], labels_nsp[0], labels_nsp[-1], labels_mlm[0], labels_mlm[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGyo3nMfHD0C",
        "outputId": "04955ba5-bf72-4063-962a-3a0d0fe8cf07"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
              " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
              " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
              " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
              " 0,\n",
              " 0,\n",
              " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
              " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "만들어진 json 파일을 라인 단위로 읽어 들여 np.memmap에 로딩해 봅시다."
      ],
      "metadata": {
        "id": "9wxpse5sJqgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라인 단위로 처리\n",
        "with open(pretrain_json_path, \"r\") as f:\n",
        "    for i, line in enumerate(tqdm(f, total=total)):\n",
        "        if 3 < i:  # 테스트를 위해서 3개만 확인\n",
        "            break\n",
        "        data = json.loads(line)\n",
        "        # encoder token\n",
        "        enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
        "        enc_token += [0] * (n_seq - len(enc_token))\n",
        "        # segment\n",
        "        segment = data[\"segment\"]\n",
        "        segment += [0] * (n_seq - len(segment))\n",
        "        # nsp label\n",
        "        label_nsp = data[\"is_next\"]\n",
        "        # mlm label\n",
        "        mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
        "        mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
        "        label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
        "        label_mlm[mask_idx] = mask_label\n",
        "\n",
        "        print(data)\n",
        "        print(\"enc_token:\", enc_token)\n",
        "        print(\"segment:\", segment)\n",
        "        print(\"label_nsp:\", label_nsp)\n",
        "        print(\"label_mlm:\", label_mlm)\n",
        "        print()\n",
        "\n",
        "        assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
        "\n",
        "        enc_tokens[i] = enc_token\n",
        "        segments[i] = segment\n",
        "        labels_nsp[i] = label_nsp\n",
        "        labels_mlm[i] = label_mlm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "919092081b584a07b1050f63cf716943",
            "28d933d81d384d4aa9575f85783be8a2",
            "36a78dfed5964b08a0b10de0ce0ff094",
            "8b7ebb845a994a508261f3203f58811b",
            "4b1496e0793549138773a1bcb86411cf",
            "45f80b4a401241c292a8239771b8f4f6",
            "33e6ce5de612478a86d27b821a8764df",
            "68389c5f9815477a8595b720e1a7f2c7",
            "6f720bf5ac7140c582b915c6e028c1e4",
            "01fe25cf417e47e0907981e2dc4322d3",
            "73e496bfaa6b43c2821849f6bc5d545a"
          ]
        },
        "id": "EpBnoW9KJq7W",
        "outputId": "a740fb29-3ba3-4a9a-e690-43014c4e8555"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/918189 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "919092081b584a07b1050f63cf716943"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tokens': ['[CLS]', '▁지', '미', '▁카', '터', '[SEP]', '▁제임스', '▁얼', '▁\"', '지', '미', '\"', '▁카', '터', '▁주', '니어', '(,', '[MASK]', '[MASK]', '[MASK]', '▁10', '월', '▁1', '일', '▁~', '▁)', '는', '[MASK]', '[MASK]', '▁출신', '▁미국', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁(19', '7', '7', '년', '▁~', '▁1981', '년', ')', '이다', '.', '▁지', '미', '▁카', '터', '는', '▁조지', '아', '주', '▁섬', '터', '[MASK]', '[MASK]', '▁플', '레', '인', '스', '▁마을', '에서', '▁태어났다', '.', '▁조지', '아', '▁공', '과', '대학교', '를', '▁졸업', '하였다', '.', '▁그', '▁후', '▁해', '군에', '▁들어가', '▁전', '함', '·', '원', '자', '력', '·', '잠', '수', '함', '의', '▁승', '무', '원으로', '▁일', '하였다', '.', '▁195', '3', '년', '[MASK]', '▁해군', '[MASK]', '[MASK]', '▁예', '편', '하였고', '▁이후', '▁땅', '콩', '·', '면', '화', '▁등을', '▁가', '꿔', '▁많은', '▁돈', '을', '[MASK]', '[MASK]', '[MASK]', '▁그의', '▁별', '명이', '▁\"', '땅', '콩', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [17, 18, 19, 27, 28, 31, 32, 33, 34, 39, 55, 56, 99, 101, 102, 118, 119, 120], 'mask_label': ['▁192', '4', '년', '▁민주', '당', '▁3', '9', '번째', '▁대통령', '▁~', '▁카운', '티', '▁미국', '▁대', '위로', '▁벌', '었다', '.']}\n",
            "enc_token: [5, 18, 3686, 207, 3714, 4, 3324, 1042, 103, 3610, 3686, 3718, 207, 3714, 37, 3418, 416, 6, 6, 6, 131, 3662, 7, 3629, 203, 241, 3602, 6, 6, 788, 243, 6, 6, 6, 6, 1647, 3682, 3682, 3625, 203, 3008, 3625, 3616, 16, 3599, 18, 3686, 207, 3714, 3602, 1755, 3630, 3646, 630, 3714, 6, 6, 429, 3740, 3628, 3626, 1369, 10, 1605, 3599, 1755, 3630, 41, 3644, 830, 3624, 1135, 52, 3599, 13, 81, 87, 1501, 2247, 25, 3779, 3873, 3667, 3631, 3813, 3873, 4196, 3636, 3779, 3601, 249, 3725, 1232, 33, 52, 3599, 479, 3652, 3625, 6, 2780, 6, 6, 168, 3877, 414, 165, 1697, 4290, 3873, 3703, 3683, 593, 21, 5007, 399, 1927, 3607, 6, 6, 6, 307, 587, 931, 103, 4313, 4290, 4]\n",
            "segment: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "label_nsp: 1\n",
            "label_mlm: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0  810 3666 3625    0    0    0    0    0    0    0 1114\n",
            " 3724    0    0   49 3632  796  663    0    0    0    0  203    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0 3565\n",
            " 3835    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0  243    0   14 1509    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0  813   17 3599    0    0    0    0    0\n",
            "    0    0]\n",
            "\n",
            "{'tokens': ['[CLS]', '▁1976', '년', '[MASK]', '▁선거', '에', '▁민주', '당', '▁후보', '로', '▁출', '마', '하여', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁포', '드를', '▁누', '르고', '▁당선', '되었다', '.', '[SEP]', '▁196', '2', '년', '▁조지', '아', '▁주', '▁상', '원', '▁의원', '[MASK]', '[MASK]', '▁낙', '선', '하나', '▁그', '[MASK]', '[MASK]', '▁부정', '선거', '▁', '였', '음을', '▁입', '증', '하게', '▁되어', '▁당선', '되고', ',', '▁196', '6', '년', '▁조지', '아', '▁주', '▁지', '사', '▁선거', '에', '▁낙', '선', '하지만', '▁1970', '년', '▁조지', '아', '[MASK]', '▁지', '사를', '▁역임', '했다', '.', '▁대통령', '이', '▁되', '기', '▁전', '▁조지', '아', '주', '▁상', '원의', '원을', '▁두', '번', '▁연', '임', '했으며', ',', '▁1971', '년부터', '▁1975', '년까지', '▁조지', '아', '▁지', '사로', '▁근무', '했다', '.', '▁조지', '아', '▁주', '지', '사로', '▁지', '내', '면서', ',', '▁미국', '에', '▁사는', '▁흑', '인', '▁등', '용', '법을', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [3, 13, 14, 15, 16, 17, 18, 19, 20, 21, 39, 40, 45, 46, 76, 79, 80, 81], 'mask_label': ['▁대통령', '▁도', '덕', '주의', '▁정책', '으로', '▁내', '세', '워', ',', '▁선거', '에서', '▁선거', '가', '▁주', '▁역임', '했다', '.']}\n",
            "enc_token: [5, 3306, 3625, 6, 822, 3600, 1114, 3724, 958, 3603, 117, 3674, 54, 6, 6, 6, 6, 6, 6, 6, 6, 6, 119, 1486, 807, 2056, 2387, 43, 3599, 4, 386, 3619, 3625, 1755, 3630, 37, 76, 3667, 2378, 6, 6, 1567, 3668, 3294, 13, 6, 6, 2386, 2163, 3596, 3671, 969, 213, 3929, 173, 607, 2387, 317, 3604, 386, 3673, 3625, 1755, 3630, 37, 18, 3620, 822, 3600, 1567, 3668, 1447, 1921, 3625, 1755, 3630, 6, 18, 451, 1398, 31, 3599, 663, 3597, 450, 3614, 25, 1755, 3630, 3646, 76, 955, 928, 157, 3821, 61, 3773, 530, 3604, 3372, 523, 3409, 673, 1755, 3630, 18, 982, 2711, 31, 3599, 1755, 3630, 37, 3610, 982, 18, 3754, 151, 3604, 243, 3600, 3554, 1733, 3628, 50, 3717, 2046, 4]\n",
            "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "label_nsp: 0\n",
            "label_mlm: [   0    0    0  663    0    0    0    0    0    0    0    0    0   75\n",
            " 4089  238 1421    9  114 3692 3964 3604    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0  822   10    0\n",
            "    0    0    0  822 3608    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0   37    0    0 1398   31 3599    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "\n",
            "{'tokens': ['[CLS]', '球', '峯', '▁간의', '▁평화', '조', '약', '으로', '[MASK]', '[MASK]', '[MASK]', '▁또한', '▁소련', '과', '▁제', '2', '차', '▁전략', '▁무', '기', '▁제한', '▁협', '상에', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁카', '터', '는', '▁1970', '년대', '▁후반', '▁당시', '▁대한민국', '▁등', '▁인', '권', '▁후', '진', '국의', '▁국민', '들의', '▁인', '권을', '▁지', '키', '기', '▁위해', '▁노력', '했으며', ',', '▁취임', '▁이후', '▁계속', '해서', '▁도', '덕', '정', '치를', '▁내', '세', '웠다', '.', '[SEP]', '▁카', '터', '▁대통령', '은', '▁에너', '지', '▁개발', '을', '[MASK]', '[MASK]', '[MASK]', '▁공', '화', '당의', '▁반', '대로', '▁무', '산', '되었다', '.', '▁카', '터', '는', '▁이집', '트', '와', '▁이스라엘', '을', '▁조정', '하여', ',', '▁캠', '프', '▁데이', '비', '드에서', '▁안', '와', '르', '▁사', '다', '트', '▁대통령', '과', '[MASK]', '[MASK]', '[MASK]', '▁베', '긴', '▁수상', '과', '▁함께', '▁중', '동', '▁평', '화를', '▁위한', '▁캠', '프', '데', '이', '비', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [1, 2, 8, 9, 10, 21, 22, 23, 24, 25, 26, 48, 73, 74, 75, 109, 110, 111], 'mask_label': ['▁양', '국', '▁이끌', '어졌다', '.', '▁협', '상에', '▁조', '인', '했다', '.', '▁위해', '▁촉', '구', '했으나', '▁메', '나', '헴']}\n",
            "enc_token: [5, 5651, 6307, 2714, 2793, 3676, 3827, 9, 6, 6, 6, 276, 1302, 3644, 30, 3619, 3751, 2835, 107, 3614, 1956, 617, 1824, 6, 6, 6, 6, 207, 3714, 3602, 1921, 596, 1840, 316, 410, 50, 42, 3830, 81, 3713, 137, 968, 247, 42, 917, 18, 3793, 3614, 231, 3375, 530, 3604, 2659, 165, 785, 874, 75, 4089, 3642, 1233, 114, 3692, 1853, 3599, 4, 207, 3714, 663, 3613, 1778, 3610, 570, 3607, 6, 6, 6, 41, 3683, 1547, 141, 448, 107, 3726, 43, 3599, 207, 3714, 3602, 2703, 3677, 3665, 3426, 3607, 3358, 54, 3604, 2432, 3721, 965, 3694, 3552, 172, 3665, 3699, 15, 3598, 3677, 663, 3644, 6, 6, 6, 271, 4099, 1011, 3644, 280, 35, 3658, 232, 934, 521, 2432, 3721, 3736, 3597, 3694, 4]\n",
            "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "label_nsp: 0\n",
            "label_mlm: [   0  230 3643    0    0    0    0    0 1435 2521 3599    0    0    0\n",
            "    0    0    0    0    0    0    0  617 1824   53 3628   31 3599    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0  231    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0 2270 3653 1003    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0  334 3637 5887\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "\n",
            "{'tokens': ['[CLS]', '질', '▁구', '출', '[MASK]', '[MASK]', '▁이유로', '▁1980', '년', '▁대통령', '첩', '욤', '▁공', '화', '당의', '▁로', '널', '드', '▁레이', '건', '[MASK]', '[MASK]', '▁', '져', '▁결국', '▁재', '선에', '▁실패', '했다', '.', '▁또한', 'Κ', '▁일', '[MASK]', '[MASK]', '▁터', '진', '▁소련', '의', '▁아', '프가', '니', '스탄', '▁침공', '▁사건', '으로', '▁인해', '▁1980', '년', '▁하계', '▁올림픽', '에', '▁반', '공', '국', '가', '들의', '▁보이', '콧', '을', '▁내', '세', '웠다', '.', '[SEP]', '▁지', '미', '▁카', '터', '는', '▁대한민국', '과의', '▁관계', '에서도', '▁중요한', '▁영향을', '▁미', '쳤', '던', '▁대통령', '▁중', '▁하나', '다', '.', '▁인', '권', '▁문제', '와', '▁주', '한', '미', '군', '▁철', '수', '▁문제', '로', '[MASK]', '▁한', '미', '▁관계', '가', '▁불', '편', '하기도', '▁했다', '.', '▁1978', '년', '▁대한민국', '에', '[MASK]', '▁북한', '의', '▁위협', '에', '▁대', '비', '해', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁창설', '하면서', ',', '卷', '射', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [4, 5, 10, 11, 20, 21, 31, 32, 33, 34, 96, 110, 118, 119, 120, 121, 125, 126], 'mask_label': ['▁실패', '를', '▁선거', '에서', '▁후보', '에게', '▁임', '기', '▁말', '기에', '▁한때', '▁대한', '▁한', '미', '연합', '사를', '▁1982', '년까지']}\n",
            "enc_token: [5, 3892, 73, 3771, 6, 6, 1827, 1640, 3625, 663, 4459, 5705, 41, 3683, 1547, 194, 4044, 3681, 1169, 3803, 6, 6, 3596, 3944, 875, 174, 2087, 1579, 31, 3599, 276, 7190, 33, 6, 6, 870, 3713, 1302, 3601, 26, 2986, 3733, 1323, 3232, 636, 9, 751, 1640, 3625, 2219, 779, 3600, 141, 3670, 3643, 3608, 247, 3052, 4805, 3607, 114, 3692, 1853, 3599, 4, 18, 3686, 207, 3714, 3602, 410, 786, 704, 643, 1165, 1063, 55, 4219, 3781, 663, 35, 324, 3598, 3599, 42, 3830, 550, 3665, 37, 3612, 3686, 3722, 380, 3636, 550, 3603, 6, 34, 3686, 704, 3608, 128, 3877, 863, 345, 3599, 3331, 3625, 410, 3600, 6, 1876, 3601, 3038, 3600, 14, 3694, 3645, 6, 6, 6, 6, 3574, 421, 3604, 5840, 5699, 4]\n",
            "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "label_nsp: 1\n",
            "label_mlm: [   0    0    0    0 1579 3624    0    0    0    0  822   10    0    0\n",
            "    0    0    0    0    0    0  958  113    0    0    0    0    0    0\n",
            "    0    0    0  273 3614  150  329    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0 3590    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0   92    0\n",
            "    0    0    0    0    0    0   34 3686 2569  451    0    0    0 2760\n",
            "  673    0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "np.memmap을 사용해 메모리 효율적으로 만들어진 데이터를 로딩하는 함수를 아래와 같이 구성하였습니다."
      ],
      "metadata": {
        "id": "-5xbPp9SKYb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pre_train_data(vocab, filename, n_seq, count=None):\n",
        "    \"\"\"\n",
        "    학습에 필요한 데이터를 로드\n",
        "    :param vocab: vocab\n",
        "    :param filename: 전처리된 json 파일\n",
        "    :param n_seq: 시퀀스 길이 (number of sequence)\n",
        "    :param count: 데이터 수 제한 (None이면 전체)\n",
        "    :return enc_tokens: encoder inputs\n",
        "    :return segments: segment inputs\n",
        "    :return labels_nsp: nsp labels\n",
        "    :return labels_mlm: mlm labels\n",
        "    \"\"\"\n",
        "    total = 0\n",
        "    with open(filename, \"r\") as f:\n",
        "        for line in f:\n",
        "            total += 1\n",
        "            # 데이터 수 제한\n",
        "            if count is not None and count <= total:\n",
        "                break\n",
        "    \n",
        "    # np.memmap을 사용하면 메모리를 적은 메모리에서도 대용량 데이터 처리가 가능 함\n",
        "    enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
        "    segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
        "    labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
        "    labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
        "\n",
        "    with open(filename, \"r\") as f:\n",
        "        for i, line in enumerate(tqdm(f, total=total)):\n",
        "            if total <= i:\n",
        "                print(\"data load early stop\", total, i)\n",
        "                break\n",
        "            data = json.loads(line)\n",
        "            # encoder token\n",
        "            enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
        "            enc_token += [0] * (n_seq - len(enc_token))\n",
        "            # segment\n",
        "            segment = data[\"segment\"]\n",
        "            segment += [0] * (n_seq - len(segment))\n",
        "            # nsp label\n",
        "            label_nsp = data[\"is_next\"]\n",
        "            # mlm label\n",
        "            mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
        "            mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
        "            label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
        "            label_mlm[mask_idx] = mask_label\n",
        "\n",
        "            assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
        "\n",
        "            enc_tokens[i] = enc_token\n",
        "            segments[i] = segment\n",
        "            labels_nsp[i] = label_nsp\n",
        "            labels_mlm[i] = label_mlm\n",
        "\n",
        "    return (enc_tokens, segments), (labels_nsp, labels_mlm)"
      ],
      "metadata": {
        "id": "l2whZMBlKZFQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 128000건만 메모리에 로딩\n",
        "pre_train_inputs, pre_train_labels = load_pre_train_data(vocab, pretrain_json_path, 128, count=128000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184,
          "referenced_widgets": [
            "a78be1bc7a7047dfaf89becc20ebd051",
            "ba24f7ec10524ede8176e9888dacedce",
            "265e9b73a845476c911314491f3c4169",
            "9959c4a8695b497db49385f2a3c7d39a",
            "26ddecdfc4ba49aea64a638ff89228cc",
            "2aa65246b2f04ac2a14dd3a87d4d52c2",
            "0a773e109b0d4289a5214e0467105728",
            "603fde6f24394a87bfa249333f156491",
            "a289d475f1974902b7fa49110cd08203",
            "a0ec543d55574527808bc94d307fa9cf",
            "06edb7fd7e1a4bdf8e70857e459a00c6"
          ]
        },
        "id": "LATqXaIEKgWH",
        "outputId": "b0a525c9-d6bd-4788-a064-7ccce7179bff"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/128000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a78be1bc7a7047dfaf89becc20ebd051"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data load early stop 128000 128000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 처음과 마지막 확인\n",
        "pre_train_inputs[0][0], pre_train_inputs[0][-1], pre_train_inputs[1][0], pre_train_inputs[1][-1], pre_train_labels[0][0], pre_train_labels[0][-1], pre_train_labels[1][0], pre_train_labels[1][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63OL0i91Kkja",
        "outputId": "47d3f67f-137a-4c80-c9fb-75f0a1278e1b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(memmap([   5,   18, 3686,  207, 3714,    4, 3324, 1042,  103, 3610, 3686,\n",
              "         3718,  207, 3714,   37, 3418,  416,    6,    6,    6,  131, 3662,\n",
              "            7, 3629,  203,  241, 3602,    6,    6,  788,  243,    6,    6,\n",
              "            6,    6, 1647, 3682, 3682, 3625,  203, 3008, 3625, 3616,   16,\n",
              "         3599,   18, 3686,  207, 3714, 3602, 1755, 3630, 3646,  630, 3714,\n",
              "            6,    6,  429, 3740, 3628, 3626, 1369,   10, 1605, 3599, 1755,\n",
              "         3630,   41, 3644,  830, 3624, 1135,   52, 3599,   13,   81,   87,\n",
              "         1501, 2247,   25, 3779, 3873, 3667, 3631, 3813, 3873, 4196, 3636,\n",
              "         3779, 3601,  249, 3725, 1232,   33,   52, 3599,  479, 3652, 3625,\n",
              "            6, 2780,    6,    6,  168, 3877,  414,  165, 1697, 4290, 3873,\n",
              "         3703, 3683,  593,   21, 5007,  399, 1927, 3607,    6,    6,    6,\n",
              "          307,  587,  931,  103, 4313, 4290,    4], dtype=int32),\n",
              " memmap([   5, 3676,  848, 3784, 1931,   58, 3676,  416, 2316, 3619, 3625,\n",
              "         3617, 3744, 4335,   12, 3625, 3616,  175, 3662,    7, 3629,  203,\n",
              "            6,    6,    6,    6,    6,    6,  143, 3625, 3616,  131, 3662,\n",
              "          342, 3629, 3616, 3602,  176,  334,  829, 1115, 3665,    6,    6,\n",
              "         3451, 1633,  375,  671, 1644, 3608,  547, 3423,  765,  815, 3604,\n",
              "            6,    6,    6, 2375, 3608, 3604,  532, 2589, 3599,    4,  307,\n",
              "          323,    6,  321, 3611,  622,  122, 3725, 3620, 3627, 3837, 3608,\n",
              "            6,  176,  268, 4082,   94,  567, 4014, 3617, 7474, 3616, 3830,\n",
              "           66, 3590,  307,  192, 1272,  158, 3788,  353, 3599,  202,  316,\n",
              "         3600,  176,   10,  323,  476, 3663, 1329,  605,  238, 3631, 2470,\n",
              "         3604, 1939,  106, 3627,   13,    6,    6, 1128,   48,    6,    6,\n",
              "          848, 3784, 3833,    8, 3637, 2263,    4], dtype=int32),\n",
              " memmap([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
              " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
              " 1,\n",
              " 1,\n",
              " memmap([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,  810, 3666, 3625,    0,    0,\n",
              "            0,    0,    0,    0,    0, 1114, 3724,    0,    0,   49, 3632,\n",
              "          796,  663,    0,    0,    0,    0,  203,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "         3565, 3835,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          243,    0,   14, 1509,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,  813,   17, 3599,\n",
              "            0,    0,    0,    0,    0,    0,    0], dtype=int32),\n",
              " memmap([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          578, 3652, 3625, 3617, 4148, 3665,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0, 1381, 4148,\n",
              "         3451,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          752, 3608, 3604,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0, 2143,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          347,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,  162,  490,    0,    0,   28, 3599,\n",
              "            0,    0,    0,    0,    0,    0,    0], dtype=int32))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step6. BERT 모델 구현**\n",
        "이제 본격적으로 BERT model을 구현해 보겠습니다.\n",
        "\n",
        "우선 몇 가지 유틸리티 함수를 정의하겠습니다."
      ],
      "metadata": {
        "id": "S2hJ4ujNK16q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pad_mask(tokens, i_pad=0):\n",
        "    \"\"\"\n",
        "    pad mask 계산하는 함수\n",
        "    :param tokens: tokens (bs, n_seq)\n",
        "    :param i_pad: id of pad\n",
        "    :return mask: pad mask (pad: 1, other: 0)\n",
        "    \"\"\"\n",
        "    mask = tf.cast(tf.math.equal(tokens, i_pad), tf.float32)\n",
        "    mask = tf.expand_dims(mask, axis=1)\n",
        "    return mask\n",
        "\n",
        "\n",
        "def get_ahead_mask(tokens, i_pad=0):\n",
        "    \"\"\"\n",
        "    ahead mask 계산하는 함수\n",
        "    :param tokens: tokens (bs, n_seq)\n",
        "    :param i_pad: id of pad\n",
        "    :return mask: ahead and pad mask (ahead or pad: 1, other: 0)\n",
        "    \"\"\"\n",
        "    n_seq = tf.shape(tokens)[1]\n",
        "    # band_part() : 삼각행렬 생성\n",
        "    ahead_mask = 1 - tf.linalg.band_part(tf.ones((n_seq, n_seq)), -1, 0)\n",
        "    ahead_mask = tf.expand_dims(ahead_mask, axis=0)\n",
        "    pad_mask = get_pad_mask(tokens, i_pad)\n",
        "    mask = tf.maximum(ahead_mask, pad_mask)\n",
        "    return mask"
      ],
      "metadata": {
        "id": "yl2SU1e1Lm_h"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서는 ReLU가 아닌 GELU를 사용하겠습니다. 일반적으로 GELU는 ReLU나 ELU보다 성능이 좋다고 합니다. "
      ],
      "metadata": {
        "id": "sbUw-KvSNOzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function(experimental_relax_shapes=True)\n",
        "def gelu(x):\n",
        "    \"\"\"\n",
        "    gelu activation 함수\n",
        "    :param x: 입력 값\n",
        "    :return: gelu activation result\n",
        "    \"\"\"\n",
        "    return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))"
      ],
      "metadata": {
        "id": "4HRq6assNNGW"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kernel_initializer(stddev=0.02):\n",
        "    \"\"\"\n",
        "    parameter initializer 생성\n",
        "    :param stddev: 생성할 랜덤 변수의 표준편차\n",
        "    \"\"\"\n",
        "    # 평균=0,표준편차 분포로 랜덤 수 생성, 평균으로부터 2표준편차이상은 제거\n",
        "    return tf.keras.initializers.TruncatedNormal(stddev=stddev)\n",
        "\n",
        "\n",
        "def bias_initializer():\n",
        "    \"\"\"\n",
        "    bias initializer 생성\n",
        "    \"\"\"\n",
        "    # 원하는 shape으로 0배열을 만들어줌\n",
        "    return tf.zeros_initializer"
      ],
      "metadata": {
        "id": "KWOIkc3lNZhU"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Config(dict):\n",
        "    \"\"\"\n",
        "    json을 config 형태로 사용하기 위한 Class\n",
        "    :param dict: config dictionary\n",
        "    \"\"\"\n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        \"\"\"\n",
        "        file에서 Config를 생성 함\n",
        "        :param file: filename\n",
        "        \"\"\"\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ],
      "metadata": {
        "id": "XnPpuMPqOvvY"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 본격적으로 embedding 레이어를 쌓아나가겠습니다.\n",
        "## **1.Token Embedding**"
      ],
      "metadata": {
        "id": "7YxkhRKtPFh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SharedEmbedding(tf.keras.layers.Layer):\n",
        "    \n",
        "    def __init__(self, config, name=\"weight_shared_embedding\"):\n",
        "        super().__init__(name=name)\n",
        "        self.n_vocab = config.n_vocab\n",
        "        self.d_model = config.d_model\n",
        "    # tf.name_scope : 컨택스트 매니저, 연산을 실행할때 이름설정\n",
        "    def build(self, input_shape):\n",
        "        with tf.name_scope(\"shared_embedding_weight\"):\n",
        "            self.shared_weights =\\\n",
        "            self.add_weight(\"weights\",\n",
        "                            shape=[self.n_vocab, self.d_model],\n",
        "                            initializer=kernel_initializer()\n",
        "                            )\n",
        "\n",
        "    def call(self, inputs, mode=\"embedding\"):\n",
        "        # mode가 embedding일 경우 embedding lookup 실행\n",
        "        if mode == \"embedding\":\n",
        "            return self._embedding(inputs)\n",
        "        # mode가 linear일 경우 linear 실행\n",
        "        elif mode == \"linear\":\n",
        "            return self._linear(inputs)\n",
        "        # mode가 기타일 경우 오류 발생\n",
        "        else:\n",
        "            raise ValueError(f\"mode {mode} is not valid.\")\n",
        "    \n",
        "    def _embedding(self, inputs):\n",
        "        # tf.gather(parmas, indices): parmas에서 indices에 해당하는 인덱스를 출력\n",
        "        # 슬라이싱과 유사\n",
        "        embed = tf.gather(self.shared_weights, tf.cast(inputs, tf.int32))\n",
        "        return embed\n",
        "\n",
        "    def _linear(self, inputs):  # (bs, n_seq, d_model)\n",
        "        \"\"\"\n",
        "        linear 실행\n",
        "        :param inputs: 입력\n",
        "        \"\"\"\n",
        "        n_batch = tf.shape(inputs)[0]\n",
        "        n_seq = tf.shape(inputs)[1]\n",
        "        # (bs * n_seq, d_model)로 차원 변경\n",
        "        inputs = tf.reshape(inputs, [-1, self.d_model])  \n",
        "        outputs = tf.matmul(inputs, self.shared_weights, transpose_b=True)\n",
        "         # (bs, n_seq, n_vocab)로 차원변경\n",
        "        outputs = tf.reshape(outputs, [n_batch, n_seq, self.n_vocab]) \n",
        "        return outputs"
      ],
      "metadata": {
        "id": "HLTTLpwMPKfo"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Position Embedding**\n",
        "Transformer이 사인 함수와 코사인 함수를 이용한 Positional Encoding을 통해 토큰의 상대적인 위치를 학습했던 것과 달리, BERT에서는 Position Embedding을 사용합니다. Position Embedding은 위치 정보가 담긴 임베딩 레이어를 하나 더 사용해 Position Embedding 벡터를 학습시켜서, BERT의 입력에 Position Embedding을 더해줍니다."
      ],
      "metadata": {
        "id": "SYivy343Iw5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, config, name=\"position_embedding\"):\n",
        "        super().__init__(name=name)\n",
        "        # embeddings_initializer() : 임베딩 초기설정\n",
        "        self.embedding = tf.keras.layers.Embedding(config.n_seq, config.d_model, embeddings_initializer=kernel_initializer())\n",
        "\n",
        "    def call(self, inputs):\n",
        "        position = tf.cast(tf.math.cumsum(tf.ones_like(inputs), axis=1, exclusive=True), tf.int32)\n",
        "        embed = self.embedding(position)\n",
        "        return embed"
      ],
      "metadata": {
        "id": "OGaGtlUUIwpe"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "상대적으로 매우 간단한 Segment Embedding은 별도의 레이어를 구현하지 않고 BERT 클래스에서 간단히 포함하도록 하겠습니다."
      ],
      "metadata": {
        "id": "GkJX9wjsN2zD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. ScaleDotProductAttention**"
      ],
      "metadata": {
        "id": "U8mK-WH7N52W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ScaleDotProductAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
        "        super().__init__(name=name)\n",
        "\n",
        "    def call(self, Q, K, V, attn_mask):\n",
        "        attn_score = tf.matmul(Q, K, transpose_b=True)\n",
        "        scale = tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32))\n",
        "        attn_scale = tf.math.divide(attn_score, scale)\n",
        "        attn_scale -= 1.e9 * attn_mask\n",
        "        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n",
        "        attn_out = tf.matmul(attn_prob, V)\n",
        "        return attn_out"
      ],
      "metadata": {
        "id": "GVfC4YDlN_mT"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. MultiHeadAttention**"
      ],
      "metadata": {
        "id": "_Ese3dn6OLxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, config, name=\"multi_head_attention\"):\n",
        "        # param config: Config 객체\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.d_model = config.d_model\n",
        "        self.n_head = config.n_head\n",
        "        self.d_head = config.d_head\n",
        "        self.W_Q = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "        self.W_K = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "        self.W_V = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n",
        "        self.W_O = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "\n",
        "    def call(self, Q, K, V, attn_mask):\n",
        "        batch_size = tf.shape(Q)[0]\n",
        "        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  \n",
        "        K_m = tf.transpose(tf.reshape(self.W_K(K), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  \n",
        "        V_m = tf.transpose(tf.reshape(self.W_V(V), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  \n",
        "        attn_mask_m = tf.expand_dims(attn_mask, axis=1)\n",
        "        attn_out = self.attention(Q_m, K_m, V_m, attn_mask_m)  # (bs, n_head, Q_len, d_head)\n",
        "        attn_out_m = tf.transpose(attn_out, perm=[0, 2, 1, 3])  # (bs, Q_len, n_head, d_head)\n",
        "        attn_out = tf.reshape(attn_out_m, [batch_size, -1, config.n_head * config.d_head])  # (bs, Q_len, d_model)\n",
        "        attn_out = self.W_O(attn_out) \n",
        "\n",
        "        return attn_out"
      ],
      "metadata": {
        "id": "Dr-lz3DuOQ19"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. PositionWiseFeedForward**"
      ],
      "metadata": {
        "id": "URzBG5kBO4VV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionWiseFeedForward(tf.keras.layers.Layer):\n",
        "    def __init__(self, config, name=\"feed_forward\"):\n",
        "        # param config: Config 객체\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.W_1 = tf.keras.layers.Dense(config.d_ff, activation=gelu, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "        self.W_2 = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "\n",
        "    def call(self, inputs):\n",
        "        ff_val = self.W_2(self.W_1(inputs))\n",
        "        return ff_val"
      ],
      "metadata": {
        "id": "TWbQiK66O8cI"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. EncoderLayer**"
      ],
      "metadata": {
        "id": "75tBZrmrPJbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, config, name=\"encoder_layer\"):\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.self_attention = MultiHeadAttention(config)\n",
        "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
        "        self.ffn = PositionWiseFeedForward(config)\n",
        "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
        "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
        " \n",
        "    def call(self, enc_embed, self_mask):\n",
        "        self_attn_val = self.self_attention(enc_embed, enc_embed, enc_embed, self_mask)\n",
        "        norm1_val = self.norm1(enc_embed + self.dropout(self_attn_val))\n",
        "        ffn_val = self.ffn(norm1_val)\n",
        "        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n",
        "\n",
        "        return enc_out"
      ],
      "metadata": {
        "id": "ZnB7IFbSPPN8"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7. BERT Layer**"
      ],
      "metadata": {
        "id": "wv0mszZeQHp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT(tf.keras.layers.Layer):\n",
        "    def __init__(self, config, name=\"bert\"):\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.i_pad = config.i_pad\n",
        "        self.embedding = SharedEmbedding(config)\n",
        "        self.position = PositionEmbedding(config)\n",
        "        self.segment = tf.keras.layers.Embedding(2, config.d_model, embeddings_initializer=kernel_initializer())\n",
        "        self.norm = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)       \n",
        "        self.encoder_layers = [EncoderLayer(config, name=f\"encoder_layer_{i}\") for i in range(config.n_layer)]\n",
        "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # param inputs: (enc_tokens, segments)\n",
        "        # return logits: dec_tokens에 대한 다음 토큰 예측 결과 logits\n",
        "        enc_tokens, segments = inputs\n",
        "        enc_self_mask = tf.keras.layers.Lambda(get_pad_mask, output_shape=(1, None), name='enc_self_mask')(enc_tokens, self.i_pad)\n",
        "\n",
        "        enc_embed = self.get_embedding(enc_tokens, segments)\n",
        "\n",
        "        enc_out = self.dropout(enc_embed)\n",
        "        for encoder_layer in self.encoder_layers:\n",
        "            enc_out = encoder_layer(enc_out, enc_self_mask)\n",
        "\n",
        "        logits_cls = enc_out[:,0]\n",
        "        logits_lm = self.embedding(enc_out, mode=\"linear\")\n",
        "        return logits_cls, logits_lm\n",
        "    \n",
        "    def get_embedding(self, tokens, segments):\n",
        "        embed = self.embedding(tokens) + self.position(tokens) + self.segment(segments)\n",
        "        embed = self.norm(embed)\n",
        "        return embed"
      ],
      "metadata": {
        "id": "Rjbtf1uvQMTk"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT 레이어를 바탕으로 최종적으로 만들어질 pretrain용 BERT 모델 구성은 아래와 같습니다."
      ],
      "metadata": {
        "id": "EeMWf2TfmvwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder Layer class 정의\n",
        "class PooledOutput(tf.keras.layers.Layer):\n",
        "    def __init__(self, config, n_output, name=\"pooled_output\"):\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.dense1 = tf.keras.layers.Dense(config.d_model, activation=tf.nn.tanh, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        "        self.dense2 = tf.keras.layers.Dense(n_output, use_bias=False, activation=tf.nn.softmax, name=\"nsp\", kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
        " \n",
        "    def call(self, inputs):\n",
        "        outputs = self.dense1(inputs)\n",
        "        outputs = self.dense2(outputs)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "5Os6M9hBmw7t"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_pre_train(config):\n",
        "    enc_tokens = tf.keras.layers.Input((None,), name=\"enc_tokens\")\n",
        "    segments = tf.keras.layers.Input((None,), name=\"segments\")\n",
        "\n",
        "    bert = BERT(config)\n",
        "    logits_cls, logits_lm = bert((enc_tokens, segments))\n",
        "\n",
        "    logits_cls = PooledOutput(config, 2, name=\"pooled_nsp\")(logits_cls)\n",
        "    outputs_nsp = tf.keras.layers.Softmax(name=\"nsp\")(logits_cls)\n",
        "\n",
        "    outputs_mlm = tf.keras.layers.Softmax(name=\"mlm\")(logits_lm)\n",
        "\n",
        "    model = tf.keras.Model(inputs=(enc_tokens, segments), outputs=(outputs_nsp, outputs_mlm))\n",
        "    return model"
      ],
      "metadata": {
        "id": "Y8CBhr7Om6EO"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아주 작은 pretrain용 BERT 모델(test_model)을 생성하여 동작을 확인해 보겠습니다."
      ],
      "metadata": {
        "id": "2VDL0aiTos5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = Config({\"d_model\": 256, \"n_head\": 4, \"d_head\": 64, \"dropout\": 0.1, \"d_ff\": 1024, \"layernorm_epsilon\": 0.001, \"n_layer\": 3, \"n_seq\": 256, \"n_vocab\": 0, \"i_pad\": 0})\n",
        "config.n_vocab = len(vocab)\n",
        "config.i_pad = vocab.pad_id()\n",
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD-KCi5Yoisp",
        "outputId": "8e13a16b-7567-4b54-8d3b-e31b7e6c0b22"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'d_model': 256,\n",
              " 'n_head': 4,\n",
              " 'd_head': 64,\n",
              " 'dropout': 0.1,\n",
              " 'd_ff': 1024,\n",
              " 'layernorm_epsilon': 0.001,\n",
              " 'n_layer': 3,\n",
              " 'n_seq': 256,\n",
              " 'n_vocab': 8007,\n",
              " 'i_pad': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_seq = 10\n",
        "\n",
        "# make test inputs\n",
        "enc_tokens = np.random.randint(0, len(vocab), (10, n_seq))\n",
        "segments = np.random.randint(0, 2, (10, n_seq))\n",
        "labels_nsp = np.random.randint(0, 2, (10,))\n",
        "labels_mlm = np.random.randint(0, len(vocab), (10, n_seq))\n",
        "\n",
        "test_model = build_model_pre_train(config)\n",
        "test_model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(), metrics=[\"acc\"])\n",
        "\n",
        "# test model fit\n",
        "test_model.fit((enc_tokens, segments), (labels_nsp, labels_mlm), epochs=2, batch_size=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHWP5J9molbJ",
        "outputId": "14fbb9ff-4d50-4770-9d49-e3b1c641dc53"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "2/2 [==============================] - 7s 16ms/step - loss: 9.7463 - nsp_loss: 0.7287 - mlm_loss: 9.0176 - nsp_acc: 0.3000 - mlm_acc: 0.0000e+00\n",
            "Epoch 2/2\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 8.5808 - nsp_loss: 0.6406 - mlm_loss: 7.9402 - nsp_acc: 0.8000 - mlm_acc: 0.0100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9162cfd790>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step7. pretrain 진행**\n",
        "1. loss와 accuracy같이 기본적으로 필요한 계산 함수를 미리 정의해 둡시다. \n",
        "2. 학습 데이터의 label이 정수로 변환되었으므로 loss 함수는 SparseCategoricalCrossentropy를 사용합니다. \n",
        "3. MLM task에 대해 더 잘 학습하도록 loss를 20배 증가시켜 줍니다."
      ],
      "metadata": {
        "id": "LrJiT38NpAdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lm_loss(y_true, y_pred):\n",
        "    # param y_true: 정답 (bs, n_seq)\n",
        "    # param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
        "    # loss 계산\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)(y_true, y_pred)\n",
        "    # pad(0) 인 부분 mask\n",
        "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=loss.dtype)\n",
        "    loss *= mask\n",
        "    return loss * 20  # mlm을 더 잘 학습하도록 20배 증가 시킴"
      ],
      "metadata": {
        "id": "wRgPQUbWpPL2"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lm_acc(y_true, y_pred):\n",
        "    #param y_true: 정답 (bs, n_seq)\n",
        "    #param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
        "    # 정답 여부 확인\n",
        "    y_pred_class = tf.cast(K.argmax(y_pred, axis=-1), tf.float32)\n",
        "    matches = tf.cast(K.equal(y_true, y_pred_class), tf.float32)\n",
        "    # pad(0) 인 부분 mask\n",
        "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=matches.dtype)\n",
        "    matches *= mask\n",
        "    # 정확도 계산\n",
        "    accuracy = K.sum(matches) / K.maximum(K.sum(mask), 1)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "MZ28uucBpfP8"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning Rate 스케줄링도 아래와 같이 구현합니다. WarmUp 이후 consine 형태로 감소하는 스케줄을 적용합니다.\n",
        "\n",
        "최근에는 Learning Rate를 단순히 감소시키기 보다는 진동하면서 최적점을 찾아가는 방식을 많이 사용하고 있습니다. 다양한 방법을 찾아서 적용시켜 보는 것도 성능을 높이는 좋은 방법입니다."
      ],
      "metadata": {
        "id": "NHYYXWblpz6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CosineSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, train_steps=4000, warmup_steps=2000, max_lr=2.5e-4):\n",
        "        #param train_steps: 학습 step 총 합\n",
        "        #param warmup_steps: warmup steps\n",
        "        #param max_lr: 최대 learning rate      \n",
        "        super().__init__()\n",
        "\n",
        "        assert 0 < warmup_steps < train_steps\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.train_steps = train_steps\n",
        "        self.max_lr = max_lr\n",
        "\n",
        "    def __call__(self, step_num):\n",
        "        #param step_num: 현재 step number\n",
        "        #retrun: 계산된 learning rate\n",
        "        state = tf.cast(step_num <= self.warmup_steps, tf.float32)\n",
        "        lr1 = tf.cast(step_num, tf.float32) / self.warmup_steps\n",
        "        progress = tf.cast(step_num - self.warmup_steps, tf.float32) / max(1, self.train_steps - self.warmup_steps)\n",
        "        lr2 = 0.5 * (1.0 + tf.math.cos(math.pi * progress))\n",
        "        return (state * lr1 + (1 - state) * lr2) * self.max_lr"
      ],
      "metadata": {
        "id": "QwmkBQfWp1vN"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute lr \n",
        "test_schedule = CosineSchedule(train_steps=4000, warmup_steps=500)\n",
        "lrs = []\n",
        "for step_num in range(4000):\n",
        "    lrs.append(test_schedule(float(step_num)).numpy())\n",
        "\n",
        "# draw\n",
        "plt.plot(lrs, 'r-', label='learning_rate')\n",
        "plt.xlabel('Step')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "HpO5BefVqfgH",
        "outputId": "49d55492-6729-4245-fb17-1af16706b199"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 모델을 실제로 빌드해 봅시다."
      ],
      "metadata": {
        "id": "5UVkTMDkqnec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 생성\n",
        "pre_train_model = build_model_pre_train(config)\n",
        "pre_train_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwqxBpAvqozn",
        "outputId": "6ec6edef-2f39-42b0-a0f6-bf0b25b067c0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " enc_tokens (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " segments (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " bert (BERT)                    ((None, 256),        4485632     ['enc_tokens[0][0]',             \n",
            "                                 (None, None, 8007)               'segments[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pooled_nsp (PooledOutput)      (None, 2)            66304       ['bert[0][0]']                   \n",
            "                                                                                                  \n",
            " nsp (Softmax)                  (None, 2)            0           ['pooled_nsp[0][0]']             \n",
            "                                                                                                  \n",
            " mlm (Softmax)                  (None, None, 8007)   0           ['bert[0][1]']                   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,551,936\n",
            "Trainable params: 4,551,936\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 본격적으로 학습을 진행합니다."
      ],
      "metadata": {
        "id": "qG62ADPNqxDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "# optimizer\n",
        "# matn.ceil: 올림값사용\n",
        "train_steps = math.ceil(len(pre_train_inputs[0]) / batch_size) * epochs\n",
        "print(\"train_steps:\", train_steps)\n",
        "learning_rate = CosineSchedule(train_steps=train_steps, warmup_steps=max(100, train_steps // 10))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "# compile\n",
        "pre_train_model.compile(loss=(tf.keras.losses.sparse_categorical_crossentropy, lm_loss), optimizer=optimizer, metrics={\"nsp\": \"acc\", \"mlm\": lm_acc})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glzTswUAqyBf",
        "outputId": "8b8b34d1-a766-4536-cfbb-ec75fe910c3a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_steps: 20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습시킨 모델을 콜백 함수를 사용해 저장하고, 시각화해 봅시다"
      ],
      "metadata": {
        "id": "pfa_v0XVrLHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wvOUdgrubjx",
        "outputId": "cf077897-b839-4cba-b112-8bfab1213326"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive\t\t   ko_8000.model  labels_mlm.memmap  sample_data\n",
            "enc_tokens.memmap  ko_8000.vocab  labels_nsp.memmap  segments.memmap\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = '/content'\n",
        "# save weights callback\n",
        "save_weights = tf.keras.callbacks.ModelCheckpoint(f\"{model_dir}/bert_pre_train.hdf5\", monitor=\"mlm_lm_acc\", verbose=1, save_best_only=True, mode=\"max\", save_freq=\"epoch\", save_weights_only=True)\n",
        "# train\n",
        "history = pre_train_model.fit(pre_train_inputs, pre_train_labels, epochs=epochs, batch_size=batch_size, callbacks=[save_weights])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19E7fTV1rMcM",
        "outputId": "fa23941d-81c7-4806-8f2d-25b9cac12bf4"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 19.5908 - nsp_loss: 0.6511 - mlm_loss: 18.9397 - nsp_acc: 0.5887 - mlm_lm_acc: 0.1093\n",
            "Epoch 1: mlm_lm_acc improved from -inf to 0.10928, saving model to /content/bert_pre_train.hdf5\n",
            "2000/2000 [==============================] - 260s 128ms/step - loss: 19.5908 - nsp_loss: 0.6511 - mlm_loss: 18.9397 - nsp_acc: 0.5887 - mlm_lm_acc: 0.1093\n",
            "Epoch 2/10\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 17.5413 - nsp_loss: 0.6241 - mlm_loss: 16.9172 - nsp_acc: 0.6168 - mlm_lm_acc: 0.1296\n",
            "Epoch 2: mlm_lm_acc improved from 0.10928 to 0.12960, saving model to /content/bert_pre_train.hdf5\n",
            "2000/2000 [==============================] - 256s 128ms/step - loss: 17.5413 - nsp_loss: 0.6241 - mlm_loss: 16.9172 - nsp_acc: 0.6168 - mlm_lm_acc: 0.1296\n",
            "Epoch 3/10\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 16.4773 - nsp_loss: 0.6153 - mlm_loss: 15.8620 - nsp_acc: 0.6278 - mlm_lm_acc: 0.1425\n",
            "Epoch 3: mlm_lm_acc improved from 0.12960 to 0.14252, saving model to /content/bert_pre_train.hdf5\n",
            "2000/2000 [==============================] - 256s 128ms/step - loss: 16.4773 - nsp_loss: 0.6153 - mlm_loss: 15.8620 - nsp_acc: 0.6278 - mlm_lm_acc: 0.1425\n",
            "Epoch 4/10\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 14.4992 - nsp_loss: 0.6120 - mlm_loss: 13.8872 - nsp_acc: 0.6315 - mlm_lm_acc: 0.1797\n",
            "Epoch 4: mlm_lm_acc improved from 0.14252 to 0.17973, saving model to /content/bert_pre_train.hdf5\n",
            "2000/2000 [==============================] - 256s 128ms/step - loss: 14.4992 - nsp_loss: 0.6120 - mlm_loss: 13.8872 - nsp_acc: 0.6315 - mlm_lm_acc: 0.1797\n",
            "Epoch 5/10\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 13.5622 - nsp_loss: 0.6070 - mlm_loss: 12.9551 - nsp_acc: 0.6396 - mlm_lm_acc: 0.2053\n",
            "Epoch 5: mlm_lm_acc improved from 0.17973 to 0.20532, saving model to /content/bert_pre_train.hdf5\n",
            "2000/2000 [==============================] - 256s 128ms/step - loss: 13.5622 - nsp_loss: 0.6070 - mlm_loss: 12.9551 - nsp_acc: 0.6396 - mlm_lm_acc: 0.2053\n",
            "Epoch 6/10\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 13.0855 - nsp_loss: 0.6021 - mlm_loss: 12.4834 - nsp_acc: 0.6495 - mlm_lm_acc: 0.2190\n",
            "Epoch 6: mlm_lm_acc improved from 0.20532 to 0.21900, saving model to /content/bert_pre_train.hdf5\n",
            "2000/2000 [==============================] - 256s 128ms/step - loss: 13.0855 - nsp_loss: 0.6021 - mlm_loss: 12.4834 - nsp_acc: 0.6495 - mlm_lm_acc: 0.2190\n",
            "Epoch 7/10\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 12.7821 - nsp_loss: 0.5960 - mlm_loss: 12.1861 - nsp_acc: 0.6599 - mlm_lm_acc: 0.2277\n",
            "Epoch 7: mlm_lm_acc improved from 0.21900 to 0.22775, saving model to /content/bert_pre_train.hdf5\n",
            "2000/2000 [==============================] - 256s 128ms/step - loss: 12.7821 - nsp_loss: 0.5960 - mlm_loss: 12.1861 - nsp_acc: 0.6599 - mlm_lm_acc: 0.2277\n",
            "Epoch 8/10\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 12.5822 - nsp_loss: 0.5901 - mlm_loss: 11.9920 - nsp_acc: 0.6711 - mlm_lm_acc: 0.2343\n",
            "Epoch 8: mlm_lm_acc improved from 0.22775 to 0.23428, saving model to /content/bert_pre_train.hdf5\n",
            "2000/2000 [==============================] - 256s 128ms/step - loss: 12.5822 - nsp_loss: 0.5901 - mlm_loss: 11.9920 - nsp_acc: 0.6711 - mlm_lm_acc: 0.2343\n",
            "Epoch 9/10\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 12.4601 - nsp_loss: 0.5850 - mlm_loss: 11.8751 - nsp_acc: 0.6798 - mlm_lm_acc: 0.2378\n",
            "Epoch 9: mlm_lm_acc improved from 0.23428 to 0.23780, saving model to /content/bert_pre_train.hdf5\n",
            "2000/2000 [==============================] - 255s 128ms/step - loss: 12.4601 - nsp_loss: 0.5850 - mlm_loss: 11.8751 - nsp_acc: 0.6798 - mlm_lm_acc: 0.2378\n",
            "Epoch 10/10\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 12.4028 - nsp_loss: 0.5826 - mlm_loss: 11.8201 - nsp_acc: 0.6848 - mlm_lm_acc: 0.2395\n",
            "Epoch 10: mlm_lm_acc improved from 0.23780 to 0.23953, saving model to /content/bert_pre_train.hdf5\n",
            "2000/2000 [==============================] - 256s 128ms/step - loss: 12.4028 - nsp_loss: 0.5826 - mlm_loss: 11.8201 - nsp_acc: 0.6848 - mlm_lm_acc: 0.2395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training result\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['nsp_loss'], 'b-', label='nsp_loss')\n",
        "plt.plot(history.history['mlm_loss'], 'r--', label='mlm_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['nsp_acc'], 'g-', label='nsp_acc')\n",
        "plt.plot(history.history['mlm_lm_acc'], 'k--', label='mlm_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "2O3vUvP1uvnq",
        "outputId": "9d8d4083-0f19-4cc5-9798-f0a122644cb3"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **회고**\n",
        "프로젝트자체는 어렵진않았지만, 전체적인 개념이나 코드진행자체를 이해하기어려웠다. 처음보는 코드가 많이나와서 전체적으로 여러번 다시 봐야할듯 하다.\n"
      ],
      "metadata": {
        "id": "aONbv48k3eoG"
      }
    }
  ]
}