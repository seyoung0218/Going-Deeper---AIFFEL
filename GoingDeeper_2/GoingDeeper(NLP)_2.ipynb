{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 프로젝트 : 뉴스 카테고리 다중분류\n",
        "vocabulary의 크기에 따라 머신러닝 모델의 성능이 어떻게 변하는지 확인해보고, 최고의 성능이 나오는 머신러닝모델과 임의의 딥러닝 모델과 성능을 비교해보겠습니다.\n",
        "# **First Try : num_words=10000**\n",
        "# **Step1. Import Libraries**"
      ],
      "metadata": {
        "id": "XnUoZrOgApLR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "du43jSAAAf60"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step2. Import Data**\n",
        "우리가 사용할 데이터는 reuter new data입니다. 이 데이터는 총 46개의 클래스로 구성되며, 해당 뉴스가 어느 카테고리에 속하는지를 예측하기 위한 데이터입니다. 텐서플로우 데이터셋에서 제공하고있는 데이터로 아주 쉽게 다운로드가 가능합니다."
      ],
      "metadata": {
        "id": "QtkPzB25Entv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)"
      ],
      "metadata": {
        "id": "goUDR-Q2E6fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "num_words는 이 데이터에서 빈도수 기준으로 상위 몇번째 단어까지 사용할 것인지 조절합니다."
      ],
      "metadata": {
        "id": "5i214r7MFL-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step3. EDA(Exploratory Data Analysis)**\n",
        "받아온 데이터의 형태를 확인해봅시다."
      ],
      "metadata": {
        "id": "-DbFwTGgljEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO-EIzKAl2OI",
        "outputId": "b38d58b0-04ab-4274-9a1b-9aa6d463156a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8982,), (2246,), (8982,), (2246,))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그럼 한번 출력을 해보죠"
      ],
      "metadata": {
        "id": "qiHx9OqwmZtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[:3])\n",
        "print(y_train[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr8Pl_l9mm3b",
        "outputId": "395ca193-277c-46e1-8a66-47f16df4ebbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[list([1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12])\n",
            " list([1, 3267, 699, 3434, 2295, 56, 2, 7511, 9, 56, 3906, 1073, 81, 5, 1198, 57, 366, 737, 132, 20, 4093, 7, 2, 49, 2295, 2, 1037, 3267, 699, 3434, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2295, 2, 2, 775, 7, 48, 34, 191, 44, 35, 1795, 505, 17, 12])\n",
            " list([1, 53, 12, 284, 15, 14, 272, 26, 53, 959, 32, 818, 15, 14, 272, 26, 39, 684, 70, 11, 14, 12, 3886, 18, 180, 183, 187, 70, 11, 14, 102, 32, 11, 29, 53, 44, 704, 15, 14, 19, 758, 15, 53, 959, 47, 1013, 15, 14, 19, 132, 15, 39, 965, 32, 11, 14, 147, 72, 11, 180, 183, 187, 44, 11, 14, 102, 19, 11, 123, 186, 90, 67, 960, 4, 78, 13, 68, 467, 511, 110, 59, 89, 90, 67, 1390, 55, 2678, 92, 617, 80, 1274, 46, 905, 220, 13, 4, 346, 48, 235, 629, 5, 211, 5, 1118, 7, 2, 81, 5, 187, 11, 15, 9, 1709, 201, 5, 47, 3615, 18, 478, 4514, 5, 1118, 7, 232, 2, 71, 5, 160, 63, 11, 9, 2, 81, 5, 102, 59, 11, 17, 12])]\n",
            "[3 4 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텍스트가 아니라 숫자 시퀀스가 출력됩니다. 텐서플로우 데이터셋에서는 이미 전처리한 데이터를 제공해준다고 합니다.\n",
        "\n",
        "그리고 레이블은 정수형태로 저장되있습니다. 그러면 몇개의 클래를 가지고 있는지 확인해봅시다."
      ],
      "metadata": {
        "id": "LTKqwj3BmxnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_class = max(y_train) + 1 # 레이블이 숫자 0부터 시작되므로 1을 더해줌\n",
        "print('클래스의 수 : {}'.format(total_class))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F05rHs84nJL8",
        "outputId": "cec7bbb4-2b80-45b7-f08e-7fab5a0df403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "클래스의 수 : 46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "클래스의 양이 많은것으로 보아 정확도를 얻는 일이 쉽지않아보입니다.\n",
        "\n",
        "다음으로 뉴스 데이터들의 길이분포를 확인해봅시다."
      ],
      "metadata": {
        "id": "gjacGtsBnZcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련용 뉴스의 최대길이 : {}'.format(max(len(l) for l in x_train)))\n",
        "print('훈련용 뉴스의 평균길이 : {}'.format(sum(map(len, x_train))/len(x_train)))\n",
        "\n",
        "plt.hist([len(s) for s in x_train], bins=50)\n",
        "plt.xlabel('length of smaples')\n",
        "plt.ylabel('number of samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "FZYOxFZIniJE",
        "outputId": "fec99e50-7a43-4a00-b513-1afc5e4ac961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련용 뉴스의 최대길이 : 2376\n",
            "훈련용 뉴스의 평균길이 : 145.5398574927633\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'number of samples')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZw0lEQVR4nO3dfbRddX3n8feHCGgrS0JBFvLQoKYPOlWkV6RTpoN1BIRO0ZmqOKNESkvbgYod6zRUp1A7rOLUh45P1FCo0bEyTNWSEUaMFLWuVknACARKSQWGpAhRlAetKPCdP/bv1uPl3uyTm5x7z733/Vprr7PPdz9998k595u992//dqoKSZJ2ZI/5TkCSNP4sFpKkXhYLSVIvi4UkqZfFQpLU6wnzncAo7L///rVixYr5TkOSFpTrrrvua1V1wHTTFmWxWLFiBRs3bpzvNCRpQUly50zTRnYaKskTk1yb5MtJNif5/RY/PMkXk2xJ8r+S7NXie7f3W9r0FQPrOqfFb01y/KhyliRNb5TXLB4Gfr6qngscAZyQ5GjgrcA7q+qZwDeA09v8pwPfaPF3tvlI8izgFODZwAnA+5IsG2HekqQpRlYsqvNQe7tnGwr4eeAvWnwt8NI2fnJ7T5v+oiRp8Uur6uGquh3YAhw1qrwlSY830tZQSZYl2QTcC6wH/gH4ZlU90mbZChzcxg8G7gJo0+8HfmQwPs0yg9s6I8nGJBu3b98+it2RpCVrpMWiqh6tqiOAQ+iOBn5ihNtaU1UTVTVxwAHTXsyXJM3SnNxnUVXfBK4BfgbYN8lkK6xDgG1tfBtwKECb/hTg64PxaZaRJM2BUbaGOiDJvm38ScCLgVvoisYvtdlWAZe38XXtPW36X1XXJe464JTWWupwYCVw7ajyliQ93ijvszgIWNtaLu0BXFZVn0hyM3Bpkv8GfAm4uM1/MfChJFuA++haQFFVm5NcBtwMPAKcWVWPjjBvSdIUWYzPs5iYmChvypOknZPkuqqamG7aoryDe1RWrL5i2vgdF5w0x5lI0tyyI0FJUi+LhSSpl8VCktTLYiFJ6mWxkCT1slhIknpZLCRJvSwWkqReFgtJUi+LhSSpl8VCktTLYiFJ6mWxkCT1slhIknpZLCRJvSwWkqReFgtJUi+LhSSpl8VCktTLYiFJ6mWxkCT1slhIknpZLCRJvSwWkqReFgtJUq+RFYskhya5JsnNSTYnObvFz0uyLcmmNpw4sMw5SbYkuTXJ8QPxE1psS5LVo8pZkjS9J4xw3Y8Ab6iq65PsA1yXZH2b9s6qetvgzEmeBZwCPBt4GvDpJD/WJr8XeDGwFdiQZF1V3TzC3CVJA0ZWLKrqbuDuNv5gkluAg3ewyMnApVX1MHB7ki3AUW3alqr6CkCSS9u8FgtJmiNzcs0iyQrgecAXW+isJDckuSTJ8hY7GLhrYLGtLTZTfOo2zkiyMcnG7du37+Y9kKSlbeTFIsmTgY8Cr6+qB4ALgWcAR9Adebx9d2ynqtZU1URVTRxwwAG7Y5WSpGaU1yxIsiddofhwVX0MoKruGZh+EfCJ9nYbcOjA4oe0GDuIS5LmwChbQwW4GLilqt4xED9oYLaXATe18XXAKUn2TnI4sBK4FtgArExyeJK96C6CrxtV3pKkxxvlkcXPAq8BbkyyqcV+F3hVkiOAAu4Afg2gqjYnuYzuwvUjwJlV9ShAkrOAq4BlwCVVtXmEeUuSphhla6jPA5lm0pU7WOZ84Pxp4lfuaDlJ0mh5B7ckqZfFQpLUy2IhSeplsZAk9bJYSJJ6WSwkSb0sFpKkXhYLSVIvi4UkqddIOxJcqFasvmK+U5CkseKRhSSpl8VCktTLYiFJ6mWxkCT1slhIknpZLCRJvSwWkqRevcUiycuT7NPG35zkY0mOHH1qkqRxMcyRxX+tqgeTHAP8G+Bi4MLRpiVJGifDFItH2+tJwJqqugLYa3QpSZLGzTDFYluS9wOvBK5MsveQy0mSFolh/ui/ArgKOL6qvgnsB7xxpFlJksZKb7Goqm8D9wLHtNAjwG2jTEqSNF6GaQ11LvA7wDkttCfwP0eZlCRpvAxzGuplwC8C3wKoqn8E9hllUpKk8TJMsfhuVRVQAEl+eLQpSZLGzTDF4rLWGmrfJL8KfBq4aLRpSZLGyTAXuN8G/AXwUeDHgd+rqnf3LZfk0CTXJLk5yeYkZ7f4fknWJ7mtvS5v8SR5V5ItSW4YvEs8yao2/21JVs12ZyVJszPUY1Wraj2wfifX/Qjwhqq6vnUXcl2S9cBrgaur6oIkq4HVdBfQXwKsbMML6O4Sf0GS/YBzgQm6U2HXJVlXVd/YyXwkSbM045FFkgeTPDDN8GCSB/pWXFV3V9X1bfxB4BbgYOBkYG2bbS3w0jZ+MvDB6nyB7rTXQcDxwPqquq8ViPXACbPcX0nSLMx4ZFFVu63FU5IVwPOALwIHVtXdbdJXgQPb+MHAXQOLbW2xmeJTt3EGcAbAYYcdtrtSlyQx5Gmodv3gGLrTQJ+vqi8Nu4EkT6a73vH6qnogyT9Pq6pKUjuX8vSqag2wBmBiYmK3rFOS1Bnmprzfoztd9CPA/sAHkrx5mJUn2ZOuUHy4qj7Wwve000u013tbfBtw6MDih7TYTHFJ0hwZpunsfwSeX1XnVtW5wNHAa/oWSncIcTFwS1W9Y2DSOmCyRdMq4PKB+KmtVdTRwP3tdNVVwHFJlreWU8e1mCRpjgxzGuofgScC32nv92a4/9n/LF1RuTHJphb7XeACuns3TgfupOuoEOBK4ERgC/Bt4DSAqrovyR8AG9p8b6mq+4bYviRpNxmmWNwPbG7NXgt4MXBtkncBVNXrpluoqj4PZLppwIummb+AM2dY1yXAJUPkKkkagWGKxcfbMOkzo0lFkjSueotFVa3tm0eStLgN0xrqF5J8Kcl9O3NTniRp8RjmNNQfA/8OuLFdV5AkLTHDNJ29C7jJQiFJS9cwRxb/BbgyyWeBhyeDU+6dkCQtYsMUi/OBh+jutdhrtOlIksbRMMXiaVX1L0aeiSRpbA1zzeLKJMeNPBNJ0tgaplj8BvDJJP9k01lJWpqGuSlvtz3XQpK0MA37PIvldI87feJkrKo+N6qkJEnjpbdYJPkV4Gy650hsouui/G+Bnx9tapKkcTHMNYuzgecDd1bVC+kej/rNkWYlSRorwxSL71TVdwCS7F1Vfwf8+GjTkiSNk2GuWWxNsi/wl8D6JN+ge2iRJGmJGKY11Mva6HlJrgGeAnxypFlJksbKMF2UPyPJ3pNvgRXAD40yKUnSeBnmmsVHgUeTPBNYAxwK/PlIs5IkjZVhisVjVfUI8DLg3VX1RuCg0aYlSRonwxSL7yV5FbAK+ESL7Tm6lCRJ42aYYnEa8DPA+VV1e5LDgQ+NNi1J0jgZpjXUzcDrBt7fDrx1lElJksbLMEcWkqQlzmIhSeo1Y7FI8qH2evbcpSNJGkc7OrL46SRPA345yfIk+w0OfStOckmSe5PcNBA7L8m2JJvacOLAtHOSbElya5LjB+IntNiWJKtnu6OSpNnb0QXuPwGuBp4OXEd39/akavEd+QDwHuCDU+LvrKq3DQaSPAs4BXg28DTg00l+rE1+L/BiYCuwIcm6dtFdkjRHZjyyqKp3VdVPApdU1dOr6vCBoa9QTD4c6b4h8zgZuLSqHm6trbYAR7VhS1V9paq+C1za5pUkzaHeC9xV9RtJnpvkrDY8Zxe3eVaSG9ppquUtdjBw18A8W1tspvjjJDkjycYkG7dv376LKUqSBg3TkeDrgA8DT23Dh5P85iy3dyHwDOAI4G7g7bNcz+NU1ZqqmqiqiQMOOGB3rVaSxHDPs/gV4AVV9S2AJG+le6zqu3d2Y1V1z+R4kov4fvch2+g6KJx0SIuxg7gkaY4Mc59FgEcH3j/KD17sHlqSwQ4IXwZMtpRaB5ySZO/WnchK4FpgA7AyyeFJ9qK7CL5uNtuWJM3eMEcWfwZ8McnH2/uXAhf3LZTkI8CxwP5JtgLnAscmOYKuNdUdwK8BVNXmJJcBNwOPAGdW1aNtPWcBVwHL6C62bx567yRJu8UwfUO9I8lngGNa6LSq+tIQy71qmvCMRaaqzgfOnyZ+JXBl3/YkSaMzzJEFVXU9cP2Ic5EkjSn7hpIk9bJYSJJ67bBYJFmW5Jq5SkaSNJ52WCxai6THkjxljvKRJI2hYS5wPwTcmGQ98K3JYFW9buZFJEmLyTDF4mNtkCQtUcPcZ7E2yZOAw6rq1jnISZI0ZobpSPDfApuAT7b3RySxyw1JWkKGaTp7Ht1zJb4JUFWb6H/wkSRpERmmWHyvqu6fEntsFMlIksbTMBe4Nyf5D8CyJCuB1wF/M9q0JEnjZJgji9+kezb2w8BHgAeA148yKUnSeBmmNdS3gTe1hx5VVT04+rQkSeNkmNZQz09yI3AD3c15X07y06NPTZI0Loa5ZnEx8J+q6q8BkhxD90Ck54wyMUnS+BjmmsWjk4UCoKo+T/c0O0nSEjHjkUWSI9voZ5O8n+7idgGvBD4z+tQkSeNiR6eh3j7l/bkD4zWCXCRJY2rGYlFVL5zLRCRJ46v3AneSfYFTgRWD89tFuSQtHcO0hroS+AJwI3bzIUlL0jDF4olV9Z9HnokkaWwNUyw+lORXgU/QdfkBQFXdN7KsFpgVq6+YNn7HBSfNcSaSNBrDFIvvAn8EvInvt4Iq7KZckpaMYYrFG4BnVtXXRp2MJGk8DXMH9xbg26NORJI0voYpFt8CNiV5f5J3TQ59CyW5JMm9SW4aiO2XZH2S29rr8hZPW++WJDcM3D1OklVt/tuSrJrNTkqSds0wxeIvgfPpHnh03cDQ5wPACVNiq4Grq2olcHV7D/ASYGUbzgAuhK640N05/gK6R7ueO1lgJElzZ5jnWaydzYqr6nNJVkwJnwwc28bX0vUx9Tst/sGqKuALSfZNclCbd/1ky6sk6+kK0Edmk5MkaXaGuYP7dqbpC6qqZtMa6sCquruNfxU4sI0fDNw1MN/WFpspPl2eZ9AdlXDYYYfNIjVJ0kyGaQ01MTD+RODlwH67uuGqqiS7rUPCqloDrAGYmJiwo0NJ2o16r1lU1dcHhm1V9cfAbO82u6edXqK93tvi24BDB+Y7pMVmikuS5tAwj1U9cmCYSPLrDHdEMp11wGSLplXA5QPxU1urqKOB+9vpqquA45Isbxe2j2sxSdIcGuaP/uBzLR4B7gBe0bdQko/QXaDeP8lWulZNFwCXJTkduHNgPVcCJ/L9ezpOg65LkSR/AGxo873FbkYkae4N0xpqVs+1qKpXzTDpRdPMW8CZM6znEuCS2eQgSdo9hmkNtTfw73n88yzeMrq0JEnjZJjTUJcD99PdiPdwz7ySpEVomGJxSFVNvRNbkrSEDNPdx98k+amRZyJJGlvDHFkcA7y23cn9MBC6a9LPGWlmkqSxMUyxeMnIs5AkjbVhms7eOReJLEY+blXSYjHMNQtJ0hJnsZAk9bJYSJJ6WSwkSb0sFpKkXhYLSVIvi4UkqZfFQpLUy2IhSeplsZAk9bJYSJJ6WSwkSb0sFpKkXhYLSVIvi4UkqZfFQpLUy2IhSeplsZAk9bJYSJJ6zUuxSHJHkhuTbEqyscX2S7I+yW3tdXmLJ8m7kmxJckOSI+cjZ0layubzyOKFVXVEVU2096uBq6tqJXB1ew/wEmBlG84ALpzzTCVpiRun01AnA2vb+FrgpQPxD1bnC8C+SQ6ajwQlaamar2JRwKeSXJfkjBY7sKrubuNfBQ5s4wcDdw0su7XFfkCSM5JsTLJx+/bto8pbkpakJ8zTdo+pqm1JngqsT/J3gxOrqpLUzqywqtYAawAmJiZ2atm5tmL1FdPG77jgpDnORJKGMy9HFlW1rb3eC3wcOAq4Z/L0Unu9t82+DTh0YPFDWkySNEfmvFgk+eEk+0yOA8cBNwHrgFVttlXA5W18HXBqaxV1NHD/wOkqSdIcmI/TUAcCH08yuf0/r6pPJtkAXJbkdOBO4BVt/iuBE4EtwLeB0+Y+ZUla2ua8WFTVV4DnThP/OvCiaeIFnDkHqUmSZjBOTWclSWPKYiFJ6mWxkCT1slhIknpZLCRJvSwWkqRe89Xdh6ZhNyCSxpVHFpKkXhYLSVIvi4UkqZfFQpLUy2IhSepla6gFwFZSkuabRxaSpF4WC0lSL4uFJKmXxUKS1MtiIUnqZWuoBcxWUpLmikcWkqReFgtJUi9PQy0hM522Ak9dSdoxi8UitKOiIEmz4WkoSVIvjywE2LJK0o5ZLDQrFhdpabFYaId21/UPi4u0sC2YYpHkBOB/AMuAP62qC+Y5JU3Di+vS4rQgikWSZcB7gRcDW4ENSdZV1c3zm5l21c4WF49EpPmxIIoFcBSwpaq+ApDkUuBkwGKxxFhcpPmxUIrFwcBdA++3Ai8YnCHJGcAZ7e1DSW6dxXb2B742qwwXh0W3/3nrTi+y6D6DnbTU9x+W9mfwozNNWCjFoldVrQHW7Mo6kmysqondlNKCs9T3H/wMlvr+g5/BTBbKTXnbgEMH3h/SYpKkObBQisUGYGWSw5PsBZwCrJvnnCRpyVgQp6Gq6pEkZwFX0TWdvaSqNo9gU7t0GmsRWOr7D34GS33/wc9gWqmq+c5BkjTmFsppKEnSPLJYSJJ6WSzouhJJcmuSLUlWz3c+o5TkjiQ3JtmUZGOL7ZdkfZLb2uvyFk+Sd7XP5YYkR85v9jsvySVJ7k1y00Bsp/c3yao2/21JVs3HvszWDJ/BeUm2te/BpiQnDkw7p30GtyY5fiC+IH8nSQ5Nck2Sm5NsTnJ2iy+p78Euq6olPdBdMP8H4OnAXsCXgWfNd14j3N87gP2nxP47sLqNrwbe2sZPBP4vEOBo4Ivznf8s9vfngCOBm2a7v8B+wFfa6/I2vny+920XP4PzgN+eZt5ntd/A3sDh7bexbCH/ToCDgCPb+D7A37f9XFLfg10dPLIY6Eqkqr4LTHYlspScDKxt42uBlw7EP1idLwD7JjloPhKcrar6HHDflPDO7u/xwPqquq+qvgGsB04Yffa7xwyfwUxOBi6tqoer6nZgC91vZMH+Tqrq7qq6vo0/CNxC1yvEkvoe7CqLxfRdiRw8T7nMhQI+leS61kUKwIFVdXcb/ypwYBtfrJ/Nzu7vYv0czmqnWS6ZPAXDIv8MkqwAngd8Eb8HO8VisfQcU1VHAi8Bzkzyc4MTqzveXjLtqZfa/g64EHgGcARwN/D2+U1n9JI8Gfgo8PqqemBw2hL+HgzNYrHEuhKpqm3t9V7g43SnF+6ZPL3UXu9tsy/Wz2Zn93fRfQ5VdU9VPVpVjwEX0X0PYJF+Bkn2pCsUH66qj7Xwkv8e7AyLxRLqSiTJDyfZZ3IcOA64iW5/J1t2rAIub+PrgFNb65CjgfsHDtsXsp3d36uA45Isb6drjmuxBWvKtaeX0X0PoPsMTkmyd5LDgZXAtSzg30mSABcDt1TVOwYmLfnvwU6Z7yvs4zDQtX74e7rWHm+a73xGuJ9Pp2vF8mVg8+S+Aj8CXA3cBnwa2K/FQ/fQqX8AbgQm5nsfZrHPH6E7zfI9unPMp89mf4FfprvYuwU4bb73azd8Bh9q+3gD3R/Hgwbmf1P7DG4FXjIQX5C/E+AYulNMNwCb2nDiUvse7Opgdx+SpF6ehpIk9bJYSJJ6WSwkSb0sFpKkXhYLSVIvi4UWvCQPjWCdR0zpifW8JL+9C+t7eZJbklyzezKcdR53JNl/PnPQwmSxkKZ3BF1b/N3ldOBXq+qFu3Gd0pyxWGhRSfLGJBtaB3m/32Ir2v/qL2rPM/hUkie1ac9v825K8kdJbmp3KL8FeGWLv7Kt/llJPpPkK0leN8P2X5XueSE3JXlri/0e3Y1hFyf5oynzH5Tkc207NyX5Vy3+UMtnc5JPJzlqYNu/OLBff53k+jb8yxY/tq3zinTPn/iTJI/7rSd5dZJr27bfn2RZGz7QcrkxyW/thn8WLQbzfVegg8OuDsBD7fU4YA3dHbh7AJ+ge5bDCuAR4Ig232XAq9v4TcDPtPELaM98AF4LvGdgG+cBf0P3nIf9ga8De07J42nA/wMOAJ4A/BXw0jbtM0xzBzzwBr5/J/0yYJ82XrS7p+n68PoUsCfwXGBTi/8Q8MQ2vhLY2MaPBb5Dd8f+MrqutH+pTbuj5f+TwP+Z3AfgfcCpwE/TdcM9md++8/3v6zAeg0cWWkyOa8OXgOuBn6D7Iwpwe1VtauPXASuS7Ev3x/lvW/zPe9Z/RXXPefgaXadzB06Z/nzgM1W1vaoeAT5MV6x2ZANwWpLzgJ+q7nkLAN8FPtnGbwQ+W1Xfa+MrWnxP4KIkNwL/m+6BPpOure7ZE4/SdfdxzJTtvoiuMGxIsqm9fzrdA32enuTdSU4AHkCi+9+PtFgE+MOqev8PBLtnGDw8EHoUeNIs1j91Hbv8+6mqz7Vu4k8CPpDkHVX1QeB7VTXZF89jk9uuqseSTG73t4B76I429qA7mvjnVU/d1JT3AdZW1TlTc0ryXLoH/fw68Aq6/pC0xHlkocXkKuCX23MLSHJwkqfONHNVfRN4MMkLWuiUgckP0j2Cc2dcC/zrJPsnWQa8CvjsjhZI8qPAPVV1EfCndI8/HdZTgLur62b8NXSnnCYd1XqI3QN4JfD5KcteDfzS5OeT7nnUP9paSu1RVR8F3ryT+WgR88hCi0ZVfSrJTwJ/2/VKzUPAq+mOAmZyOt2pnMfo/rDf3+LXAKvbKZo/HHL7dydZ3ZYN3Wmry3sWOxZ4Y5LvtXxPHWZbzfuAjyY5le6U1bcGpm0A3gM8s+Xz8Sm53pzkzXRPTdyDrkfaM4F/Av5s4IL44448tDTZ66yWtCRPrqqH2vhquq66z57ntHZJkmOB366qX5jvXLR4eGShpe6kJOfQ/RbupGsFJWkKjywkSb28wC1J6mWxkCT1slhIknpZLCRJvSwWkqRe/x+5nyNETs+75gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "대부분의 길이는 500미만에 몰려있는것으로 보입니다.\n",
        "\n",
        "타깃레이블의 분포도 확인해봅시다. "
      ],
      "metadata": {
        "id": "AsbIHUUioN_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(11,5))\n",
        "sns.countplot(x=y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "Qi7jqSW-oWg1",
        "outputId": "cda48040-89b3-4dc6-9366-7e4164f4fbc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7effd9486a10>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 792x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 뉴스 데이터는 3번,4번 클래스가 대부분을 차지하고 있습니다. 수치적으로도 정확히 몇개인지 출력해보겠습니다."
      ],
      "metadata": {
        "id": "VjwacmAbom3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
        "print('각 클래스 빈도수:')\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAbluzplouDm",
        "outputId": "0cdce820-d314-4270-fc5d-225ae7a46a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 클래스 빈도수:\n",
            "[[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
            "    14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
            "    28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
            "    42   43   44   45]\n",
            " [  55  432   74 3159 1949   17   48   16  139  101  124  390   49  172\n",
            "    26   20  444   39   66  549  269  100   15   41   62   92   24   15\n",
            "    48   19   45   39   32   11   50   10   49   19   19   24   36   30\n",
            "    13   21   12   18]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step4. Restore from integer to text**\n",
        "정수 시퀀스로 변환된 데이터를 다시 텍스트로 돌려보겠습니다. 이번 프로젝트에서는 딥러닝이 아닌 머신러닝 방법을 사용하여 벡터화를 진행할 것이기때문입니다. \n",
        "먼저 해당 데이터의 단어장(Vocabulary)를 불러와봅시다."
      ],
      "metadata": {
        "id": "bDDl0IKpt9LW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = reuters.get_word_index(path='reuters_word_index.json')"
      ],
      "metadata": {
        "id": "HrAmDKkUvRE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "'the'와 'it'에 어떤 정수가 맵핑되어있는지 확인해봅시다."
      ],
      "metadata": {
        "id": "yxjQbhqmvk0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index['the']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWD4DV73vfXF",
        "outputId": "180fbd9b-3e69-42be-f6d3-b7090ef8f9bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index['it']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XghZJXYvvnW",
        "outputId": "5e196e6d-91c2-410f-b084-70d0889634e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "우리는 정수로부터 단어를 얻는 index_word가 필요합니다. \n",
        "그리고 \\<pad>,\\<sos>,\\<unk>의 토큰에 0번,1번,2번을 맵핑해줄것이기때문에 기존index에 전부 3을 더해주어야합니다."
      ],
      "metadata": {
        "id": "IELrRNWEwD8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = {index+3 : word for word, index in word_index.items()}\n",
        "\n",
        "for index, token in enumerate(('<pad>', '<sos>', '<unk>')):\n",
        "    index_to_word[index] = token"
      ],
      "metadata": {
        "id": "uSjBUSAwwvww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "그럼 index_to_word를 이용해서 첫번째 훈련용 뉴스 기사를 원래 텍스트로 복원해보겠습니다."
      ],
      "metadata": {
        "id": "Lgu94cGgxU37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(' '.join([index_to_word[index] for index in x_train[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAd3MZxyxbGD",
        "outputId": "aca1e92d-c632-4d6f-ac60-cc4014dad9b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "첫번째 훈련용 뉴스기사가 정수 시퀀스에서 텍스트로 복원되었습니다. 이 데이터도 어느 정도 전처리가 된 상태라서, 자연스럽게 읽히지는 않습니다. 하지만 문맥을 가진 텍스트이기때문에, 이 데이터를 가지고 머신러닝을 시작해도 문제없어 보입니다.\n",
        "\n",
        "이제 전체 훈련용, 테스트용 뉴스데이터를 텍스트데이터로 변환해 보겠습니다."
      ],
      "metadata": {
        "id": "LNRjPiFpx2sH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train dataset\n",
        "decoded = []\n",
        "for i in range(len(x_train)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_train = decoded\n",
        "print(len(x_train))\n",
        "\n",
        "# test dataset\n",
        "decoded = []\n",
        "for i in range(len(x_test)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_test = decoded\n",
        "print(len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSlMi7cGyLIx",
        "outputId": "0dcb2b38-0ad3-4c00-91e2-2a2d10f6b5bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8982\n",
            "2246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "제대로 변환이 됐는지 한번 출력해봅시다."
      ],
      "metadata": {
        "id": "LCd_4DMrzNfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "98j6SYd3zR46",
        "outputId": "a73d02f7-d395-46e4-c311-5cce5aab6eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<sos> generale de banque sa lt <unk> br and lt heller overseas corp of chicago have each taken 50 pct stakes in <unk> company sa <unk> factors generale de banque said in a statement it gave no financial details of the transaction sa <unk> <unk> turnover in 1986 was 17 5 billion belgian francs reuter 3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "acFiZ18kzYXQ",
        "outputId": "638498e4-5aab-4804-a04f-9870fab407b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<sos> philippine sugar production in the 1987 88 crop year ending august has been set at 1 6 mln tonnes up from a provisional 1 3 mln tonnes this year sugar regulatory administration <unk> chairman <unk> yulo said yulo told reuters a survey during the current milling season which ends next month showed the 1986 87 estimate would almost certainly be met he said at least 1 2 mln tonnes of the 1987 88 crop would be earmarked for domestic consumption yulo said about 130 000 tonnes would be set aside for the u s sugar quota 150 000 tonnes for strategic reserves and 50 000 tonnes would be sold on the world market he said if the government approved a long standing <unk> recommendation to manufacture ethanol the project would take up another 150 000 tonnes slightly raising the target the government for its own reasons has been delaying approval of the project but we expect it to come through by july yulo said ethanol could make up five pct of gasoline cutting the oil import bill by about 300 mln pesos yulo said three major philippine <unk> were ready to start manufacturing ethanol if the project was approved the ethanol project would result in employment for about 100 000 people sharply reducing those thrown out of work by depressed world sugar prices and a <unk> domestic industry production quotas set for the first time in 1987 88 had been submitted to president corazon aquino i think the president would rather wait <unk> the new congress <unk> after the may elections he said but there is really no need for such quotas we are right now producing just slightly over our own consumption level the producers have never enjoyed such high prices yulo said adding sugar was currently selling locally for 320 pesos per <unk> up from 190 pesos last august yulo said prices were driven up because of speculation following the <unk> bid to control production we are no longer concerned so much with the world market he said adding producers in the <unk> region had learned from their <unk> and diversified into corn and <unk> farming and <unk> production he said diversification into products other than ethanol was also possible within the sugar industry the <unk> long ago <unk> their <unk> yulo said they have 300 sugar mills compared with our 41 but they <unk> many of them and diversified production we want to call this a <unk> <unk> instead of the sugar industry he said sugarcane could be fed to pigs and livestock used for <unk> <unk> or used in room <unk> when you cut sugarcane you don't even have to produce sugar he said yulo said the philippines was lobbying for a renewal of the international sugar agreement which expired in 1984 as a major sugar producer we are urging them to write a new agreement which would revive world prices yulo said if there is no agreement world prices will always be depressed particularly because the european community is <unk> its producers and dumping sugar on the markets he said current world prices holding steady at about 7 60 cents per pound were <unk> for the philippines where production costs ranged from 12 to 14 cents a pound if the price holds steady for a while at 7 60 cents i expect the level to rise to about 11 cents a pound by the end of this year he said yulo said economists forecast a bullish sugar market by 1990 with world consumption <unk> production he said sugar markets were holding up despite <unk> from artificial sweeteners and high fructose corn syrup but we are not happy with the reagan administration he said since <unk> we have been regular suppliers of sugar to the u s in 1982 when they restored the quota system they cut <unk> in half without any justification manila was <unk> watching washington's moves to cut domestic support prices to 12 cents a pound from 18 cents the u s agriculture department last december slashed its 12 month 1987 sugar import quota from the philippines to 143 780 short tons from 231 660 short tons in 1986 yulo said despite next year's increased production target some philippine mills were expected to shut down at least four of the 41 mills were not working during the 1986 87 season he said we expect two or three more to follow suit during the next season reuter 3\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step5. Vectorizing**\n",
        "텍스트 데이터가 있을 때, 모델의 입력으로 넣기 위해서는 우선 각 문서를 벡터화할 필요가 있습니다. 일반적으로 텍스트 분류를 할 모델로 인공 신경망을 사용하는 경우, 벡터화 방법 또한 인공 신경망을 사용하는것이 보편적입니다.(Eembedding)\n",
        "\n",
        "여기서는 인공신경망이아닌 머신러닝을 사용하기때문에, 벡터화 방법도 인공신경망이 아닌 방법을 사용합니다. 여기서 사용할 벡터화 방법은 Bag of Words가설을 기반으로하는 DTM, TF-IDF입니다."
      ],
      "metadata": {
        "id": "DAsIQD1Rzdte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DTM 생성\n",
        "dtmvector = CountVectorizer()\n",
        "x_train_dtm = dtmvector.fit_transform(x_train)\n",
        "x_test_dtm = dtmvector.transform(x_test)\n",
        "print(x_train_dtm.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0zASTwI0txv",
        "outputId": "19e35bb2-335e-4ca2-a2cc-7e4156013b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8982, 9670)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전에 num_words=10000을 사용했지만, DTM열의 개수는 이보다 적은수입니다. 그 이유는 DTM이 자체적인 규칙에 따라서 불필요하다고 판단하는 토큰들을 제거했기 때문입니다.\n",
        "\n",
        "이어서 TF-IDF행렬을 만들어봅시다."
      ],
      "metadata": {
        "id": "4tpHf4J_1WVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF생성\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
        "tfidfv_test = tfidf_transformer.transform(x_test_dtm)\n",
        "print(tfidfv.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_EH-kk41sS-",
        "outputId": "3781bb1f-05f0-49c6-a943-39bc07df6610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8982, 9670)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "추가적인 전처리를 하지 않는 이상, DTM과 동일한 크기를 가집니다."
      ],
      "metadata": {
        "id": "c-j1EBdu17FE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step6. Using various machine learning model**\n",
        "다양한 머신러닝 모델을 사용해서 성능을 비교해보겠습니다.\n",
        "1. Multinomial Naive Bayes Classifier(NB)\n",
        "2. Complement Naive Bayes Classifier(CNB)\n",
        "3. Logistic Regression\n",
        "4. Linear Support Vector Machine\n",
        "5. Decision Tree\n",
        "6. Random Forest\n",
        "7. GradientBoostingClassifier\n",
        "8. Voting"
      ],
      "metadata": {
        "id": "XWZbDXsx3yRd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Multinomial Naive Bayes Classifier(NB)\n",
        "나이브 베이즈 분류기는 베이즈 정리에 기반한 통계적 분류 기법이고, feature끼리 서로독립이라는 조건이 필요합니다."
      ],
      "metadata": {
        "id": "0CGWob3X5Kao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultinomialNB()\n",
        "model.fit(tfidfv, y_train)\n",
        "predicted = model.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDw_IKo95cg-",
        "outputId": "efa372bc-1d15-44d2-f388-9c42a1aca5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.6567230632235085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Complement Naive Bayes Classifier(CNB)\n",
        "NB는 독립변수가 '조건부로 독립적'이라는 가정을하기때문에, 문서가 특정분류에 속할 실제 확률을 사용할때 문제가 발생할 수 있습니다. 대부분의 샘플이 3번,4번 클래스에 치중해있기때문에, 데이터가 불균형합니다. 이 경우에 사용하는것이 CNB입니다. 이는 데이터의 불균형을 고려하여 가중치를 부여하는 특징을 가지고 있습니다. 따라서 일반적으로 CNB는 NB보다 성능이 좋습니다."
      ],
      "metadata": {
        "id": "ysmPlL0J68rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cb = ComplementNB()\n",
        "cb.fit(tfidfv, y_train)\n",
        "predicted = cb.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79KOSwJk7ykO",
        "outputId": "87328f3e-6ce1-4853-d5cc-73ba66ae41fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.7707034728406055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Logistic Regression\n",
        "로지스틱 회귀는 소프트맥스함수를 사용한 다중 클래스 분류 알고리즘을 지원합니다. 주의할점은 이름이 회귀이지만, 실제로는 분류를 수행한다는 점입니다."
      ],
      "metadata": {
        "id": "tkQjOD6I8IGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(C=10000, penalty='l2', max_iter=3000)\n",
        "lr.fit(tfidfv, y_train)\n",
        "predicted = lr.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr7asvHA8XNW",
        "outputId": "2b7eda97-e951-42c2-fa7d-499640ba875b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.8107747105966162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Linear Support Vector Machine(SVM)\n",
        "LinearSVM은 태생적으로 이진분류를 위한 모델입니다. 그런데 이진분류 알고리즘을 다중클래스분류 알고리즘으로 사용하는 방법이 있습니다. 각 클래스를 다른 모든클래스와 구분하도록 이진분류모델을 학습시켜면 되죠. 결국 클래스의 수만큼 이진분류모델이 만들어집니다. "
      ],
      "metadata": {
        "id": "ZC_iuuvQ8sC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lsvc = LinearSVC(C=10000, penalty='l1', max_iter=3000, dual=False)\n",
        "lsvc.fit(tfidfv, y_train)\n",
        "predicted = lsvc.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3hW-kCF9Wxb",
        "outputId": "16f06c4a-ad7c-4a3a-8e94-40766d5382a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.7733748886910062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Decision Tree\n",
        "결정트리는 분류와 회귀문제에 널리 사용하는 모델입니다. 기본적으로 결정트리는 결정에 다다르기 위해 '예/아니오'질문을 이어나가면서 학습하죠. 하지만 트리계열의 모델들은 고차원이고 희소한 데이터에 대해서는 성능이 나오지 않는다는 특징이있습니다. 따라서 DTM이나 TF-IDF행렬의 경우 고차원이면서 sparse하기때문에 성능이 별로 나오지 않습니다."
      ],
      "metadata": {
        "id": "D19Z0eve9xTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
        "tree.fit(tfidfv, y_train)\n",
        "predicted = tree.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7i9-LAF-0Fu",
        "outputId": "181077bb-6352-47f8-f1d7-528d3de58872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.6202137132680321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Random Forest\n",
        "결정트리는 훈련데이터에 과적합되는 경향이있습니다. 랜덤포레스트는 이 문제를 앙상블로 해결합니다. 가령 서로 다른 방향으로 과적합된 트리들을 조합하면 오히려 모델전체에서는 과적합을 피할수 있죠."
      ],
      "metadata": {
        "id": "HHrvBf1y_G5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
        "forest.fit(tfidfv, y_train)\n",
        "predicted = forest.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0axfSGko_aC1",
        "outputId": "415ec16d-2a50-4033-e363-0d0e25a5a0f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.674087266251113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. GradientBoostingClassifier\n",
        "그래디언트 부스팅트리는 여러개의 결정 트리를 묶어 만드는 앙상블 모델입니다. 랜덤포레스트와 다르게 이전 트리의 오차를 보완하는 방식으로 순차적으로 트리를 만듭니다. 그래디언트 부스팅 트리는 일부 특성을 무시한다는 특징을 갖고있습니다. 그래서 보통 랜덤포레스트를 먼저 사용해보고, 성능이나 예측 시간면에서 만족스럽지 않은 경우에 그래디언트 부스팅 트리를 사용하는것이 좋습니다.\n",
        "###장점\n",
        "- 메모리적게사용\n",
        "- 예측이 빠름\n",
        "\n",
        "###단점\n",
        "- 훈련시간이 느림\n",
        "- 희소한 고차원 데이터에서는 성능이 낮음"
      ],
      "metadata": {
        "id": "RHRUND8YAKV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grbt = GradientBoostingClassifier(random_state=0)\n",
        "grbt.fit(tfidfv, y_train)\n",
        "predicted = grbt.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkWc2KY5A-Nb",
        "outputId": "ca92051f-f122-4f65-e168-28a60532fe31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.7662511130899377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Voting\n",
        "캐글에서 상위권을 차지한 많은 솔루션들이 앙상블이라는 방법을 사용합니다. 그중에서 투표를 통해 결과를 도출하는 보팅이라는 방법을 사용합니다.\n",
        "### hard Voting\n",
        ": 결과물에 대한 최종값을 투표해서 결정\n",
        "\n",
        "### Soft Voting\n",
        ": 결과물이 나올 확률값을 다 더해서 최종 결과물에 대한 각각의 확률을 구한뒤 최종값을 도출\n",
        "\n",
        "로지스틱회귀,CNB,그래디언트 부스팅 트리를 사용하여 소프트보팅을 해봅시다."
      ],
      "metadata": {
        "id": "xH1JyEaLBjPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voting_classifier = VotingClassifier(estimators=[\n",
        "    ('lr', LogisticRegression(C=10000, max_iter=3000, penalty='l2')),\n",
        "    ('cb', ComplementNB()),\n",
        "    ('grbt', GradientBoostingClassifier(random_state=0))\n",
        "], voting='soft')\n",
        "voting_classifier.fit(tfidfv, y_train)\n",
        "predicted = voting_classifier.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXzSHCd3COUo",
        "outputId": "4748b7c2-6272-4814-984e-e3265bddeca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.8165627782724845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step7. Performance Comparison**\n",
        "\n",
        "|num_words=10000|accuracy|\n",
        "|:----:|:----:|\n",
        "|Naive Bayes Classifier|0.656|\n",
        "|Complement Naive Bayes Classifier|0.771|\n",
        "|Logistic Regression|0.811|\n",
        "|LinearSVC|0.773|\n",
        "|DecisionTree|0.620|\n",
        "|RandomForest|0.674|\n",
        "|Gradient BoostingTree|0.766|\n",
        "|Soft Voting|0.817|\n",
        "\n",
        "로지스틱회귀와 소프트보팅이 80%이상의 정확도를 보여줍니다."
      ],
      "metadata": {
        "id": "ioMiFgMEEEp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Second Try : num_words=6000**\n",
        "단어장의 크기를 6000으로 줄여서 이전 메커니즘을 그대로 수행해보겠습니다."
      ],
      "metadata": {
        "id": "LpJQYz_BRFrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=6000, test_split=0.2)\n",
        "\n",
        "# 정수시퀀스 텍스트로 변환\n",
        "word_index = reuters.get_word_index(path='reuters_word_index.json')\n",
        "index_to_word = {index+3 : word for word, index in word_index.items()}\n",
        "\n",
        "for index, token in enumerate(('<pad>', '<sos>', '<unk>')):\n",
        "    index_to_word[index] = token\n",
        "\n",
        "# train dataset\n",
        "decoded = []\n",
        "for i in range(len(x_train)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_train = decoded\n",
        "print(len(x_train))\n",
        "\n",
        "# test dataset\n",
        "decoded = []\n",
        "for i in range(len(x_test)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_test = decoded\n",
        "print(len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nbsOBDuSCXS",
        "outputId": "66b12fc9-a324-43f4-b891-305e32414554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8982\n",
            "2246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터화\n",
        "# DTM 생성\n",
        "dtmvector = CountVectorizer()\n",
        "x_train_dtm = dtmvector.fit_transform(x_train)\n",
        "x_test_dtm = dtmvector.transform(x_test)\n",
        "\n",
        "# TF-IDF생성\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
        "tfidfv_test = tfidf_transformer.transform(x_test_dtm)\n",
        "print(tfidfv.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWvNkoQWTQNs",
        "outputId": "bc97c7d7-9b55-4063-f0f0-8fbd7f609d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8982, 5844)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Multinomial Naive Bayes Classifier(NB)\n",
        "model = MultinomialNB()\n",
        "model.fit(tfidfv, y_train)\n",
        "predicted = model.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lqz7Wzy9Taa1",
        "outputId": "68d3d9d4-0c16-4580-8564-37355e41db30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.6691896705253785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Complement Naive Bayes Classifier(CNB)\n",
        "cb = ComplementNB()\n",
        "cb.fit(tfidfv, y_train)\n",
        "predicted = cb.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klfqrqsCTg2S",
        "outputId": "456b34b5-a8e5-4152-dd51-9f5831e66ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.7689225289403384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Logistic Regression\n",
        "lr = LogisticRegression(C=10000, penalty='l2', max_iter=3000)\n",
        "lr.fit(tfidfv, y_train)\n",
        "predicted = lr.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-w2DIMaTlEm",
        "outputId": "aea503d8-a4f2-466c-ae06-1f00324bb732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.8076580587711487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Linear Support Vector Machine(SVM)\n",
        "lsvc = LinearSVC(C=10000, penalty='l1', max_iter=3000, dual=False)\n",
        "lsvc.fit(tfidfv, y_train)\n",
        "predicted = lsvc.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QozAosVPTpLo",
        "outputId": "9869ab4f-266e-49ea-a25c-a900d20b89ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.7702582368655387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Decision Tree\n",
        "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
        "tree.fit(tfidfv, y_train)\n",
        "predicted = tree.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTZtkRA-Tsxk",
        "outputId": "7f211c53-66c9-4aaf-8bee-655698a12c2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.6260017809439002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Random Forest\n",
        "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
        "forest.fit(tfidfv, y_train)\n",
        "predicted = forest.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcI7G_wuTwVc",
        "outputId": "1e33f4ee-583a-4234-9f20-ed020179db9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.6874443455031166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. GradientBoostingClassifier\n",
        "grbt = GradientBoostingClassifier(random_state=0)\n",
        "grbt.fit(tfidfv, y_train)\n",
        "predicted = grbt.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH734cBLTzwL",
        "outputId": "fef5b8a2-b476-4f03-8a8a-e459ce29bdde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.7644701691896705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Voting\n",
        "voting_classifier = VotingClassifier(estimators=[\n",
        "    ('lr', LogisticRegression(C=10000, max_iter=3000, penalty='l2')),\n",
        "    ('cb', ComplementNB()),\n",
        "    ('grbt', GradientBoostingClassifier(random_state=0))\n",
        "], voting='soft')\n",
        "voting_classifier.fit(tfidfv, y_train)\n",
        "predicted = voting_classifier.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgUtDo9ET37J",
        "outputId": "adf25224-57e3-41d9-cc64-bb60cd2d1054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.8138913624220837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "|num_words=6000|accuracy|\n",
        "|:----:|:----:|\n",
        "|Naive Bayes Classifier|0.669|\n",
        "|Complement Naive Bayes Classifier|0.769|\n",
        "|Logistic Regression|0.807|\n",
        "|LinearSVC|0.770|\n",
        "|DecisionTree|0.626|\n",
        "|RandomForest|0.687|\n",
        "|Gradient BoostingTree|0.764|\n",
        "|Soft Voting|0.813|\n",
        "\n",
        "전반적으로 값이 내려갔습니다."
      ],
      "metadata": {
        "id": "x4EDvrONUHt0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Third try : num_words=14000**"
      ],
      "metadata": {
        "id": "tv6QsmdfUYGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=14000, test_split=0.2)\n",
        "\n",
        "# 정수시퀀스 텍스트로 변환\n",
        "word_index = reuters.get_word_index(path='reuters_word_index.json')\n",
        "index_to_word = {index+3 : word for word, index in word_index.items()}\n",
        "\n",
        "for index, token in enumerate(('<pad>', '<sos>', '<unk>')):\n",
        "    index_to_word[index] = token\n",
        "\n",
        "# train dataset\n",
        "decoded = []\n",
        "for i in range(len(x_train)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_train = decoded\n",
        "print(len(x_train))\n",
        "\n",
        "# test dataset\n",
        "decoded = []\n",
        "for i in range(len(x_test)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_test = decoded\n",
        "print(len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpccHH3pUjfo",
        "outputId": "b6583a0a-6515-4b3d-eeb3-d3e8b7b588da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8982\n",
            "2246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터화\n",
        "# DTM 생성\n",
        "dtmvector = CountVectorizer()\n",
        "x_train_dtm = dtmvector.fit_transform(x_train)\n",
        "x_test_dtm = dtmvector.transform(x_test)\n",
        "\n",
        "# TF-IDF생성\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
        "tfidfv_test = tfidf_transformer.transform(x_test_dtm)\n",
        "print(tfidfv.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZd0uaHgUoQH",
        "outputId": "165876d4-26ae-42ee-9806-5b10af3dc82b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8982, 13341)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Multinomial Naive Bayes Classifier(NB)\n",
        "model = MultinomialNB()\n",
        "model.fit(tfidfv, y_train)\n",
        "predicted = model.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbXgJSi6UqV5",
        "outputId": "3b8fda5e-f4fd-4f9a-9cc8-4ccf90360529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.6393588601959038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Complement Naive Bayes Classifier(CNB)\n",
        "cb = ComplementNB()\n",
        "cb.fit(tfidfv, y_train)\n",
        "predicted = cb.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmBELhlzUtgN",
        "outputId": "4f1db486-3646-4487-9769-efe4381b564c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.7733748886910062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Logistic Regression\n",
        "lr = LogisticRegression(C=10000, penalty='l2', max_iter=3000)\n",
        "lr.fit(tfidfv, y_train)\n",
        "predicted = lr.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ5hxcigUwDf",
        "outputId": "e3228b73-c383-4949-fe52-bb317d9c8712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.8138913624220837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Linear Support Vector Machine(SVM)\n",
        "lsvc = LinearSVC(C=10000, penalty='l1', max_iter=3000, dual=False)\n",
        "lsvc.fit(tfidfv, y_train)\n",
        "predicted = lsvc.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSEjyU5BUzXe",
        "outputId": "12455629-41d9-4c68-d3bb-b455d3507227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.763579697239537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Decision Tree\n",
        "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
        "tree.fit(tfidfv, y_train)\n",
        "predicted = tree.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBe4NCXfU07N",
        "outputId": "e67c66f1-ee8d-48d3-f379-e754db64623a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.6179875333926982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Random Forest\n",
        "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
        "forest.fit(tfidfv, y_train)\n",
        "predicted = forest.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY6up4aaU2uE",
        "outputId": "19d6daaf-e5fd-4101-de5b-2265e8c79062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.6580587711487088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. GradientBoostingClassifier\n",
        "grbt = GradientBoostingClassifier(random_state=0)\n",
        "grbt.fit(tfidfv, y_train)\n",
        "predicted = grbt.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7hvA4c3U5PP",
        "outputId": "532413d9-4dba-43ac-be14-656a5673e5ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.7729296527159395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Voting\n",
        "voting_classifier = VotingClassifier(estimators=[\n",
        "    ('lr', LogisticRegression(C=10000, max_iter=3000, penalty='l2')),\n",
        "    ('cb', ComplementNB()),\n",
        "    ('grbt', GradientBoostingClassifier(random_state=0))\n",
        "], voting='soft')\n",
        "voting_classifier.fit(tfidfv, y_train)\n",
        "predicted = voting_classifier.predict(tfidfv_test)\n",
        "print('accuracy :', accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXwtA-OkU660",
        "outputId": "1d921b44-07b1-4d21-c412-5cf7091a175d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.8174532502226179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "|num_words=14000|accuracy|\n",
        "|:----:|:----:|\n",
        "|Naive Bayes Classifier|0.639|\n",
        "|Complement Naive Bayes Classifier|0.773|\n",
        "|Logistic Regression|0.814|\n",
        "|LinearSVC|0.764|\n",
        "|DecisionTree|0.618|\n",
        "|RandomForest|0.658|\n",
        "|Gradient BoostingTree|0.773|\n",
        "|Soft Voting|0.817|\n",
        "\n",
        "전반적으로 값이 올라갔습니다."
      ],
      "metadata": {
        "id": "B8sXo84hX53K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step8. Total Performance Comparison**\n",
        "단어장의 크기에 따른 모델의 성능을 비교해보겠습니다. \n",
        "\n",
        "|Machine Learning Model|accuracy_6000|accuracy_10000|accuracy_14000|\n",
        "|:----:|:----:|:----:|:----:|\n",
        "|Naive Bayes Classifier|0.669|0.656|0.639|\n",
        "|Complement Naive Bayes Classifier|0.769|0.771|0.773|\n",
        "|Logistic Regression|0.807|0.811|0.814|\n",
        "|LinearSVC|0.770|0.773|0.764|\n",
        "|DecisionTree|0.626|0.620|0.618|\n",
        "|RandomForest|0.687|0.674|0.658|\n",
        "|Gradient BoostingTree|0.764|0.766|0.773|\n",
        "|Soft Voting|0.813|0.816|0.817|\n",
        "\n",
        "- Naive Bayes, DecisionTree, RandomForest는 단어장의 크기가 커질수록 성능이 줄어듬\n",
        "- CNB, LogisticRegression, GradientBoostingTree, Voting은 단어장의 크기가 커질수록 성능이 늘어남\n",
        "- 제일 높은 성능 모델 : num_words=14000, Voting, accuracy=0.817"
      ],
      "metadata": {
        "id": "YvbBUTTSX-Qs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step9. Performance Comparison with DeepLearning Model**\n",
        "위 과정을 통해 나온 최적의 모델과 단어 수 조건에서, 딥러닝모델을 적용한 결과와 비교해 봅시다.\n"
      ],
      "metadata": {
        "id": "6ql4jRjoY7Y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=14000, test_split=0.2)"
      ],
      "metadata": {
        "id": "66RRcesjZ6Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "해당 데이터는 이미 전처리가된 정수시퀀스 형태입니다. 따라서 바로 패딩을 적용해주겠습니다."
      ],
      "metadata": {
        "id": "xBNEKMLDaWzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 패딩\n",
        "x_train = pad_sequences(x_train,\n",
        "                        value=0,\n",
        "                        padding='pre',\n",
        "                        maxlen=300)\n",
        "x_test = pad_sequences(x_test,\n",
        "                       value=0,\n",
        "                       padding='pre',\n",
        "                       maxlen=300)"
      ],
      "metadata": {
        "id": "uQi0kiknbISb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원핫인코딩을 해줍시다\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "one_hot_y_train = to_categorical(y_train)\n",
        "one_hot_y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "ooUCAEcdAYaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터는 준비되었으므로, 이제 모델을 설계하고 훈련을 진행해봅시다."
      ],
      "metadata": {
        "id": "1lsDeQ12b8J7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델설계\n",
        "vocab_size = 8000\n",
        "word_vector_dim = 100\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "model.add(keras.layers.LSTM(64))\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dropout(rate=0.2))\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2EBTSUZcARN",
        "outputId": "98e1843b-b7c6-4fa5-cf5c-d3f9b3a40076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_53\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_44 (Embedding)    (None, None, 100)         800000    \n",
            "                                                                 \n",
            " lstm_41 (LSTM)              (None, 64)                42240     \n",
            "                                                                 \n",
            " dense_154 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_155 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_156 (Dense)           (None, 46)                2990      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 853,550\n",
            "Trainable params: 853,550\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델훈련\n",
        "epochs = 35\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, one_hot_y_train,\n",
        "         epochs=epochs,\n",
        "         batch_size=128,\n",
        "         validation_data=(x_test, one_hot_y_test),\n",
        "         verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juQttTjCcJlB",
        "outputId": "9008e2b6-f193-4d80-cdbc-cc4fd0d18a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "71/71 [==============================] - 4s 31ms/step - loss: 2.8543 - accuracy: 0.3351 - val_loss: 2.1496 - val_accuracy: 0.4568\n",
            "Epoch 2/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 1.9311 - accuracy: 0.4706 - val_loss: 1.7910 - val_accuracy: 0.5583\n",
            "Epoch 3/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 1.7561 - accuracy: 0.5024 - val_loss: 1.7523 - val_accuracy: 0.5356\n",
            "Epoch 4/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 1.6382 - accuracy: 0.5571 - val_loss: 1.7418 - val_accuracy: 0.5401\n",
            "Epoch 5/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 1.5218 - accuracy: 0.5755 - val_loss: 1.7103 - val_accuracy: 0.5516\n",
            "Epoch 6/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 1.4396 - accuracy: 0.5993 - val_loss: 1.7352 - val_accuracy: 0.5797\n",
            "Epoch 7/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 1.4352 - accuracy: 0.5912 - val_loss: 1.6948 - val_accuracy: 0.5810\n",
            "Epoch 8/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 1.3239 - accuracy: 0.6316 - val_loss: 1.7388 - val_accuracy: 0.5663\n",
            "Epoch 9/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 1.2464 - accuracy: 0.6555 - val_loss: 1.7697 - val_accuracy: 0.5788\n",
            "Epoch 10/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 1.1863 - accuracy: 0.6810 - val_loss: 1.7413 - val_accuracy: 0.5966\n",
            "Epoch 11/35\n",
            "71/71 [==============================] - 2s 22ms/step - loss: 1.1549 - accuracy: 0.6770 - val_loss: 1.7619 - val_accuracy: 0.6011\n",
            "Epoch 12/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 1.0936 - accuracy: 0.6937 - val_loss: 1.7593 - val_accuracy: 0.6002\n",
            "Epoch 13/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 1.0320 - accuracy: 0.7130 - val_loss: 1.8242 - val_accuracy: 0.6144\n",
            "Epoch 14/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.9683 - accuracy: 0.7200 - val_loss: 1.8895 - val_accuracy: 0.5984\n",
            "Epoch 15/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.9336 - accuracy: 0.7303 - val_loss: 1.8703 - val_accuracy: 0.6131\n",
            "Epoch 16/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.8755 - accuracy: 0.7460 - val_loss: 1.9391 - val_accuracy: 0.6144\n",
            "Epoch 17/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.8288 - accuracy: 0.7633 - val_loss: 1.9349 - val_accuracy: 0.6082\n",
            "Epoch 18/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.7916 - accuracy: 0.7779 - val_loss: 1.9884 - val_accuracy: 0.6131\n",
            "Epoch 19/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.7205 - accuracy: 0.7949 - val_loss: 2.0502 - val_accuracy: 0.6380\n",
            "Epoch 20/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.6663 - accuracy: 0.8125 - val_loss: 2.0965 - val_accuracy: 0.6060\n",
            "Epoch 21/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.6474 - accuracy: 0.8165 - val_loss: 2.1875 - val_accuracy: 0.6429\n",
            "Epoch 22/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.6246 - accuracy: 0.8205 - val_loss: 2.1633 - val_accuracy: 0.6233\n",
            "Epoch 23/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.5853 - accuracy: 0.8320 - val_loss: 2.1897 - val_accuracy: 0.6443\n",
            "Epoch 24/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.5244 - accuracy: 0.8457 - val_loss: 2.3898 - val_accuracy: 0.6380\n",
            "Epoch 25/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.5065 - accuracy: 0.8542 - val_loss: 2.4100 - val_accuracy: 0.6456\n",
            "Epoch 26/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.4857 - accuracy: 0.8602 - val_loss: 2.4634 - val_accuracy: 0.6345\n",
            "Epoch 27/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.4675 - accuracy: 0.8656 - val_loss: 2.4969 - val_accuracy: 0.6269\n",
            "Epoch 28/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.4324 - accuracy: 0.8798 - val_loss: 2.6324 - val_accuracy: 0.6305\n",
            "Epoch 29/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.5405 - accuracy: 0.8393 - val_loss: 2.4441 - val_accuracy: 0.5833\n",
            "Epoch 30/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.5225 - accuracy: 0.8501 - val_loss: 2.4788 - val_accuracy: 0.6500\n",
            "Epoch 31/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.4207 - accuracy: 0.8807 - val_loss: 2.4820 - val_accuracy: 0.6407\n",
            "Epoch 32/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.4706 - accuracy: 0.8779 - val_loss: 2.5049 - val_accuracy: 0.6429\n",
            "Epoch 33/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.4402 - accuracy: 0.8850 - val_loss: 2.5387 - val_accuracy: 0.6398\n",
            "Epoch 34/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.5582 - accuracy: 0.8358 - val_loss: 2.5940 - val_accuracy: 0.6153\n",
            "Epoch 35/35\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.4307 - accuracy: 0.8761 - val_loss: 2.5807 - val_accuracy: 0.6411\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efe59a3b390>"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, one_hot_y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwHxxery7Wxg",
        "outputId": "58e1db28-fed4-4308-f752-dc558d88a86f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 1s 9ms/step - loss: 2.5807 - accuracy: 0.6411\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.5807442665100098, 0.641139805316925]"
            ]
          },
          "metadata": {},
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "해당 딥러닝모델은 성능이 62%정도밖에 나오지않는다. "
      ],
      "metadata": {
        "id": "xEh6U1WsCIX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 회고\n",
        "- 텐서플로우 데이터셋의 신기한점은 텍스트데이터가아니라 정수시퀀스가 주어진다는 점이다. 모델의 성능을 확인하려할때 따로 전처리를 해주지 않아도 되는점이 편리한거같다.\n",
        "- 이번노드를 진행하면서 많은 머신러닝모델을 사용해 볼 수 있어서 좋았다. 매번 딥러닝모델만 보다보니까 머신러닝을 까먹어가고있었는데 이번 노드를 통해 다시한번 상기시킬 수 있었다.\n",
        "- 좋은 성능을 보인 모델은 로지스틱회귀랑 소프트보팅이다. 조금더 높은 성능을 보인것은 소프트보팅이지만, 나는 로지스틱회귀가 좀 더 마음에 든다. 왜냐하면 학습시간때문이다. 보팅은 학습시키는데 무려 20분이상이 걸렸다. 데이터가 별로 안커서망정이지 데이터가 좀 컷다면 시간을 매우 많이 잡아먹었을것이다. 그에반해 로지스틱회귀는 10분을 넘어간적이없다. 빠른 학습시간에 좋은 성능까지,가성비가 좋은거같다.\n",
        "- 마지막으로 딥러닝모델을 설계해보고, 머신러닝 작업에서 사용했던 동일한 크기의 단어장과 동일한 데이터셋으로 딥러닝 성능을 확인해보는것이었다. 여기서 많은 시간을 할애했다. 모델 설계를 이리저리 바꿔보고, 패딩이나, 옵티마이저, 손실함수 등등 안건드려본게 없는것같다. 이런저런 수정을하다보니 50번이상의 모델설계를 하게되었다. 그럼에도불구하고 모델의 정확도가 70%를 넘긴적이없다...원래이런건지 내가 잘못설계한건지...다른분들이한것을 참조해보았다. 어떤분은 정확도가 80%를 넘겼길래 내가쓴 코드와 비교해보았더니 두가지 차이점이있었다. 첫번째로 계층의 깊이가 나보다 작았다. 이해는 할 수 없었지만 나도 한번 계층의 깊이를 훨씬 낮추어서 학습을 진행해보았지만 큰 성능의 향상은 없었다. 두번째는 벡터화과정이다. 나는 임베딩계층을 이용해서 벡터화를 진행했지만, 이분은 임베딩 계층을 사용하지않고, 정답레이블뿐만아니라 입력데이터도 원핫벡터로 표현한것이다. 말그대로 입력값과 정답레이블이 전부 0과1로 이루어진 데이터를 모델에 넣었던 것이다...데이터가 작았었기때문에 가능한방법인것같다(나도 다음에 써먹어봐야겠다)"
      ],
      "metadata": {
        "id": "Fdxed01DCVoS"
      }
    }
  ]
}