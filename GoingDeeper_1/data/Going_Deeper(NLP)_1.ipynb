{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzj8Z_5nsxiz"
      },
      "source": [
        "# 프로젝트 : SentencePiece 사용하기\n",
        "# Step1. Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OjqOq1Kse9Q"
      },
      "outputs": [],
      "source": [
        "# Mecab 설치\n",
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk \n",
        "!pip3 install konlpy JPype1-py3\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_ijP-koD3XsL"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Mecab\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG6ur5wk6ToC"
      },
      "source": [
        "# Step2. Import Data\n",
        "사용할 데이터셋은 [네이버 영화리뷰 감정분석](https://github.com/e9t/nsmc/)입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Ub074KU16WHZ",
        "outputId": "f8b36f67-6554-4b0c-f139-859665ba48d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             id                       document  label\n",
              "65668   8558886          저 브로커조차 돈을받고 다큐를 찍었네ㅋ      0\n",
              "136490  2050923              2004년 최악의 영화중 하나.      0\n",
              "52019   1371995       내가본 최고의 영화중 한편으로 각인될것이다.      1\n",
              "77908   9766503             줄리안이다ㅋㅋ 요래보니 반갑군ㅋㅋ      1\n",
              "52586   3719672  세상에서 가장 똑똑해 보이는 멍청이의 요절복통 코메디      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-842ec73a-6993-41cc-be5e-9c5a94c7bc0c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>65668</th>\n",
              "      <td>8558886</td>\n",
              "      <td>저 브로커조차 돈을받고 다큐를 찍었네ㅋ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136490</th>\n",
              "      <td>2050923</td>\n",
              "      <td>2004년 최악의 영화중 하나.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52019</th>\n",
              "      <td>1371995</td>\n",
              "      <td>내가본 최고의 영화중 한편으로 각인될것이다.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77908</th>\n",
              "      <td>9766503</td>\n",
              "      <td>줄리안이다ㅋㅋ 요래보니 반갑군ㅋㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52586</th>\n",
              "      <td>3719672</td>\n",
              "      <td>세상에서 가장 똑똑해 보이는 멍청이의 요절복통 코메디</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-842ec73a-6993-41cc-be5e-9c5a94c7bc0c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-842ec73a-6993-41cc-be5e-9c5a94c7bc0c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-842ec73a-6993-41cc-be5e-9c5a94c7bc0c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_data = pd.read_table('/content/drive/MyDrive/GoingDeeper_Data/GD1/ratings_train.txt')\n",
        "test_data = pd.read_table('/content/drive/MyDrive/GoingDeeper_Data/GD1/ratings_test.txt')\n",
        "\n",
        "train_data.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7np5RLwO--H"
      },
      "source": [
        "# Step3. Preprocessing Data\n",
        "\n",
        "## 1. 전처리함수 구현\n",
        "해당 데이터는 전처리가 되지 않은 데이터입니다. 전처리함수를 만들고, 함수를 이용해 전처리를 시켜주겠습니다. 그리고 토크나이저는 Mecab, Kkma, Okt 3가지를 사용할 것인데 먼저 Mecab으로 수행해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZhivPwYubZP"
      },
      "outputs": [],
      "source": [
        "tokenizer = Mecab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VQPhHoXW4YKj"
      },
      "outputs": [],
      "source": [
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
        "\n",
        "def preprocessing(train_data, test_data, num_words=10000):\n",
        "    # 중복치, 결측치 제거\n",
        "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
        "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
        "    train_data = train_data.dropna(how= 'any')\n",
        "    test_data = test_data.dropna(how= 'any')\n",
        "\n",
        "    # 토큰화, 불용어 제거\n",
        "    X_train = []\n",
        "    for sentence in train_data['document']:\n",
        "        temp_X = tokenizer.morphs(sentence)\n",
        "        temp_X = [word for word in temp_X if not word in stopwords]\n",
        "        X_train.append(temp_X) # 리스트안에 리스트로 저장됨\n",
        "\n",
        "    X_test = []\n",
        "    for sentence in test_data['document']:\n",
        "        temp_X = tokenizer.morphs(sentence)\n",
        "        temp_X = [word for word in temp_X if not word in stopwords]\n",
        "        X_test.append(temp_X)\n",
        "\n",
        "    # 사전구성\n",
        "    words = np.concatenate(X_train).tolist() # 각 리스트들을 합쳐주면 넘파이배열로 저장되는데 이를 다시 리스트로변환\n",
        "    counter = Counter(words) # 딕셔너리형태로 각 단어의 빈도수를 저장\n",
        "    counter = counter.most_common(10000-4) # 각 단어의 빈도수를 튜플로만들고 내림차순으로 리스트에 담음\n",
        "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter] # 빈도수를 제외하고 각 단어들을 특수토큰과 합침\n",
        "    word_to_index = {word:index for index, word in enumerate(vocab)} # 리스트에 담겨있는 단어 순서대로 0부터 인덱스를 매김\n",
        "\n",
        "    # 텍스트리스트를 꺼내서 이를 각 단어에해당하는 인덱스 리스트로 변환시켜줌\n",
        "    def wordlist_to_indexlist(wordlist):\n",
        "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
        "    \n",
        "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
        "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
        "\n",
        "    # X_train, y_train, X_test, y_test, word_to_index 리턴턴\n",
        "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALqqZomkud9o"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_test, y_test, word_to_index = preprocessing(train_data, test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfJF0jdf-19y"
      },
      "outputs": [],
      "source": [
        "index_to_word = {index:word for word, index in word_to_index.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk1VjLPgHbWU"
      },
      "source": [
        "## 2. 패딩\n",
        "패딩을 시켜주기위해 먼저 데이터셋 내 문장 길이 분포를 확인하고 최대길이를 지정해주겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLy3otGzHs-M"
      },
      "outputs": [],
      "source": [
        "total_data = list(X_train) + list(X_test)\n",
        "len_list = [len(sentence) for sentence in total_data] # 문장길이 리스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "UyeXfRLzIwEu",
        "outputId": "028c9ca3-181c-4be0-c82d-66e2a3f1020b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([3.5740e+03, 2.1467e+04, 3.6004e+04, 3.0725e+04, 2.5049e+04,\n",
              "        2.0522e+04, 1.4715e+04, 9.5350e+03, 5.9230e+03, 2.8880e+03,\n",
              "        3.6190e+03, 2.9720e+03, 2.5950e+03, 2.2050e+03, 1.9180e+03,\n",
              "        1.7100e+03, 1.6030e+03, 1.6800e+03, 1.7670e+03, 1.1360e+03,\n",
              "        1.4320e+03, 1.0730e+03, 6.1800e+02, 3.1700e+02, 1.6000e+02,\n",
              "        6.7000e+01, 3.8000e+01, 1.3000e+01, 4.0000e+00, 3.0000e+00,\n",
              "        2.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00]),\n",
              " array([  0. ,   2.9,   5.8,   8.7,  11.6,  14.5,  17.4,  20.3,  23.2,\n",
              "         26.1,  29. ,  31.9,  34.8,  37.7,  40.6,  43.5,  46.4,  49.3,\n",
              "         52.2,  55.1,  58. ,  60.9,  63.8,  66.7,  69.6,  72.5,  75.4,\n",
              "         78.3,  81.2,  84.1,  87. ,  89.9,  92.8,  95.7,  98.6, 101.5,\n",
              "        104.4, 107.3, 110.2, 113.1, 116. ]),\n",
              " <a list of 40 Patch objects>)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(len_list, bins=40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw0k4zL7J0k4"
      },
      "source": [
        "최대길이는 평균에다가 표준편차*2를 더한값으로 하겠습니다.(신뢰구간95%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5XzVBJ7Jh3-",
        "outputId": "f7ea42cf-a551-4caa-9163-d14c0c724428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41\n"
          ]
        }
      ],
      "source": [
        "max_len = np.mean(len_list) + 2 * np.std(len_list)\n",
        "max_len = int(max_len)\n",
        "print(max_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4AI93lKKbXL"
      },
      "source": [
        "이제 패딩을 시켜줍시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BDa_hXsKxDa"
      },
      "outputs": [],
      "source": [
        "X_train = pad_sequences(X_train,\n",
        "                        value=word_to_index[\"<PAD>\"],\n",
        "                        padding='pre',\n",
        "                        maxlen=max_len)\n",
        "X_test = pad_sequences(X_test,\n",
        "                       value=word_to_index[\"<PAD>\"],\n",
        "                       padding='pre',\n",
        "                       maxlen=max_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brz0uTXj2-53"
      },
      "source": [
        "# Step4. 모델 생성 및 훈련\n",
        "## LSTM\n",
        "모델을 설계해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0v_8DJtMYqt",
        "outputId": "6f533b5c-869a-4f68-839a-be81194d17e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 200)         2000000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 8)                 6688      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,006,769\n",
            "Trainable params: 2,006,769\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vocab_size = 10000\n",
        "word_vector_dim = 200\n",
        "\n",
        "lstm = keras.Sequential()\n",
        "lstm.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "lstm.add(keras.layers.LSTM(8))\n",
        "lstm.add(keras.layers.Dense(8, activation='relu'))\n",
        "lstm.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "lstm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G856ITQdQW2c"
      },
      "source": [
        "훈련을 시켜보겠습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJU63VTtQaDV",
        "outputId": "be37b6c2-fcb3-4521-d4a8-0299511f4f1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "286/286 [==============================] - 5s 9ms/step - loss: 0.4389 - accuracy: 0.8043 - val_loss: 0.3575 - val_accuracy: 0.8454\n",
            "Epoch 2/20\n",
            "286/286 [==============================] - 2s 8ms/step - loss: 0.3191 - accuracy: 0.8647 - val_loss: 0.3434 - val_accuracy: 0.8502\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5f3e1f7790>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epochs = 20\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=0)\n",
        "\n",
        "lstm.compile(optimizer='adam',\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "lstm.fit(X_train, y_train,\n",
        "         epochs=epochs,\n",
        "         batch_size=512,\n",
        "         validation_data=(X_test, y_test),\n",
        "         callbacks=[callback],\n",
        "         verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCJX8uek3_6N"
      },
      "source": [
        "# Step5. 다른 토크나이저들(KoNLPy)\n",
        "## Kkma\n",
        "이번엔 Kkma를 토크나이저로 사용해보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifIDk8dRvIVP"
      },
      "source": [
        "그냥 Konlpy를 install하면 Kkma와 Okt사용에는 문제가 없고, Mecab사용할때 문제가 발생한다. 그래서 초반에 Mecab사용을 위해 추가적인 설치를 해주었지만, 이로인해 다시 Kkma와 Okt사용에 문제가 생겨버립니다. 따라서 코랩세션관리에서 해당 노트북을 지운다음에 다시 konlpy를 설치해준다음에 Kkma와 Okt를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBnz1LDqp2RD"
      },
      "outputs": [],
      "source": [
        "!pip3 install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-mTZJaniSwrf",
        "outputId": "159023ab-b043-4823-f6dd-5f9bebe93372"
      },
      "outputs": [
        {
          "ename": "java.lang.OutOfMemoryError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/_jpype.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mkr.lucypark.kkma.KkmaInterface.morphAnalyzer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/_jpype.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36morg.snu.ids.ha.ma.MorphemeAnalyzer.analyze\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/_jpype.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36morg.snu.ids.ha.ma.MorphemeAnalyzer.analyze\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/_jpype.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mjava.lang.StringBuilder.append\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/_jpype.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mjava.lang.String.valueOf\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/_jpype.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36morg.snu.ids.ha.ma.MExpression.toString\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/_jpype.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mjava.lang.StringBuffer.append\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/_jpype.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mjava.lang.AbstractStringBuilder.append\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/_jpype.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mjava.lang.AbstractStringBuilder.ensureCapacityInternal\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/_jpype.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mjava.util.Arrays.copyOf\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Java Exception",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mjava.lang.OutOfMemoryError\u001b[0m                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-bc0753d1b922>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKkma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKkma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 토크나이저 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 전처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-9a9b6113ee1d>\u001b[0m in \u001b[0;36mpreprocessing\u001b[0;34m(train_data, test_data, num_words)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'document'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtemp_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtemp_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_X\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_X\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 리스트안에 리스트로 저장됨\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/konlpy/tag/_kkma.py\u001b[0m in \u001b[0;36mmorphs\u001b[0;34m(self, phrase)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;34m\"\"\"Parse phrase to morphemes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/konlpy/tag/_kkma.py\u001b[0m in \u001b[0;36mpos\u001b[0;34m(self, phrase, flatten, join)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mvalidate_phrase_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjki\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mmorphemes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mjava.lang.OutOfMemoryError\u001b[0m: java.lang.OutOfMemoryError: Java heap space"
          ]
        }
      ],
      "source": [
        "from konlpy.tag import Kkma\n",
        "tokenizer = Kkma() # 토크나이저 생성\n",
        "X_train, y_train, X_test, y_test, word_to_index = preprocessing(train_data, test_data) # 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## java.lang.OutOfMemoryError: Java heap space 에러원인\n",
        "heap은 서버를 구동할 떄 앞으로 있을 메모리를 미리 할당하게 되는데, 만약 heap의 총용량보다 넘치게 된다면 해당 에러가 발생하게됩니다. 따라서 문제를 해결하려면 서버의 메모리 용량을 늘려줘야합니다. 아래의 코드로 heap의 용량을 늘려줄 수 있습니다.\n",
        "\n",
        "1024 -> 2048 -> 4096 순으로 늘려주었을때, 늘어난만큼 더 오랬동안 작동이 되었지만 결국 반복되는 heap용량의 문제로 전처리가 진행되지않습니다. 더 이상은 너무 많은 시간을 잡아먹으므로 여기까지만 하고, Okt를 사용하겠습니다."
      ],
      "metadata": {
        "id": "smw5qDnC3VPp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpYa5PbR5W1b"
      },
      "outputs": [],
      "source": [
        "import konlpy\n",
        "konlpy.jvm.init_jvm(jvmpath=None, max_heap_size=4096)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVNrCRIQxTte"
      },
      "source": [
        "## Okt\n",
        "토크나이저로 Okt도 사용해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1U_wIPuSxeB5"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Okt\n",
        "tokenizer = Okt()\n",
        "X_train, y_train, X_test, y_test, word_to_index = preprocessing(train_data, test_data) # 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRBrzNW2xnwz"
      },
      "source": [
        "패딩을 해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eF7Qiy7xryW",
        "outputId": "a05317f7-c976-4d0a-b03f-935e433f5ecd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33\n"
          ]
        }
      ],
      "source": [
        "total_data = list(X_train) + list(X_test)\n",
        "len_list = [len(sentence) for sentence in total_data] # 문장길이 리스트\n",
        "max_len = np.mean(len_list) + 2 * np.std(len_list)\n",
        "max_len = int(max_len)\n",
        "print(max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucAPmRilxwLk"
      },
      "outputs": [],
      "source": [
        "X_train = pad_sequences(X_train,\n",
        "                        value=word_to_index[\"<PAD>\"],\n",
        "                        padding='pre',\n",
        "                        maxlen=max_len)\n",
        "X_test = pad_sequences(X_test,\n",
        "                       value=word_to_index[\"<PAD>\"],\n",
        "                       padding='pre',\n",
        "                       maxlen=max_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9xX1jkQxyWI"
      },
      "source": [
        "모델설계 및 훈련을 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtWp8Ob1x0RS",
        "outputId": "dccbbd1e-1257-43ef-b0ea-61c97bb97255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "286/286 [==============================] - 13s 11ms/step - loss: 0.4446 - accuracy: 0.8070 - val_loss: 0.3620 - val_accuracy: 0.8397\n",
            "Epoch 2/20\n",
            "286/286 [==============================] - 2s 7ms/step - loss: 0.3226 - accuracy: 0.8613 - val_loss: 0.3472 - val_accuracy: 0.8459\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f635fe39050>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size = 10000\n",
        "word_vector_dim = 200\n",
        "\n",
        "lstm = keras.Sequential()\n",
        "lstm.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "lstm.add(keras.layers.LSTM(8))\n",
        "lstm.add(keras.layers.Dense(8, activation='relu'))\n",
        "lstm.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "epochs = 20\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=0)\n",
        "\n",
        "lstm.compile(optimizer='adam',\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "lstm.fit(X_train, y_train,\n",
        "         epochs=epochs,\n",
        "         batch_size=512,\n",
        "         validation_data=(X_test, y_test),\n",
        "         callbacks=[callback],\n",
        "         verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KoNLPy tokenizers 성능확인\n",
        "|    |val_loss|val_accuracy|\n",
        "|:---:|:---:|:---:|\n",
        "|Mecab|0.3434|0.8502|\n",
        "|Okt|0.3472|0.8459|"
      ],
      "metadata": {
        "id": "zf9qa8qD-7jX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step6. SentencePiece 설치하기\n",
        "SentencePiece는 구글에서 제공하는 오픈소스기반 토크나이저로서, BPE와 unigram 2가지 subword토크나이징 모델 중 하나를 선택해서 사용할 수 있도록 패키징한 것입니다. 그리고 최근 사전학습된 대부분 모델들은 SentencePice를 토크나이저로 채용하면서 사실상 표준의 역할을 하고 있습니다.\n",
        "\n",
        "먼저 설치를 진행합니다."
      ],
      "metadata": {
        "id": "Y0iJVuc6ETz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5TJudA5-Ls4",
        "outputId": "89231510-bd90-42cd-9f58-c16a1014a90f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 7.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터의 문장들을 리스트에 전부 담아줍니다.\n",
        "corpus = []\n",
        "\n",
        "for sentence in train_data['document']:\n",
        "    corpus.append(sentence)\n",
        "\n",
        "print(len(corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePt0KjAfB21D",
        "outputId": "fbdd3812-e08f-4e2d-ebb4-0040894a560d"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리\n",
        "추후 패딩을 위해서 너무 긴문장은 지우고, 너무 짧은 문장은 노이즈로 작용할 수 있기때문에 지워주겠습니다."
      ],
      "metadata": {
        "id": "B89dktLKZiPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sen_len = []\n",
        "\n",
        "for s in corpus:\n",
        "    t = len(str(s))\n",
        "    sen_len.append(t)\n",
        "\n",
        "plt.figure()\n",
        "plt.hist(sen_len, bins=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "RzQsiKQxT1IC",
        "outputId": "fb550cd8-369c-492b-f4d5-90277d24b8b4"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 2989.,  4643.,  5620., 10396., 13123., 11380., 10509.,  9621.,\n",
              "         8850.,  5738.,  8133.,  7323.,  6273.,  6085.,  5737.,  4845.,\n",
              "         2531.,  1904.,  1706.,  1029.,  1448.,  1291.,  1245.,  1112.,\n",
              "         1002.,   955.,   890.,   833.,   810.,   502.,   751.,   621.,\n",
              "          609.,   627.,   528.,   514.,   530.,   445.,   476.,   266.,\n",
              "          433.,   438.,   479.,   473.,   538.,   696.,   995.,  2003.,\n",
              "           30.,    25.]),\n",
              " array([  1. ,   3.9,   6.8,   9.7,  12.6,  15.5,  18.4,  21.3,  24.2,\n",
              "         27.1,  30. ,  32.9,  35.8,  38.7,  41.6,  44.5,  47.4,  50.3,\n",
              "         53.2,  56.1,  59. ,  61.9,  64.8,  67.7,  70.6,  73.5,  76.4,\n",
              "         79.3,  82.2,  85.1,  88. ,  90.9,  93.8,  96.7,  99.6, 102.5,\n",
              "        105.4, 108.3, 111.2, 114.1, 117. , 119.9, 122.8, 125.7, 128.6,\n",
              "        131.5, 134.4, 137.3, 140.2, 143.1, 146. ]),\n",
              " <a list of 50 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "길이가 10미만인 문장과 길이가 50이상인 문장은 지워주도록 하겠습니다. "
      ],
      "metadata": {
        "id": "ZNR36WP-Zzlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 50\n",
        "min_len = 10\n",
        "\n",
        "filtered_corpus = [] \n",
        "filtered_target = []  \n",
        "\n",
        "target = np.array(train_data['label'])\n",
        "\n",
        "for s, t in zip(corpus, target):\n",
        "    if (len(str(s)) < max_len) & (len(str(s)) >= min_len):\n",
        "        filtered_corpus.append(s) \n",
        "        filtered_target.append(t)\n",
        "\n",
        "print(len(filtered_corpus))\n",
        "print(len(filtered_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_FjHplJZv3K",
        "outputId": "620a551f-c849-4cf7-d280-4b438697585a"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "109826\n",
            "109826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 길이10~50인 말뭉치가 완성이 되었습니다."
      ],
      "metadata": {
        "id": "RR27jZsIbuo2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step7. SentencePiece 모델 학습\n",
        "토크나이저 함수를 정의해주기위해서 SentencePiece모델을 학습시켜줘야합니다."
      ],
      "metadata": {
        "id": "KAedm7FGIeS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "temp_file = '/content/drive/MyDrive/GoingDeeper_Data/GD1/korean-english-park.train.ko.temp'\n",
        "\n",
        "vocab_size = 10000\n",
        "\n",
        "with open(temp_file, 'w') as f:\n",
        "    for row in filtered_corpus:\n",
        "        f.write(str(row) + '\\n')\n",
        "\n",
        "spm.SentencePieceTrainer.Train(\n",
        "    '--input={} --model_prefix=kor_spm_bpe_8k --model_type=bpe --vocab_size={}'.format(temp_file, vocab_size)\n",
        ")"
      ],
      "metadata": {
        "id": "b46eDEbuIye-"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l kor_spm_bpe_8k*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gbmIlUBKxya",
        "outputId": "00eacb01-bd83-4460-f278-76bcec12afbc"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 408426 Sep 23 03:59 kor_spm_bpe_8k.model\n",
            "-rw-r--r-- 1 root root 149617 Sep 23 03:59 kor_spm_bpe_8k.vocab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SentencePiece모델학습이 완료된후 **kor_spm_bpe_8k.model**파일과 **kor_spm_bpe_8k.vocab**파일이 생성되었음을 확인할 수 있습니다.\n",
        "\n",
        "그럼 이렇게 학습된 모델을 한번 짧은 문장으로 활용해보겠습니다."
      ],
      "metadata": {
        "id": "D54hmW0fLIWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = spm.SentencePieceProcessor()\n",
        "s.Load('kor_spm_bpe_8k.model')\n",
        "\n",
        "# SentencePiece를 활용한 sentence -> encoding\n",
        "tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
        "print(tokensIDs)\n",
        "\n",
        "# SentencePiece를 활용한 encoding -> sentence 복원\n",
        "print(s.DecodeIds(tokensIDs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqOCh1xbL5cu",
        "outputId": "ab28b639-6685-4c56-9e0b-f3706794d99e"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6447, 1006, 8552, 8273, 1599, 8267, 8380, 8261, 8259]\n",
            "아버지가방에들어가신다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step8. Tokenizer 함수 작성\n",
        "아래 조건을 만족하는 함수를 정의하도록 하겠습니다.\n",
        "1. 매개변수로 토큰화된 문장의 list를 전달하는 대신 온전한 문장의 list를 전달합니다.\n",
        "2. 생성된 vocab파일을 읽어와 {word:index}형태를 가지는 word_index사전과 {index:word}형태를 가지는 index_word사전을 생성하고 함께 반환합니다.\n",
        "3. 리턴값인 tensor는 토큰화한 후 인코딩된 문장입니다. "
      ],
      "metadata": {
        "id": "rKCxNSVHMs9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sp_tokenize(s, corpus, spm):\n",
        "\n",
        "    tensor = []\n",
        "    \n",
        "    # corpus에 있는 텍스트문장을 인코딩시켜 tensor에 넣어줍니다.\n",
        "    for sen in corpus:\n",
        "        tensor.append(s.EncodeAsIds(sen))\n",
        "\n",
        "    # 학습때 생성된 vocab파일을 불러와 vocab변수에 넣어 단어리스트를 생성합니다.\n",
        "    with open(\"./{}.vocab\".format(spm), 'r') as f:\n",
        "        vocab = f.readlines() # vocab=[...,'▁어릴\\t-995\\n','▁역사\\t-996\\n',...]\n",
        "\n",
        "    word_index = {}\n",
        "    index_word = {}\n",
        "    # vocab에 있는 단어를 꺼내 순수 텍스트만 꺼내서 word에 저장해주고, 이를 이용해 사전을 만들어줍니다.\n",
        "    for idx, line in enumerate(vocab):\n",
        "        word = line.split(\"\\t\")[0]\n",
        "\n",
        "        word_index.update({word:idx})\n",
        "        index_word.update({idx:word})\n",
        "\n",
        "    tensor = pad_sequences(tensor, padding='post')\n",
        "\n",
        "    return tensor, word_index, index_word"
      ],
      "metadata": {
        "id": "XF_I3JlbNS48"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "그럼 말뭉치를 함수에 통과시켜서 tensor를 얻어봅시다."
      ],
      "metadata": {
        "id": "JCrXJC79bnbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor, word_index, index_word = sp_tokenize(s, filtered_corpus, 'kor_spm_bpe_8k')"
      ],
      "metadata": {
        "id": "nK-VI-jAQoOK"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor[30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFJE2CUkbWmP",
        "outputId": "4704dbc8-a745-4225-9ade-a883036c31c0"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   6,  208,   71,  245, 4574,  613,  539, 1019,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step9. 훈련셋과 테스트셋 분리"
      ],
      "metadata": {
        "id": "3KeKk0rXcCsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(tensor, filtered_target, test_size=0.2)"
      ],
      "metadata": {
        "id": "oZbQB5-ccKoV"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "KnvR38Q_yMB8"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train))\n",
        "print(len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dHbfrxvwZib",
        "outputId": "632845a1-8e8a-49f7-ba13-53b73361181f"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87860\n",
            "21966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step10. 모델설계 및 훈련"
      ],
      "metadata": {
        "id": "ho5W3LSIwY0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "word_vector_dim = 200\n",
        "\n",
        "lstm = keras.Sequential()\n",
        "lstm.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "lstm.add(keras.layers.LSTM(8))\n",
        "lstm.add(keras.layers.Dense(8, activation='relu'))\n",
        "lstm.add(keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "Jrtvb-vkwl5U"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "lstm.compile(optimizer='adam',\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "lstm.fit(X_train, y_train,\n",
        "         epochs=epochs,\n",
        "         batch_size=512,\n",
        "         validation_data=(X_test, y_test),\n",
        "         callbacks=[callback],\n",
        "         verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZS6NUARw47X",
        "outputId": "4dda0d98-6bd9-451a-ee88-11dd07c63358"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 3s 10ms/step - loss: 0.6932 - accuracy: 0.4944 - val_loss: 0.6931 - val_accuracy: 0.5035\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.6931 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5036\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.6197 - accuracy: 0.6595 - val_loss: 0.6098 - val_accuracy: 0.6727\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.5694 - accuracy: 0.7308 - val_loss: 0.5698 - val_accuracy: 0.7208\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.5535 - accuracy: 0.7537 - val_loss: 0.5477 - val_accuracy: 0.7657\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.5334 - accuracy: 0.7724 - val_loss: 0.5333 - val_accuracy: 0.7721\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.4971 - accuracy: 0.7961 - val_loss: 0.5114 - val_accuracy: 0.7806\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.4604 - accuracy: 0.8118 - val_loss: 0.4818 - val_accuracy: 0.7915\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.4213 - accuracy: 0.8283 - val_loss: 0.4615 - val_accuracy: 0.8048\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.3916 - accuracy: 0.8440 - val_loss: 0.4466 - val_accuracy: 0.8113\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.3590 - accuracy: 0.8567 - val_loss: 0.4339 - val_accuracy: 0.8146\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.3414 - accuracy: 0.8702 - val_loss: 0.4504 - val_accuracy: 0.8210\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.3233 - accuracy: 0.8801 - val_loss: 0.4412 - val_accuracy: 0.8241\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.3074 - accuracy: 0.8891 - val_loss: 0.4428 - val_accuracy: 0.8245\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.2942 - accuracy: 0.8952 - val_loss: 0.4583 - val_accuracy: 0.8219\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.2831 - accuracy: 0.9021 - val_loss: 0.4834 - val_accuracy: 0.8211\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.2756 - accuracy: 0.9057 - val_loss: 0.4725 - val_accuracy: 0.8200\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.2691 - accuracy: 0.9092 - val_loss: 0.4686 - val_accuracy: 0.8205\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.2632 - accuracy: 0.9128 - val_loss: 0.4508 - val_accuracy: 0.8108\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.2613 - accuracy: 0.9120 - val_loss: 0.4880 - val_accuracy: 0.8212\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1346615b10>"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step11. Unigram 사용\n",
        "위에서 BPE모델을 사용해봤으니 이번엔 unigram모델을 사용해보겠습니다."
      ],
      "metadata": {
        "id": "u2NWIMJizifT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unigram모델 학습\n",
        "\n",
        "temp_file = '/content/drive/MyDrive/GoingDeeper_Data/GD1/korean-english-park.train.ko.temp'\n",
        "\n",
        "vocab_size = 10000\n",
        "\n",
        "with open(temp_file, 'w') as f:\n",
        "    for row in filtered_corpus:\n",
        "        f.write(str(row) + '\\n')\n",
        "\n",
        "spm.SentencePieceTrainer.Train(\n",
        "    '--input={} --model_prefix=kor_spm_unigram_10k --model_type=bpe --vocab_size={}'.format(temp_file, vocab_size)\n",
        ")"
      ],
      "metadata": {
        "id": "i9XFtmIjz0T6"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unigram모델과 사전파일 확인\n",
        "!ls -l kor_spm_unigram_10k*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni8hiS000C8W",
        "outputId": "77f86d98-3016-4d2c-a2da-083f0307c492"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 408431 Sep 23 05:26 kor_spm_unigram_10k.model\n",
            "-rw-r--r-- 1 root root 149617 Sep 23 05:26 kor_spm_unigram_10k.vocab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서와 사전획득\n",
        "tensor, word_index, index_word = sp_tokenize(s, filtered_corpus, 'kor_spm_unigram_10k')"
      ],
      "metadata": {
        "id": "RYDE06Tp0Lm0"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련셋과 테스트셋 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(tensor, filtered_target, test_size=0.2)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "jgp6u0V90Re1"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 설계\n",
        "vocab_size = 10000\n",
        "word_vector_dim = 200\n",
        "\n",
        "lstm = keras.Sequential()\n",
        "lstm.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "lstm.add(keras.layers.LSTM(8))\n",
        "lstm.add(keras.layers.Dense(8, activation='relu'))\n",
        "lstm.add(keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "1mBG6ZTP0no2"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "epochs = 20\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "lstm.compile(optimizer='adam',\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "lstm.fit(X_train, y_train,\n",
        "         epochs=epochs,\n",
        "         batch_size=512,\n",
        "         validation_data=(X_test, y_test),\n",
        "         callbacks=[callback],\n",
        "         verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BroFGpme0rxb",
        "outputId": "4e15ca89-f2a7-4f22-fc3a-d8f3bdb93a94"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 3s 10ms/step - loss: 0.6933 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.4993\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.6713 - accuracy: 0.5475 - val_loss: 0.5666 - val_accuracy: 0.7154\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.5451 - accuracy: 0.7556 - val_loss: 0.6053 - val_accuracy: 0.6869\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.5709 - accuracy: 0.7085 - val_loss: 0.5713 - val_accuracy: 0.7168\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.5464 - accuracy: 0.7514 - val_loss: 0.5422 - val_accuracy: 0.7673\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.5147 - accuracy: 0.7883 - val_loss: 0.5336 - val_accuracy: 0.7756\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.4978 - accuracy: 0.8014 - val_loss: 0.5340 - val_accuracy: 0.7749\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.4906 - accuracy: 0.8055 - val_loss: 0.5277 - val_accuracy: 0.7805\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.4834 - accuracy: 0.8108 - val_loss: 0.5232 - val_accuracy: 0.7833\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.4809 - accuracy: 0.8124 - val_loss: 0.5270 - val_accuracy: 0.7823\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.4802 - accuracy: 0.8134 - val_loss: 0.5254 - val_accuracy: 0.7828\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.4851 - accuracy: 0.8099 - val_loss: 0.5228 - val_accuracy: 0.7855\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.4754 - accuracy: 0.8149 - val_loss: 0.5210 - val_accuracy: 0.7842\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.4776 - accuracy: 0.8151 - val_loss: 0.5434 - val_accuracy: 0.7653\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.4988 - accuracy: 0.7885 - val_loss: 0.5230 - val_accuracy: 0.7855\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.4680 - accuracy: 0.8201 - val_loss: 0.5188 - val_accuracy: 0.7865\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.4649 - accuracy: 0.8204 - val_loss: 0.5105 - val_accuracy: 0.7823\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.4346 - accuracy: 0.8266 - val_loss: 0.4727 - val_accuracy: 0.7833\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.3997 - accuracy: 0.8294 - val_loss: 0.4533 - val_accuracy: 0.8011\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 1s 8ms/step - loss: 0.3598 - accuracy: 0.8520 - val_loss: 0.4364 - val_accuracy: 0.8137\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1330324890>"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step12. 성능 비교\n",
        "모델 설계는 전부 동일하게 맞추어 진행하였고, 정확도순으로 표를 정리하였다.\n",
        "\n",
        "|    |val_loss|val_accuracy|\n",
        "|:---:|:---:|:---:|\n",
        "|Mecab|0.3434|0.8502|\n",
        "|Okt|0.3472|0.8459|\n",
        "|BPE|0.4880|0.8212|\n",
        "|unigram|0.4364|0.8137|"
      ],
      "metadata": {
        "id": "q50D6H741QCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 회고\n",
        "- 이번 프로젝트는 여러가지 토크나이저를 사용해보면서 성능비교를하는 것입니다.\n",
        "- 여기서 사용한 데이터셋은 네이버 영화 리뷰 데이터셋으로 예전에 사용해본적이있어, 전처리자체는 크게 어렵지 않았다.\n",
        "- 초반에 Mecab을 사용하기위해 추가적인 설치과정이 있었다. 하지만 이 때문에 kkma랑 okt를 사용할때 에러가 나버린것이다. 에러를 해결하기위해 여러가지 시도를 해보고 구글링도 해보았지만, 아직 내 지식으로는 힘든것같아서 꼼수를 조금 써보았다. 먼저 Mecab을 사용한다음에, 세션관리에서 메로리를 지워서 초기화시켜주었다. 그리고나서 다시 KoNLPy를 불러와 Kkma와 Okt를 사용하였다.\n",
        "- Kkma를 사용할때 또다른 문제가 발생했다... Kkma는 정확도가 높은대신 다른 토크나이저에 비해 매우 느린 단점이 있다. 그때문인지 연산도중에 서버의 메모리 용량을 초과해서 heap space에러가 발생했다. heap space size를 반복해서 늘려주었지만, 어디까지 늘려야되는지도 모르겠고 시간도 너무 많이 잡아먹었다. 하다보니까 굳이 이렇게까지해서 써봐야하나라는 현타가왔다... 어짜피 다른 토크나이저도 많이 써볼것인데..라는 생각에 그냥 Kkma사용은 안하기로했다.\n",
        "- SentencePiece를 진행하기전에 데이터 전처리과정중에 너무 짧거나 너무 긴문장을 지우려고 len()을 사용해서 전처리를 하려했다. 하지만 왠지모르게 계속 에러가 뜨는것이 아닌가? 알고보니 당연히 전부 텍스트 데이터인줄알았는데 중간중간 텍스트가 아닌 숫자가 숨겨져있는것이었다. 그러니 len()함수가 안먹히는 것이 당연했다..\n",
        "- SentencePiece 모델들은 사용하기가 매우 편리한것같다. 그냥 원래 텍스트 문장을 넣어주면, 인코딩을 거쳐 분산표현으로 출력이 되었다.\n",
        "- SentencePiece모델들은 subword단위로 토큰화를 진행해 어떻게보면 Konlpy토크나이저보다 더 세밀하게 토큰화를 하는것이다. 하지만 최종 결과를 뽑아보니 SentencePiece모델보다 konlpy모델이 loss도 더 낮고, accuracy도 더 높았다. 엄청 큰차이가 나는것은 아니었지만, 딱히 이해가 가지않는다. 모델 설계를 잘못한것일까? 전처리를 잘못한것일까?"
      ],
      "metadata": {
        "id": "abMCQD8y2JMF"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}